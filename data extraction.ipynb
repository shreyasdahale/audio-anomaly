{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from sklearn import preprocessing \n",
    "import winsound\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = []\n",
    "maneuvering_direction = []\n",
    "fault = []\n",
    "ID = []\n",
    "\n",
    "for file in os.listdir('./Dataset-ArIES/drone_A/A/train/mic1'):\n",
    "    labels = file.split('_')\n",
    "    model_type.append(labels[0])\n",
    "    maneuvering_direction.append(labels[1])\n",
    "    fault.append(labels[2])\n",
    "    ID.append(file)\n",
    "for file in os.listdir('./Dataset-ArIES/drone_B/B/train/mic1'):\n",
    "    labels = file.split('_')\n",
    "    model_type.append(labels[0])\n",
    "    maneuvering_direction.append(labels[1])\n",
    "    fault.append(labels[2])\n",
    "    ID.append(file)\n",
    "for file in os.listdir('./Dataset-ArIES/drone_C/C/train/mic1'):\n",
    "    labels = file.split('_')\n",
    "    model_type.append(labels[0])\n",
    "    maneuvering_direction.append(labels[1])\n",
    "    fault.append(labels[2])\n",
    "    ID.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('./Dataset/drone_A/A/train/mic2'):\n",
    "    labels = file.split('_')\n",
    "    model_type.append(labels[0])\n",
    "    maneuvering_direction.append(labels[1])\n",
    "    fault.append(labels[2])\n",
    "    ID.append(file)\n",
    "for file in os.listdir('./Dataset/drone_B/B/train/mic2'):\n",
    "    labels = file.split('_')\n",
    "    model_type.append(labels[0])\n",
    "    maneuvering_direction.append(labels[1])\n",
    "    fault.append(labels[2])\n",
    "    ID.append(file)\n",
    "for file in os.listdir('./Dataset/drone_C/C/train/mic2'):\n",
    "    labels = file.split('_')\n",
    "    model_type.append(labels[0])\n",
    "    maneuvering_direction.append(labels[1])\n",
    "    fault.append(labels[2])\n",
    "    ID.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([ID, model_type, maneuvering_direction, fault])\n",
    "df = pd.DataFrame(data.T, columns=['ID', 'model_type', 'maneuvering_direction', 'fault']) \n",
    "df = pd.get_dummies(df, columns=['model_type', 'maneuvering_direction', 'fault'], dtype=int)\n",
    "df.to_csv('train.csv', index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic1 = []\n",
    "mic2 = []\n",
    "for file in os.listdir('./Dataset/drone_A/A/train/mic1'):\n",
    "    filename = os.path.join('./Dataset/drone_A/A/train/mic1', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic1.append(audio_data)\n",
    "for file in os.listdir('./Dataset/drone_A/A/train/mic2'):\n",
    "    filename = os.path.join('./Dataset/drone_A/A/train/mic2', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic2.append(audio_data)\n",
    "\n",
    "for file in os.listdir('./Dataset/drone_B/B/train/mic1'):\n",
    "    filename = os.path.join('./Dataset/drone_B/B/train/mic1', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic1.append(audio_data)\n",
    "for file in os.listdir('./Dataset/drone_B/B/train/mic2'):\n",
    "    filename = os.path.join('./Dataset/drone_B/B/train/mic2', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic2.append(audio_data)\n",
    "\n",
    "for file in os.listdir('./Dataset/drone_C/C/train/mic1'):\n",
    "    filename = os.path.join('./Dataset/drone_C/C/train/mic1', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic1.append(audio_data)\n",
    "for file in os.listdir('./Dataset/drone_C/C/train/mic2'):\n",
    "    filename = os.path.join('./Dataset/drone_C/C/train/mic2', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic2.append(audio_data)\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sg(audio_data, sr=22050):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
    "    # mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, S=spectrogram, n_mfcc=30)\n",
    "    # for i in range(len(spectrogram)):\n",
    "    #     for j in range(len(spectrogram[i])):\n",
    "    #           spectrogram[i][j] = spectrogram[i][j]/np.max(abs(spectrogram[i]))\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = []\n",
    "for i in tqdm(range(len(mic1))):\n",
    "    train_array.append(compute_sg(mic1[i]))\n",
    "for i in tqdm(range(len(mic1))):\n",
    "    train_array.append(compute_sg(mic2[i]))\n",
    "train_array = np.array(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_2d = train_array.reshape(len(train_array), train_array.shape[1]*train_array.shape[2])\n",
    "np.savetxt('sg_train.csv', train_array_2d, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic1_test = []\n",
    "mic2_test = []\n",
    "for file in os.listdir('./Dataset-ArIES/drone_A/A/test/mic1'):\n",
    "    filename = os.path.join('./Dataset-ArIES/drone_A/A/test/mic1', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic1_test.append(audio_data)\n",
    "for file in os.listdir('./Dataset-ArIES/drone_A/A/test/mic2'):\n",
    "    filename = os.path.join('./Dataset-ArIES/drone_A/A/test/mic2', file)\n",
    "    audio_data, sample_r = librosa.load(filename)\n",
    "    mic2_test.append(audio_data)\n",
    "\n",
    "for file in os.listdir('./Dataset-ArIES/drone_B/B/test/mic1'):\n",
    "    filename = os.path.join('./Dataset-ArIES/drone_B/B/test/mic1', file)\n",
    "    y, _ = librosa.load(filename)\n",
    "    mic1_test.append(y)\n",
    "for file in os.listdir('./Dataset-ArIES/drone_B/B/test/mic2'):\n",
    "    filename = os.path.join('./Dataset-ArIES/drone_B/B/test/mic2', file)\n",
    "    y, _ = librosa.load(filename)\n",
    "    mic2_test.append(y)\n",
    "\n",
    "for file in os.listdir('./Dataset-ArIES/drone_C/C/test/mic1'):\n",
    "    filename = os.path.join('./Dataset-ArIES/drone_C/C/test/mic1', file)\n",
    "    y, _ = librosa.load(filename)\n",
    "    mic1_test.append(y)\n",
    "for file in os.listdir('./Dataset-ArIES/drone_C/C/test/mic2'):\n",
    "    filename = os.path.join('./Dataset-ArIES/drone_C/C/test/mic2', file)\n",
    "    y, _ = librosa.load(filename)\n",
    "    mic2_test.append(y)\n",
    "\n",
    "print('Data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_array_test = []\n",
    "for i in tqdm(range(len(mic1_test))):\n",
    "    sg_array_test.append(compute_sg(mic1_test[i]))\n",
    "for i in tqdm(range(len(mic2_test))):\n",
    "    sg_array_test.append(compute_sg(mic2_test[i]))\n",
    "sg_array_test = np.array(sg_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_array_test_2d = sg_array_test.reshape(sg_array_test.shape[0], sg_array_test.shape[1]*sg_array_test.shape[2])\n",
    "np.savetxt('sg_test.csv', sg_array_test_2d, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
