{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8021673,"sourceType":"datasetVersion","datasetId":4719040}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import librosa\n# import os\nimport numpy as np\n# import matplotlib.pyplot as plt\nimport pandas as pd\n# import IPython.display as ipd\n# from sklearn import preprocessing \n# import winsound\nimport torch\nimport torch.nn as nn\n# import torch.optim as optim\n# from torch.autograd import Variable\nimport torch.nn.functional as F\n# from torch.utils.data import Dataset\n# from collections import Counter\nfrom tqdm import tqdm\n# from sklearn.metrics import classification_report \nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:35:42.292480Z","iopub.execute_input":"2024-04-04T02:35:42.293209Z","iopub.status.idle":"2024-04-04T02:35:46.882203Z","shell.execute_reply.started":"2024-04-04T02:35:42.293178Z","shell.execute_reply":"2024-04-04T02:35:46.881417Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# spectrogram_array = np.loadtxt('spectrograms_Atrain.csv', delimiter=',')\n# spectrogram_array = spectrogram_array.reshape(32400, 256, 74) # reshaping the array to have time frames as 3 dimensions","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:35:46.883826Z","iopub.execute_input":"2024-04-04T02:35:46.884718Z","iopub.status.idle":"2024-04-04T02:35:46.888463Z","shell.execute_reply.started":"2024-04-04T02:35:46.884684Z","shell.execute_reply":"2024-04-04T02:35:46.887592Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"mfcc_array_2d = np.loadtxt('/kaggle/input/dataset/mfcc_train.csv', delimiter=',')\nmfcc_array = mfcc_array_2d.reshape(len(mfcc_array_2d), 20, 74)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:35:47.974899Z","iopub.execute_input":"2024-04-04T02:35:47.975558Z","iopub.status.idle":"2024-04-04T02:37:13.372373Z","shell.execute_reply.started":"2024-04-04T02:35:47.975526Z","shell.execute_reply":"2024-04-04T02:37:13.371552Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# spectrograms_tensor_Atrain = torch.tensor(spectrogram_array, dtype=torch.float32)\n# spectrograms_tensor_Atrain = spectrograms_tensor_Atrain.unsqueeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:09:39.498669Z","iopub.execute_input":"2024-04-03T04:09:39.498989Z","iopub.status.idle":"2024-04-03T04:09:39.503015Z","shell.execute_reply.started":"2024-04-03T04:09:39.498963Z","shell.execute_reply":"2024-04-03T04:09:39.502058Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# spectrograms_tensor_Atrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:09:39.503911Z","iopub.execute_input":"2024-04-03T04:09:39.504153Z","iopub.status.idle":"2024-04-03T04:09:39.514810Z","shell.execute_reply.started":"2024-04-03T04:09:39.504131Z","shell.execute_reply":"2024-04-03T04:09:39.514038Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"training_tensor = torch.tensor(mfcc_array, dtype=torch.float32)\ntraining_tensor = training_tensor.unsqueeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:13.374238Z","iopub.execute_input":"2024-04-04T02:37:13.374589Z","iopub.status.idle":"2024-04-04T02:37:13.643765Z","shell.execute_reply.started":"2024-04-04T02:37:13.374559Z","shell.execute_reply":"2024-04-04T02:37:13.642696Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"output_data = pd.read_csv('/kaggle/input/dataset/train.csv', header = None)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:13.645010Z","iopub.execute_input":"2024-04-04T02:37:13.645447Z","iopub.status.idle":"2024-04-04T02:37:13.990409Z","shell.execute_reply.started":"2024-04-04T02:37:13.645419Z","shell.execute_reply":"2024-04-04T02:37:13.989443Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1821392965.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n  output_data = pd.read_csv('/kaggle/input/dataset/train.csv', header = None)\n","output_type":"stream"}]},{"cell_type":"code","source":"output_data","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:13.993214Z","iopub.execute_input":"2024-04-04T02:37:13.993869Z","iopub.status.idle":"2024-04-04T02:37:14.024798Z","shell.execute_reply.started":"2024-04-04T02:37:13.993836Z","shell.execute_reply":"2024-04-04T02:37:14.023862Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                      0             1   \\\n0                                                     ID  model_type_A   \n1      A_B_MF1_mic1_0_ConstructionSite_527_snr=12.519...             1   \n2      A_B_MF1_mic1_100_EoeunHill_279_snr=11.12957698...             1   \n3      A_B_MF1_mic1_101_WestDoor_321_snr=12.345834132...             1   \n4      A_B_MF1_mic1_103_ConstructionSite_465_snr=11.8...             1   \n...                                                  ...           ...   \n97196  C_R_PC4_mic1_974_ConstructionSite_720_snr=12.8...             0   \n97197  C_R_PC4_mic1_975_DuckPond_142_snr=12.327612455...             0   \n97198  C_R_PC4_mic1_977_SportsComplex_566_snr=13.2281...             0   \n97199  C_R_PC4_mic1_97_WestDoor_280_snr=14.8309085957...             0   \n97200  C_R_PC4_mic1_98_WestDoor_227_snr=11.9326010221...             0   \n\n                 2             3                        4   \\\n0      model_type_B  model_type_C  maneuvering_direction_B   \n1                 0             0                        1   \n2                 0             0                        1   \n3                 0             0                        1   \n4                 0             0                        1   \n...             ...           ...                      ...   \n97196             0             1                        0   \n97197             0             1                        0   \n97198             0             1                        0   \n97199             0             1                        0   \n97200             0             1                        0   \n\n                            5                         6   \\\n0      maneuvering_direction_C  maneuvering_direction_CC   \n1                            0                         0   \n2                            0                         0   \n3                            0                         0   \n4                            0                         0   \n...                        ...                       ...   \n97196                        0                         0   \n97197                        0                         0   \n97198                        0                         0   \n97199                        0                         0   \n97200                        0                         0   \n\n                            7                        8   \\\n0      maneuvering_direction_F  maneuvering_direction_L   \n1                            0                        0   \n2                            0                        0   \n3                            0                        0   \n4                            0                        0   \n...                        ...                      ...   \n97196                        0                        0   \n97197                        0                        0   \n97198                        0                        0   \n97199                        0                        0   \n97200                        0                        0   \n\n                            9          10         11         12         13  \\\n0      maneuvering_direction_R  fault_MF1  fault_MF2  fault_MF3  fault_MF4   \n1                            0          1          0          0          0   \n2                            0          1          0          0          0   \n3                            0          1          0          0          0   \n4                            0          1          0          0          0   \n...                        ...        ...        ...        ...        ...   \n97196                        1          0          0          0          0   \n97197                        1          0          0          0          0   \n97198                        1          0          0          0          0   \n97199                        1          0          0          0          0   \n97200                        1          0          0          0          0   \n\n            14         15         16         17         18  \n0      fault_N  fault_PC1  fault_PC2  fault_PC3  fault_PC4  \n1            0          0          0          0          0  \n2            0          0          0          0          0  \n3            0          0          0          0          0  \n4            0          0          0          0          0  \n...        ...        ...        ...        ...        ...  \n97196        0          0          0          0          1  \n97197        0          0          0          0          1  \n97198        0          0          0          0          1  \n97199        0          0          0          0          1  \n97200        0          0          0          0          1  \n\n[97201 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID</td>\n      <td>model_type_A</td>\n      <td>model_type_B</td>\n      <td>model_type_C</td>\n      <td>maneuvering_direction_B</td>\n      <td>maneuvering_direction_C</td>\n      <td>maneuvering_direction_CC</td>\n      <td>maneuvering_direction_F</td>\n      <td>maneuvering_direction_L</td>\n      <td>maneuvering_direction_R</td>\n      <td>fault_MF1</td>\n      <td>fault_MF2</td>\n      <td>fault_MF3</td>\n      <td>fault_MF4</td>\n      <td>fault_N</td>\n      <td>fault_PC1</td>\n      <td>fault_PC2</td>\n      <td>fault_PC3</td>\n      <td>fault_PC4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A_B_MF1_mic1_0_ConstructionSite_527_snr=12.519...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A_B_MF1_mic1_100_EoeunHill_279_snr=11.12957698...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A_B_MF1_mic1_101_WestDoor_321_snr=12.345834132...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A_B_MF1_mic1_103_ConstructionSite_465_snr=11.8...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97196</th>\n      <td>C_R_PC4_mic1_974_ConstructionSite_720_snr=12.8...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97197</th>\n      <td>C_R_PC4_mic1_975_DuckPond_142_snr=12.327612455...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97198</th>\n      <td>C_R_PC4_mic1_977_SportsComplex_566_snr=13.2281...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97199</th>\n      <td>C_R_PC4_mic1_97_WestDoor_280_snr=14.8309085957...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97200</th>\n      <td>C_R_PC4_mic1_98_WestDoor_227_snr=11.9326010221...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>97201 rows × 19 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"maneuvering_direction = output_data[[4, 5, 6, 7, 8, 9]].values[1:]\nmaneuvering_direction = maneuvering_direction.astype('int32')\nfault = output_data[[10, 11, 12, 13, 14, 15, 16, 17,18]].values[1:]\nfault = fault.astype('int32')\nmodel_type = output_data[[1, 2, 3]].values[1:]\nmodel_type = model_type.astype('int32')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:14.025781Z","iopub.execute_input":"2024-04-04T02:37:14.026042Z","iopub.status.idle":"2024-04-04T02:37:14.188144Z","shell.execute_reply.started":"2024-04-04T02:37:14.026019Z","shell.execute_reply":"2024-04-04T02:37:14.187266Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y1 = torch.tensor(model_type, dtype=torch.float16).cuda()\ny2 = torch.tensor(maneuvering_direction, dtype=torch.float16).cuda()\ny3 = torch.tensor(fault, dtype=torch.float16).cuda()\nXtr = torch.tensor(training_tensor, dtype=torch.float32).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:14.189329Z","iopub.execute_input":"2024-04-04T02:37:14.189629Z","iopub.status.idle":"2024-04-04T02:37:14.717169Z","shell.execute_reply.started":"2024-04-04T02:37:14.189598Z","shell.execute_reply":"2024-04-04T02:37:14.716344Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1052091417.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  Xtr = torch.tensor(training_tensor, dtype=torch.float32).cuda()\n","output_type":"stream"}]},{"cell_type":"code","source":"# Xtrain = torch.tensor(spectrograms_tensor_Atrain, dtype=torch.float32).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T04:09:40.820699Z","iopub.execute_input":"2024-04-03T04:09:40.820975Z","iopub.status.idle":"2024-04-03T04:09:40.824721Z","shell.execute_reply.started":"2024-04-03T04:09:40.820953Z","shell.execute_reply":"2024-04-03T04:09:40.823818Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = TensorDataset(Xtr, y1, y2, y3)\ndataloader = DataLoader(dataset, batch_size=128, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:14.718330Z","iopub.execute_input":"2024-04-04T02:37:14.718635Z","iopub.status.idle":"2024-04-04T02:37:14.723474Z","shell.execute_reply.started":"2024-04-04T02:37:14.718610Z","shell.execute_reply":"2024-04-04T02:37:14.722504Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.softplus1 = nn.Softplus(beta=1, threshold=20) \n        self.softplus2 = nn.Softplus(beta=1, threshold=20)\n        self.relu = nn.ReLU(inplace=True)\n        \n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = self.softplus1(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        shortcut = self.shortcut(x)\n        out += shortcut\n        out = self.softplus2(out)  \n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.rl = nn.ReLU(inplace=True)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.rl(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        return out\n\nclass MultiTaskResNet18(nn.Module):\n    def __init__(self, num_classes1=3, num_classes2=6, num_classes3=9):\n        super(MultiTaskResNet18, self).__init__()\n        self.resnet18 = ResNet(BasicBlock, [3, 4, 6, 3])\n        self.fc1 = nn.Linear(512, num_classes1)\n        self.fc2 = nn.Linear(512, num_classes2)\n        self.fc3 = nn.Linear(512, num_classes3)\n        self.sm1 = nn.Softmax(dim=1)#dim=1)\n        self.sm2 = nn.Softmax(dim=1)#dim=1)\n        self.sm3 = nn.Softmax(dim=1)#dim=1)\n\n    def forward(self, x):\n        out = self.resnet18(x)\n        out1 = self.sm1(self.fc1(out))#, dim=1)\n        out2 = self.sm2(self.fc2(out))#, dim=1)\n        out3 = self.sm3(self.fc3(out))#, dim=1)\n        return out1, out2, out3\n\nmodel = MultiTaskResNet18(num_classes1=3, num_classes2=6, num_classes3=9).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:14.724816Z","iopub.execute_input":"2024-04-04T02:37:14.725085Z","iopub.status.idle":"2024-04-04T02:37:15.047470Z","shell.execute_reply.started":"2024-04-04T02:37:14.725062Z","shell.execute_reply":"2024-04-04T02:37:15.046500Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:37:15.048613Z","iopub.execute_input":"2024-04-04T02:37:15.048873Z","iopub.status.idle":"2024-04-04T02:37:17.404646Z","shell.execute_reply.started":"2024-04-04T02:37:15.048852Z","shell.execute_reply":"2024-04-04T02:37:17.403706Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\nfor epoch in tqdm(range(num_epochs)):\n    for batch_idx, (data, target1, target2, target3) in enumerate(dataloader):\n        data, target1, target2, target3 = data.cuda(), target1.cuda(), target2.cuda(), target3.cuda()\n        outputs1, outputs2, outputs3 = model(data)\n\n        loss1 = criterion(outputs1, target1)\n        loss2 = criterion(outputs2, target2)\n        loss3 = criterion(outputs3, target3)\n        total_loss = loss1 + loss2 + loss3\n    \n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        # scheduler.step()\n\n        if (batch_idx+1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(dataloader)}], Total Loss: {total_loss.item():.4f}')\n# winsound.Beep(440, 500)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T02:38:48.641954Z","iopub.execute_input":"2024-04-04T02:38:48.643021Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/100], Step [10/760], Total Loss: 4.8308\nEpoch [1/100], Step [20/760], Total Loss: 4.7618\nEpoch [1/100], Step [30/760], Total Loss: 4.6770\nEpoch [1/100], Step [40/760], Total Loss: 4.5977\nEpoch [1/100], Step [50/760], Total Loss: 4.6209\nEpoch [1/100], Step [60/760], Total Loss: 4.5580\nEpoch [1/100], Step [70/760], Total Loss: 4.5208\nEpoch [1/100], Step [80/760], Total Loss: 4.5350\nEpoch [1/100], Step [90/760], Total Loss: 4.5219\nEpoch [1/100], Step [100/760], Total Loss: 4.4654\nEpoch [1/100], Step [110/760], Total Loss: 4.5502\nEpoch [1/100], Step [120/760], Total Loss: 4.5031\nEpoch [1/100], Step [130/760], Total Loss: 4.4577\nEpoch [1/100], Step [140/760], Total Loss: 4.5011\nEpoch [1/100], Step [150/760], Total Loss: 4.4438\nEpoch [1/100], Step [160/760], Total Loss: 4.4451\nEpoch [1/100], Step [170/760], Total Loss: 4.5107\nEpoch [1/100], Step [180/760], Total Loss: 4.4828\nEpoch [1/100], Step [190/760], Total Loss: 4.5462\nEpoch [1/100], Step [200/760], Total Loss: 4.5136\nEpoch [1/100], Step [210/760], Total Loss: 4.4374\nEpoch [1/100], Step [220/760], Total Loss: 4.4230\nEpoch [1/100], Step [230/760], Total Loss: 4.4272\nEpoch [1/100], Step [240/760], Total Loss: 4.3398\nEpoch [1/100], Step [250/760], Total Loss: 4.4500\nEpoch [1/100], Step [260/760], Total Loss: 4.3925\nEpoch [1/100], Step [270/760], Total Loss: 4.3698\nEpoch [1/100], Step [280/760], Total Loss: 4.3739\nEpoch [1/100], Step [290/760], Total Loss: 4.4061\nEpoch [1/100], Step [300/760], Total Loss: 4.4185\nEpoch [1/100], Step [310/760], Total Loss: 4.4001\nEpoch [1/100], Step [320/760], Total Loss: 4.3323\nEpoch [1/100], Step [330/760], Total Loss: 4.2742\nEpoch [1/100], Step [340/760], Total Loss: 4.2998\nEpoch [1/100], Step [350/760], Total Loss: 4.3133\nEpoch [1/100], Step [360/760], Total Loss: 4.2307\nEpoch [1/100], Step [370/760], Total Loss: 4.2532\nEpoch [1/100], Step [380/760], Total Loss: 4.2864\nEpoch [1/100], Step [390/760], Total Loss: 4.2370\nEpoch [1/100], Step [400/760], Total Loss: 4.2644\nEpoch [1/100], Step [410/760], Total Loss: 4.3286\nEpoch [1/100], Step [420/760], Total Loss: 4.2702\nEpoch [1/100], Step [430/760], Total Loss: 4.3275\nEpoch [1/100], Step [440/760], Total Loss: 4.1678\nEpoch [1/100], Step [450/760], Total Loss: 4.3060\nEpoch [1/100], Step [460/760], Total Loss: 4.2043\nEpoch [1/100], Step [470/760], Total Loss: 4.2371\nEpoch [1/100], Step [480/760], Total Loss: 4.1657\nEpoch [1/100], Step [490/760], Total Loss: 4.1601\nEpoch [1/100], Step [500/760], Total Loss: 4.2231\nEpoch [1/100], Step [510/760], Total Loss: 4.2023\nEpoch [1/100], Step [520/760], Total Loss: 4.1530\nEpoch [1/100], Step [530/760], Total Loss: 4.2154\nEpoch [1/100], Step [540/760], Total Loss: 4.2154\nEpoch [1/100], Step [550/760], Total Loss: 4.2432\nEpoch [1/100], Step [560/760], Total Loss: 4.0505\nEpoch [1/100], Step [570/760], Total Loss: 4.2103\nEpoch [1/100], Step [580/760], Total Loss: 4.2230\nEpoch [1/100], Step [590/760], Total Loss: 4.2337\nEpoch [1/100], Step [600/760], Total Loss: 4.0954\nEpoch [1/100], Step [610/760], Total Loss: 4.1244\nEpoch [1/100], Step [620/760], Total Loss: 4.1357\nEpoch [1/100], Step [630/760], Total Loss: 4.2413\nEpoch [1/100], Step [640/760], Total Loss: 4.1594\nEpoch [1/100], Step [650/760], Total Loss: 4.1711\nEpoch [1/100], Step [660/760], Total Loss: 4.1968\nEpoch [1/100], Step [670/760], Total Loss: 4.0921\nEpoch [1/100], Step [680/760], Total Loss: 4.2120\nEpoch [1/100], Step [690/760], Total Loss: 4.2032\nEpoch [1/100], Step [700/760], Total Loss: 4.1807\nEpoch [1/100], Step [710/760], Total Loss: 4.1598\nEpoch [1/100], Step [720/760], Total Loss: 4.1150\nEpoch [1/100], Step [730/760], Total Loss: 4.2199\nEpoch [1/100], Step [740/760], Total Loss: 4.1884\nEpoch [1/100], Step [750/760], Total Loss: 4.1410\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 1/100 [02:21<3:53:12, 141.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/100], Step [760/760], Total Loss: 4.1599\nEpoch [2/100], Step [10/760], Total Loss: 4.2404\nEpoch [2/100], Step [20/760], Total Loss: 4.2083\nEpoch [2/100], Step [30/760], Total Loss: 4.0684\nEpoch [2/100], Step [40/760], Total Loss: 4.0677\nEpoch [2/100], Step [50/760], Total Loss: 4.1473\nEpoch [2/100], Step [60/760], Total Loss: 4.1022\nEpoch [2/100], Step [70/760], Total Loss: 4.1603\nEpoch [2/100], Step [80/760], Total Loss: 4.2534\nEpoch [2/100], Step [90/760], Total Loss: 4.1650\nEpoch [2/100], Step [100/760], Total Loss: 4.1143\nEpoch [2/100], Step [110/760], Total Loss: 4.0847\nEpoch [2/100], Step [120/760], Total Loss: 4.1750\nEpoch [2/100], Step [130/760], Total Loss: 4.1325\nEpoch [2/100], Step [140/760], Total Loss: 4.2004\nEpoch [2/100], Step [150/760], Total Loss: 4.1997\nEpoch [2/100], Step [160/760], Total Loss: 4.1348\nEpoch [2/100], Step [170/760], Total Loss: 4.1769\nEpoch [2/100], Step [180/760], Total Loss: 4.1071\nEpoch [2/100], Step [190/760], Total Loss: 4.1206\nEpoch [2/100], Step [200/760], Total Loss: 4.0914\nEpoch [2/100], Step [210/760], Total Loss: 4.1372\nEpoch [2/100], Step [220/760], Total Loss: 4.0477\nEpoch [2/100], Step [230/760], Total Loss: 4.1953\nEpoch [2/100], Step [240/760], Total Loss: 4.2211\nEpoch [2/100], Step [250/760], Total Loss: 3.9892\nEpoch [2/100], Step [260/760], Total Loss: 4.0393\nEpoch [2/100], Step [270/760], Total Loss: 4.1772\nEpoch [2/100], Step [280/760], Total Loss: 4.1211\nEpoch [2/100], Step [290/760], Total Loss: 4.1486\nEpoch [2/100], Step [300/760], Total Loss: 4.1929\nEpoch [2/100], Step [310/760], Total Loss: 4.1684\nEpoch [2/100], Step [320/760], Total Loss: 4.0460\nEpoch [2/100], Step [330/760], Total Loss: 4.0410\nEpoch [2/100], Step [340/760], Total Loss: 4.0894\nEpoch [2/100], Step [350/760], Total Loss: 4.1774\nEpoch [2/100], Step [360/760], Total Loss: 4.1656\nEpoch [2/100], Step [370/760], Total Loss: 4.0645\nEpoch [2/100], Step [380/760], Total Loss: 4.0713\nEpoch [2/100], Step [390/760], Total Loss: 4.1219\nEpoch [2/100], Step [400/760], Total Loss: 4.0463\nEpoch [2/100], Step [410/760], Total Loss: 4.0971\nEpoch [2/100], Step [420/760], Total Loss: 4.1128\nEpoch [2/100], Step [430/760], Total Loss: 4.1577\nEpoch [2/100], Step [440/760], Total Loss: 4.0851\nEpoch [2/100], Step [450/760], Total Loss: 4.0461\nEpoch [2/100], Step [460/760], Total Loss: 4.0427\nEpoch [2/100], Step [470/760], Total Loss: 4.0932\nEpoch [2/100], Step [480/760], Total Loss: 4.0920\nEpoch [2/100], Step [490/760], Total Loss: 4.0040\nEpoch [2/100], Step [500/760], Total Loss: 4.0511\nEpoch [2/100], Step [510/760], Total Loss: 4.0193\nEpoch [2/100], Step [520/760], Total Loss: 4.1015\nEpoch [2/100], Step [530/760], Total Loss: 4.1816\nEpoch [2/100], Step [540/760], Total Loss: 4.0721\nEpoch [2/100], Step [550/760], Total Loss: 4.0980\nEpoch [2/100], Step [560/760], Total Loss: 4.0279\nEpoch [2/100], Step [570/760], Total Loss: 3.9817\nEpoch [2/100], Step [580/760], Total Loss: 4.1468\nEpoch [2/100], Step [590/760], Total Loss: 4.1523\nEpoch [2/100], Step [600/760], Total Loss: 4.0888\nEpoch [2/100], Step [610/760], Total Loss: 4.1120\nEpoch [2/100], Step [620/760], Total Loss: 4.0812\nEpoch [2/100], Step [630/760], Total Loss: 4.1389\nEpoch [2/100], Step [640/760], Total Loss: 4.1201\nEpoch [2/100], Step [650/760], Total Loss: 4.2204\nEpoch [2/100], Step [660/760], Total Loss: 4.1289\nEpoch [2/100], Step [670/760], Total Loss: 4.1175\nEpoch [2/100], Step [680/760], Total Loss: 4.1683\nEpoch [2/100], Step [690/760], Total Loss: 4.0581\nEpoch [2/100], Step [700/760], Total Loss: 4.0287\nEpoch [2/100], Step [710/760], Total Loss: 4.1415\nEpoch [2/100], Step [720/760], Total Loss: 3.9771\nEpoch [2/100], Step [730/760], Total Loss: 4.1024\nEpoch [2/100], Step [740/760], Total Loss: 4.0887\nEpoch [2/100], Step [750/760], Total Loss: 3.9903\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 2/100 [04:41<3:49:42, 140.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/100], Step [760/760], Total Loss: 4.2031\nEpoch [3/100], Step [10/760], Total Loss: 4.0864\nEpoch [3/100], Step [20/760], Total Loss: 4.0653\nEpoch [3/100], Step [30/760], Total Loss: 4.0210\nEpoch [3/100], Step [40/760], Total Loss: 4.0816\nEpoch [3/100], Step [50/760], Total Loss: 4.0247\nEpoch [3/100], Step [60/760], Total Loss: 4.0367\nEpoch [3/100], Step [70/760], Total Loss: 4.1199\nEpoch [3/100], Step [80/760], Total Loss: 3.9738\nEpoch [3/100], Step [90/760], Total Loss: 4.1150\nEpoch [3/100], Step [100/760], Total Loss: 3.9908\nEpoch [3/100], Step [110/760], Total Loss: 4.0469\nEpoch [3/100], Step [120/760], Total Loss: 4.1471\nEpoch [3/100], Step [130/760], Total Loss: 4.0749\nEpoch [3/100], Step [140/760], Total Loss: 4.0909\nEpoch [3/100], Step [150/760], Total Loss: 4.0364\nEpoch [3/100], Step [160/760], Total Loss: 4.0370\nEpoch [3/100], Step [170/760], Total Loss: 4.0602\nEpoch [3/100], Step [180/760], Total Loss: 4.1155\nEpoch [3/100], Step [190/760], Total Loss: 4.1130\nEpoch [3/100], Step [200/760], Total Loss: 4.1526\nEpoch [3/100], Step [210/760], Total Loss: 3.9960\nEpoch [3/100], Step [220/760], Total Loss: 4.0557\nEpoch [3/100], Step [230/760], Total Loss: 3.9879\nEpoch [3/100], Step [240/760], Total Loss: 4.0453\nEpoch [3/100], Step [250/760], Total Loss: 4.1410\nEpoch [3/100], Step [260/760], Total Loss: 4.0783\nEpoch [3/100], Step [270/760], Total Loss: 4.0848\nEpoch [3/100], Step [280/760], Total Loss: 4.0608\nEpoch [3/100], Step [290/760], Total Loss: 4.0962\nEpoch [3/100], Step [300/760], Total Loss: 4.0282\nEpoch [3/100], Step [310/760], Total Loss: 3.9444\nEpoch [3/100], Step [320/760], Total Loss: 3.9555\nEpoch [3/100], Step [330/760], Total Loss: 4.0689\nEpoch [3/100], Step [340/760], Total Loss: 3.9950\nEpoch [3/100], Step [350/760], Total Loss: 4.0664\nEpoch [3/100], Step [360/760], Total Loss: 3.9753\nEpoch [3/100], Step [370/760], Total Loss: 4.0130\nEpoch [3/100], Step [380/760], Total Loss: 4.0251\nEpoch [3/100], Step [390/760], Total Loss: 4.0812\nEpoch [3/100], Step [400/760], Total Loss: 4.0483\nEpoch [3/100], Step [410/760], Total Loss: 3.9773\nEpoch [3/100], Step [420/760], Total Loss: 3.9533\nEpoch [3/100], Step [430/760], Total Loss: 4.0037\nEpoch [3/100], Step [440/760], Total Loss: 4.0719\nEpoch [3/100], Step [450/760], Total Loss: 3.9577\nEpoch [3/100], Step [460/760], Total Loss: 4.1514\nEpoch [3/100], Step [470/760], Total Loss: 4.0047\nEpoch [3/100], Step [480/760], Total Loss: 4.0300\nEpoch [3/100], Step [490/760], Total Loss: 4.0545\nEpoch [3/100], Step [500/760], Total Loss: 4.0126\nEpoch [3/100], Step [510/760], Total Loss: 4.0002\nEpoch [3/100], Step [520/760], Total Loss: 4.0643\nEpoch [3/100], Step [530/760], Total Loss: 3.9700\nEpoch [3/100], Step [540/760], Total Loss: 4.0786\nEpoch [3/100], Step [550/760], Total Loss: 4.0273\nEpoch [3/100], Step [560/760], Total Loss: 4.1023\nEpoch [3/100], Step [570/760], Total Loss: 3.9623\nEpoch [3/100], Step [580/760], Total Loss: 4.0543\nEpoch [3/100], Step [590/760], Total Loss: 3.9314\nEpoch [3/100], Step [600/760], Total Loss: 4.0211\nEpoch [3/100], Step [610/760], Total Loss: 4.0721\nEpoch [3/100], Step [620/760], Total Loss: 4.0085\nEpoch [3/100], Step [630/760], Total Loss: 4.0434\nEpoch [3/100], Step [640/760], Total Loss: 4.0170\nEpoch [3/100], Step [650/760], Total Loss: 4.0637\nEpoch [3/100], Step [660/760], Total Loss: 3.9894\nEpoch [3/100], Step [670/760], Total Loss: 3.9466\nEpoch [3/100], Step [680/760], Total Loss: 3.8941\nEpoch [3/100], Step [690/760], Total Loss: 3.8903\nEpoch [3/100], Step [700/760], Total Loss: 4.0564\nEpoch [3/100], Step [710/760], Total Loss: 3.9700\nEpoch [3/100], Step [720/760], Total Loss: 4.0698\nEpoch [3/100], Step [730/760], Total Loss: 3.8504\nEpoch [3/100], Step [740/760], Total Loss: 4.0048\nEpoch [3/100], Step [750/760], Total Loss: 3.9930\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 3/100 [07:01<3:46:59, 140.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [3/100], Step [760/760], Total Loss: 3.8398\nEpoch [4/100], Step [10/760], Total Loss: 3.9885\nEpoch [4/100], Step [20/760], Total Loss: 3.9682\nEpoch [4/100], Step [30/760], Total Loss: 4.0135\nEpoch [4/100], Step [40/760], Total Loss: 3.9115\nEpoch [4/100], Step [50/760], Total Loss: 4.1445\nEpoch [4/100], Step [60/760], Total Loss: 3.9683\nEpoch [4/100], Step [70/760], Total Loss: 4.0395\nEpoch [4/100], Step [80/760], Total Loss: 3.9401\nEpoch [4/100], Step [90/760], Total Loss: 3.9375\nEpoch [4/100], Step [100/760], Total Loss: 4.0284\nEpoch [4/100], Step [110/760], Total Loss: 4.0033\nEpoch [4/100], Step [120/760], Total Loss: 3.9476\nEpoch [4/100], Step [130/760], Total Loss: 4.0135\nEpoch [4/100], Step [140/760], Total Loss: 4.0616\nEpoch [4/100], Step [150/760], Total Loss: 3.9579\nEpoch [4/100], Step [160/760], Total Loss: 4.0515\nEpoch [4/100], Step [170/760], Total Loss: 4.0784\nEpoch [4/100], Step [180/760], Total Loss: 4.1181\nEpoch [4/100], Step [190/760], Total Loss: 4.0523\nEpoch [4/100], Step [200/760], Total Loss: 3.9405\nEpoch [4/100], Step [210/760], Total Loss: 4.0300\nEpoch [4/100], Step [220/760], Total Loss: 3.8856\nEpoch [4/100], Step [230/760], Total Loss: 4.0117\nEpoch [4/100], Step [240/760], Total Loss: 3.9222\nEpoch [4/100], Step [250/760], Total Loss: 3.9451\nEpoch [4/100], Step [260/760], Total Loss: 3.9428\nEpoch [4/100], Step [270/760], Total Loss: 3.9908\nEpoch [4/100], Step [280/760], Total Loss: 4.0079\nEpoch [4/100], Step [290/760], Total Loss: 3.9432\nEpoch [4/100], Step [300/760], Total Loss: 3.9856\nEpoch [4/100], Step [310/760], Total Loss: 3.9355\nEpoch [4/100], Step [320/760], Total Loss: 3.7968\nEpoch [4/100], Step [330/760], Total Loss: 4.0711\nEpoch [4/100], Step [340/760], Total Loss: 3.9434\nEpoch [4/100], Step [350/760], Total Loss: 4.0075\nEpoch [4/100], Step [360/760], Total Loss: 3.9472\nEpoch [4/100], Step [370/760], Total Loss: 3.9094\nEpoch [4/100], Step [380/760], Total Loss: 4.0924\nEpoch [4/100], Step [390/760], Total Loss: 4.0107\nEpoch [4/100], Step [400/760], Total Loss: 4.0840\nEpoch [4/100], Step [410/760], Total Loss: 3.8456\nEpoch [4/100], Step [420/760], Total Loss: 4.0619\nEpoch [4/100], Step [430/760], Total Loss: 3.9462\nEpoch [4/100], Step [440/760], Total Loss: 3.9841\nEpoch [4/100], Step [450/760], Total Loss: 3.9989\nEpoch [4/100], Step [460/760], Total Loss: 3.9231\nEpoch [4/100], Step [470/760], Total Loss: 3.9927\nEpoch [4/100], Step [480/760], Total Loss: 4.0318\nEpoch [4/100], Step [490/760], Total Loss: 3.8119\nEpoch [4/100], Step [500/760], Total Loss: 3.9990\nEpoch [4/100], Step [510/760], Total Loss: 3.8981\nEpoch [4/100], Step [520/760], Total Loss: 4.0098\nEpoch [4/100], Step [530/760], Total Loss: 3.9436\nEpoch [4/100], Step [540/760], Total Loss: 3.9158\nEpoch [4/100], Step [550/760], Total Loss: 3.9836\nEpoch [4/100], Step [560/760], Total Loss: 3.9112\nEpoch [4/100], Step [570/760], Total Loss: 4.0421\nEpoch [4/100], Step [580/760], Total Loss: 3.9668\nEpoch [4/100], Step [590/760], Total Loss: 4.0230\nEpoch [4/100], Step [600/760], Total Loss: 3.9576\nEpoch [4/100], Step [610/760], Total Loss: 3.9635\nEpoch [4/100], Step [620/760], Total Loss: 3.9383\nEpoch [4/100], Step [630/760], Total Loss: 3.9290\nEpoch [4/100], Step [640/760], Total Loss: 4.0681\nEpoch [4/100], Step [650/760], Total Loss: 3.9683\nEpoch [4/100], Step [660/760], Total Loss: 3.9258\nEpoch [4/100], Step [670/760], Total Loss: 3.9765\nEpoch [4/100], Step [680/760], Total Loss: 3.9573\nEpoch [4/100], Step [690/760], Total Loss: 3.9128\nEpoch [4/100], Step [700/760], Total Loss: 3.8523\nEpoch [4/100], Step [710/760], Total Loss: 3.9872\nEpoch [4/100], Step [720/760], Total Loss: 3.9226\nEpoch [4/100], Step [730/760], Total Loss: 3.9154\nEpoch [4/100], Step [740/760], Total Loss: 3.9417\nEpoch [4/100], Step [750/760], Total Loss: 3.8982\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 4/100 [09:21<3:44:27, 140.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [4/100], Step [760/760], Total Loss: 4.1146\nEpoch [5/100], Step [10/760], Total Loss: 3.9048\nEpoch [5/100], Step [20/760], Total Loss: 3.7420\nEpoch [5/100], Step [30/760], Total Loss: 4.0599\nEpoch [5/100], Step [40/760], Total Loss: 3.8909\nEpoch [5/100], Step [50/760], Total Loss: 3.8335\nEpoch [5/100], Step [60/760], Total Loss: 3.8944\nEpoch [5/100], Step [70/760], Total Loss: 3.9293\nEpoch [5/100], Step [80/760], Total Loss: 3.9570\nEpoch [5/100], Step [90/760], Total Loss: 3.9129\nEpoch [5/100], Step [100/760], Total Loss: 3.9497\nEpoch [5/100], Step [110/760], Total Loss: 3.8717\nEpoch [5/100], Step [120/760], Total Loss: 3.9311\nEpoch [5/100], Step [130/760], Total Loss: 3.8957\nEpoch [5/100], Step [140/760], Total Loss: 3.8800\nEpoch [5/100], Step [150/760], Total Loss: 4.0063\nEpoch [5/100], Step [160/760], Total Loss: 3.9382\nEpoch [5/100], Step [170/760], Total Loss: 3.8645\nEpoch [5/100], Step [180/760], Total Loss: 3.8697\nEpoch [5/100], Step [190/760], Total Loss: 3.9353\nEpoch [5/100], Step [200/760], Total Loss: 3.8886\nEpoch [5/100], Step [210/760], Total Loss: 3.9509\nEpoch [5/100], Step [220/760], Total Loss: 3.9160\nEpoch [5/100], Step [230/760], Total Loss: 3.9494\nEpoch [5/100], Step [240/760], Total Loss: 3.9017\nEpoch [5/100], Step [250/760], Total Loss: 3.7413\nEpoch [5/100], Step [260/760], Total Loss: 3.8983\nEpoch [5/100], Step [270/760], Total Loss: 4.0278\nEpoch [5/100], Step [280/760], Total Loss: 3.8321\nEpoch [5/100], Step [290/760], Total Loss: 3.9442\nEpoch [5/100], Step [300/760], Total Loss: 3.8565\nEpoch [5/100], Step [310/760], Total Loss: 3.8581\nEpoch [5/100], Step [320/760], Total Loss: 4.0140\nEpoch [5/100], Step [330/760], Total Loss: 3.9185\nEpoch [5/100], Step [340/760], Total Loss: 3.8587\nEpoch [5/100], Step [350/760], Total Loss: 3.8683\nEpoch [5/100], Step [360/760], Total Loss: 4.0605\nEpoch [5/100], Step [370/760], Total Loss: 3.9899\nEpoch [5/100], Step [380/760], Total Loss: 3.9130\nEpoch [5/100], Step [390/760], Total Loss: 3.9573\nEpoch [5/100], Step [400/760], Total Loss: 3.8539\nEpoch [5/100], Step [410/760], Total Loss: 3.8948\nEpoch [5/100], Step [420/760], Total Loss: 3.9069\nEpoch [5/100], Step [430/760], Total Loss: 3.7809\nEpoch [5/100], Step [440/760], Total Loss: 3.8990\nEpoch [5/100], Step [450/760], Total Loss: 3.9388\nEpoch [5/100], Step [460/760], Total Loss: 3.8273\nEpoch [5/100], Step [470/760], Total Loss: 3.8778\nEpoch [5/100], Step [480/760], Total Loss: 3.9008\nEpoch [5/100], Step [490/760], Total Loss: 3.9736\nEpoch [5/100], Step [500/760], Total Loss: 3.9523\nEpoch [5/100], Step [510/760], Total Loss: 3.8979\nEpoch [5/100], Step [520/760], Total Loss: 3.9224\nEpoch [5/100], Step [530/760], Total Loss: 3.8985\nEpoch [5/100], Step [540/760], Total Loss: 4.0018\nEpoch [5/100], Step [550/760], Total Loss: 3.8444\nEpoch [5/100], Step [560/760], Total Loss: 4.0153\nEpoch [5/100], Step [570/760], Total Loss: 3.9041\nEpoch [5/100], Step [580/760], Total Loss: 3.8854\nEpoch [5/100], Step [590/760], Total Loss: 3.8687\nEpoch [5/100], Step [600/760], Total Loss: 3.9022\nEpoch [5/100], Step [610/760], Total Loss: 3.8892\nEpoch [5/100], Step [620/760], Total Loss: 3.8411\nEpoch [5/100], Step [630/760], Total Loss: 3.9742\nEpoch [5/100], Step [640/760], Total Loss: 3.9123\nEpoch [5/100], Step [650/760], Total Loss: 3.9643\nEpoch [5/100], Step [660/760], Total Loss: 3.7898\nEpoch [5/100], Step [670/760], Total Loss: 3.8585\nEpoch [5/100], Step [680/760], Total Loss: 3.8636\nEpoch [5/100], Step [690/760], Total Loss: 3.9411\nEpoch [5/100], Step [700/760], Total Loss: 3.9468\nEpoch [5/100], Step [710/760], Total Loss: 3.9373\nEpoch [5/100], Step [720/760], Total Loss: 3.8699\nEpoch [5/100], Step [730/760], Total Loss: 3.8720\nEpoch [5/100], Step [740/760], Total Loss: 3.8638\nEpoch [5/100], Step [750/760], Total Loss: 3.8173\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 5/100 [11:41<3:42:00, 140.22s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [5/100], Step [760/760], Total Loss: 4.0202\nEpoch [6/100], Step [10/760], Total Loss: 3.8880\nEpoch [6/100], Step [20/760], Total Loss: 3.9618\nEpoch [6/100], Step [30/760], Total Loss: 3.9981\nEpoch [6/100], Step [40/760], Total Loss: 3.8531\nEpoch [6/100], Step [50/760], Total Loss: 3.9083\nEpoch [6/100], Step [60/760], Total Loss: 3.8640\nEpoch [6/100], Step [70/760], Total Loss: 3.8410\nEpoch [6/100], Step [80/760], Total Loss: 3.7876\nEpoch [6/100], Step [90/760], Total Loss: 3.8988\nEpoch [6/100], Step [100/760], Total Loss: 4.1139\nEpoch [6/100], Step [110/760], Total Loss: 3.9205\nEpoch [6/100], Step [120/760], Total Loss: 3.8390\nEpoch [6/100], Step [130/760], Total Loss: 3.9228\nEpoch [6/100], Step [140/760], Total Loss: 3.8981\nEpoch [6/100], Step [150/760], Total Loss: 3.9033\nEpoch [6/100], Step [160/760], Total Loss: 3.9207\nEpoch [6/100], Step [170/760], Total Loss: 3.9076\nEpoch [6/100], Step [180/760], Total Loss: 3.9392\nEpoch [6/100], Step [190/760], Total Loss: 3.8273\nEpoch [6/100], Step [200/760], Total Loss: 3.9495\nEpoch [6/100], Step [210/760], Total Loss: 3.9023\nEpoch [6/100], Step [220/760], Total Loss: 3.8894\nEpoch [6/100], Step [230/760], Total Loss: 3.8370\nEpoch [6/100], Step [240/760], Total Loss: 3.8926\nEpoch [6/100], Step [250/760], Total Loss: 3.8019\nEpoch [6/100], Step [260/760], Total Loss: 3.9314\nEpoch [6/100], Step [270/760], Total Loss: 3.9097\nEpoch [6/100], Step [280/760], Total Loss: 3.7849\nEpoch [6/100], Step [290/760], Total Loss: 3.8567\nEpoch [6/100], Step [300/760], Total Loss: 3.7368\nEpoch [6/100], Step [310/760], Total Loss: 3.9054\nEpoch [6/100], Step [320/760], Total Loss: 3.9702\nEpoch [6/100], Step [330/760], Total Loss: 3.8820\nEpoch [6/100], Step [340/760], Total Loss: 3.8169\nEpoch [6/100], Step [350/760], Total Loss: 3.9412\nEpoch [6/100], Step [360/760], Total Loss: 3.7731\nEpoch [6/100], Step [370/760], Total Loss: 3.8625\nEpoch [6/100], Step [380/760], Total Loss: 3.8774\nEpoch [6/100], Step [390/760], Total Loss: 3.8674\nEpoch [6/100], Step [400/760], Total Loss: 3.9317\nEpoch [6/100], Step [410/760], Total Loss: 3.9609\nEpoch [6/100], Step [420/760], Total Loss: 3.8183\nEpoch [6/100], Step [430/760], Total Loss: 3.8425\nEpoch [6/100], Step [440/760], Total Loss: 3.8459\nEpoch [6/100], Step [450/760], Total Loss: 4.0111\nEpoch [6/100], Step [460/760], Total Loss: 3.8809\nEpoch [6/100], Step [470/760], Total Loss: 3.8111\nEpoch [6/100], Step [480/760], Total Loss: 3.8446\nEpoch [6/100], Step [490/760], Total Loss: 3.8872\nEpoch [6/100], Step [500/760], Total Loss: 3.8216\nEpoch [6/100], Step [510/760], Total Loss: 3.8790\nEpoch [6/100], Step [520/760], Total Loss: 3.8915\nEpoch [6/100], Step [530/760], Total Loss: 3.8898\nEpoch [6/100], Step [540/760], Total Loss: 3.8809\nEpoch [6/100], Step [550/760], Total Loss: 3.8562\nEpoch [6/100], Step [560/760], Total Loss: 3.8866\nEpoch [6/100], Step [570/760], Total Loss: 3.8077\nEpoch [6/100], Step [580/760], Total Loss: 3.9641\nEpoch [6/100], Step [590/760], Total Loss: 3.9077\nEpoch [6/100], Step [600/760], Total Loss: 3.6847\nEpoch [6/100], Step [610/760], Total Loss: 3.8958\nEpoch [6/100], Step [620/760], Total Loss: 3.8452\nEpoch [6/100], Step [630/760], Total Loss: 3.8837\nEpoch [6/100], Step [640/760], Total Loss: 3.8102\nEpoch [6/100], Step [650/760], Total Loss: 3.8049\nEpoch [6/100], Step [660/760], Total Loss: 3.8619\nEpoch [6/100], Step [670/760], Total Loss: 3.8456\nEpoch [6/100], Step [680/760], Total Loss: 3.8622\nEpoch [6/100], Step [690/760], Total Loss: 3.9166\nEpoch [6/100], Step [700/760], Total Loss: 3.8349\nEpoch [6/100], Step [710/760], Total Loss: 3.8770\nEpoch [6/100], Step [720/760], Total Loss: 3.8502\nEpoch [6/100], Step [730/760], Total Loss: 3.8897\nEpoch [6/100], Step [740/760], Total Loss: 3.8794\nEpoch [6/100], Step [750/760], Total Loss: 3.8240\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 6/100 [14:01<3:39:36, 140.18s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [6/100], Step [760/760], Total Loss: 3.9556\nEpoch [7/100], Step [10/760], Total Loss: 3.8480\nEpoch [7/100], Step [20/760], Total Loss: 3.8741\nEpoch [7/100], Step [30/760], Total Loss: 3.9596\nEpoch [7/100], Step [40/760], Total Loss: 3.8723\nEpoch [7/100], Step [50/760], Total Loss: 3.7336\nEpoch [7/100], Step [60/760], Total Loss: 3.8515\nEpoch [7/100], Step [70/760], Total Loss: 3.8601\nEpoch [7/100], Step [80/760], Total Loss: 3.9420\nEpoch [7/100], Step [90/760], Total Loss: 3.7250\nEpoch [7/100], Step [100/760], Total Loss: 3.8466\nEpoch [7/100], Step [110/760], Total Loss: 3.8999\nEpoch [7/100], Step [120/760], Total Loss: 3.8550\nEpoch [7/100], Step [130/760], Total Loss: 3.7566\nEpoch [7/100], Step [140/760], Total Loss: 3.7167\nEpoch [7/100], Step [150/760], Total Loss: 3.8632\nEpoch [7/100], Step [160/760], Total Loss: 3.9852\nEpoch [7/100], Step [170/760], Total Loss: 3.7900\nEpoch [7/100], Step [180/760], Total Loss: 3.8527\nEpoch [7/100], Step [190/760], Total Loss: 3.7191\nEpoch [7/100], Step [200/760], Total Loss: 3.9049\nEpoch [7/100], Step [210/760], Total Loss: 3.8521\nEpoch [7/100], Step [220/760], Total Loss: 3.7930\nEpoch [7/100], Step [230/760], Total Loss: 3.8238\nEpoch [7/100], Step [240/760], Total Loss: 3.9380\nEpoch [7/100], Step [250/760], Total Loss: 3.9536\nEpoch [7/100], Step [260/760], Total Loss: 3.8048\nEpoch [7/100], Step [270/760], Total Loss: 3.7890\nEpoch [7/100], Step [280/760], Total Loss: 3.9970\nEpoch [7/100], Step [290/760], Total Loss: 3.8433\nEpoch [7/100], Step [300/760], Total Loss: 3.9368\nEpoch [7/100], Step [310/760], Total Loss: 3.8025\nEpoch [7/100], Step [320/760], Total Loss: 3.8928\nEpoch [7/100], Step [330/760], Total Loss: 3.9167\nEpoch [7/100], Step [340/760], Total Loss: 3.7728\nEpoch [7/100], Step [350/760], Total Loss: 3.7742\nEpoch [7/100], Step [360/760], Total Loss: 3.8402\nEpoch [7/100], Step [370/760], Total Loss: 3.8779\nEpoch [7/100], Step [380/760], Total Loss: 3.8370\nEpoch [7/100], Step [390/760], Total Loss: 3.8889\nEpoch [7/100], Step [400/760], Total Loss: 3.9680\nEpoch [7/100], Step [410/760], Total Loss: 3.8138\nEpoch [7/100], Step [420/760], Total Loss: 3.9696\nEpoch [7/100], Step [430/760], Total Loss: 3.7506\nEpoch [7/100], Step [440/760], Total Loss: 3.8764\nEpoch [7/100], Step [450/760], Total Loss: 3.7238\nEpoch [7/100], Step [460/760], Total Loss: 3.7881\nEpoch [7/100], Step [470/760], Total Loss: 3.8868\nEpoch [7/100], Step [480/760], Total Loss: 3.8553\nEpoch [7/100], Step [490/760], Total Loss: 3.8811\nEpoch [7/100], Step [500/760], Total Loss: 3.9206\nEpoch [7/100], Step [510/760], Total Loss: 3.7662\nEpoch [7/100], Step [520/760], Total Loss: 3.8508\nEpoch [7/100], Step [530/760], Total Loss: 3.8335\nEpoch [7/100], Step [540/760], Total Loss: 3.8918\nEpoch [7/100], Step [550/760], Total Loss: 3.8387\nEpoch [7/100], Step [560/760], Total Loss: 3.8618\nEpoch [7/100], Step [570/760], Total Loss: 3.7705\nEpoch [7/100], Step [580/760], Total Loss: 3.8119\nEpoch [7/100], Step [590/760], Total Loss: 3.7827\nEpoch [7/100], Step [600/760], Total Loss: 3.8200\nEpoch [7/100], Step [610/760], Total Loss: 3.9081\nEpoch [7/100], Step [620/760], Total Loss: 3.8083\nEpoch [7/100], Step [630/760], Total Loss: 3.8419\nEpoch [7/100], Step [640/760], Total Loss: 3.8344\nEpoch [7/100], Step [650/760], Total Loss: 3.8507\nEpoch [7/100], Step [660/760], Total Loss: 3.8535\nEpoch [7/100], Step [670/760], Total Loss: 3.9627\nEpoch [7/100], Step [680/760], Total Loss: 3.6746\nEpoch [7/100], Step [690/760], Total Loss: 3.7353\nEpoch [7/100], Step [700/760], Total Loss: 3.7738\nEpoch [7/100], Step [710/760], Total Loss: 3.8619\nEpoch [7/100], Step [720/760], Total Loss: 3.7863\nEpoch [7/100], Step [730/760], Total Loss: 3.8826\nEpoch [7/100], Step [740/760], Total Loss: 3.8440\nEpoch [7/100], Step [750/760], Total Loss: 3.8151\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 7/100 [16:22<3:37:13, 140.15s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [7/100], Step [760/760], Total Loss: 3.8670\nEpoch [8/100], Step [10/760], Total Loss: 3.9071\nEpoch [8/100], Step [20/760], Total Loss: 3.7528\nEpoch [8/100], Step [30/760], Total Loss: 3.7990\nEpoch [8/100], Step [40/760], Total Loss: 3.7918\nEpoch [8/100], Step [50/760], Total Loss: 3.7876\nEpoch [8/100], Step [60/760], Total Loss: 3.8821\nEpoch [8/100], Step [70/760], Total Loss: 3.8735\nEpoch [8/100], Step [80/760], Total Loss: 3.8159\nEpoch [8/100], Step [90/760], Total Loss: 3.7918\nEpoch [8/100], Step [100/760], Total Loss: 3.7171\nEpoch [8/100], Step [110/760], Total Loss: 3.8372\nEpoch [8/100], Step [120/760], Total Loss: 3.8111\nEpoch [8/100], Step [130/760], Total Loss: 3.8576\nEpoch [8/100], Step [140/760], Total Loss: 3.7806\nEpoch [8/100], Step [150/760], Total Loss: 3.8292\nEpoch [8/100], Step [160/760], Total Loss: 3.7458\nEpoch [8/100], Step [170/760], Total Loss: 3.8579\nEpoch [8/100], Step [180/760], Total Loss: 3.8011\nEpoch [8/100], Step [190/760], Total Loss: 3.8769\nEpoch [8/100], Step [200/760], Total Loss: 3.7050\nEpoch [8/100], Step [210/760], Total Loss: 3.8852\nEpoch [8/100], Step [220/760], Total Loss: 3.7512\nEpoch [8/100], Step [230/760], Total Loss: 3.8492\nEpoch [8/100], Step [240/760], Total Loss: 3.7968\nEpoch [8/100], Step [250/760], Total Loss: 3.8521\nEpoch [8/100], Step [260/760], Total Loss: 3.8616\nEpoch [8/100], Step [270/760], Total Loss: 3.8302\nEpoch [8/100], Step [280/760], Total Loss: 3.7775\nEpoch [8/100], Step [290/760], Total Loss: 3.8418\nEpoch [8/100], Step [300/760], Total Loss: 3.8968\nEpoch [8/100], Step [310/760], Total Loss: 3.7919\nEpoch [8/100], Step [320/760], Total Loss: 3.8361\nEpoch [8/100], Step [330/760], Total Loss: 3.8262\nEpoch [8/100], Step [340/760], Total Loss: 3.8714\nEpoch [8/100], Step [350/760], Total Loss: 3.8666\nEpoch [8/100], Step [360/760], Total Loss: 3.8533\nEpoch [8/100], Step [370/760], Total Loss: 3.7419\nEpoch [8/100], Step [380/760], Total Loss: 3.8281\nEpoch [8/100], Step [390/760], Total Loss: 3.7086\nEpoch [8/100], Step [400/760], Total Loss: 3.7085\nEpoch [8/100], Step [410/760], Total Loss: 3.7782\nEpoch [8/100], Step [420/760], Total Loss: 3.7156\nEpoch [8/100], Step [430/760], Total Loss: 3.7670\nEpoch [8/100], Step [440/760], Total Loss: 3.7685\nEpoch [8/100], Step [450/760], Total Loss: 3.6214\nEpoch [8/100], Step [460/760], Total Loss: 3.8091\nEpoch [8/100], Step [470/760], Total Loss: 3.7509\nEpoch [8/100], Step [480/760], Total Loss: 3.8936\nEpoch [8/100], Step [490/760], Total Loss: 3.7481\nEpoch [8/100], Step [500/760], Total Loss: 3.7608\nEpoch [8/100], Step [510/760], Total Loss: 3.8352\nEpoch [8/100], Step [520/760], Total Loss: 3.8066\nEpoch [8/100], Step [530/760], Total Loss: 3.7363\nEpoch [8/100], Step [540/760], Total Loss: 3.7784\nEpoch [8/100], Step [550/760], Total Loss: 3.8501\nEpoch [8/100], Step [560/760], Total Loss: 3.8819\nEpoch [8/100], Step [570/760], Total Loss: 3.7727\nEpoch [8/100], Step [580/760], Total Loss: 3.7442\nEpoch [8/100], Step [590/760], Total Loss: 3.7930\nEpoch [8/100], Step [600/760], Total Loss: 3.7034\nEpoch [8/100], Step [610/760], Total Loss: 3.8948\nEpoch [8/100], Step [620/760], Total Loss: 3.7848\nEpoch [8/100], Step [630/760], Total Loss: 3.7692\nEpoch [8/100], Step [640/760], Total Loss: 3.7011\nEpoch [8/100], Step [650/760], Total Loss: 3.8028\nEpoch [8/100], Step [660/760], Total Loss: 3.7909\nEpoch [8/100], Step [670/760], Total Loss: 3.7709\nEpoch [8/100], Step [680/760], Total Loss: 3.6943\nEpoch [8/100], Step [690/760], Total Loss: 3.8134\nEpoch [8/100], Step [700/760], Total Loss: 3.7667\nEpoch [8/100], Step [710/760], Total Loss: 3.8006\nEpoch [8/100], Step [720/760], Total Loss: 3.8192\nEpoch [8/100], Step [730/760], Total Loss: 3.7506\nEpoch [8/100], Step [740/760], Total Loss: 3.8587\nEpoch [8/100], Step [750/760], Total Loss: 3.8344\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 8/100 [18:42<3:34:51, 140.13s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [8/100], Step [760/760], Total Loss: 3.6677\nEpoch [9/100], Step [10/760], Total Loss: 3.7705\nEpoch [9/100], Step [20/760], Total Loss: 3.9719\nEpoch [9/100], Step [30/760], Total Loss: 3.7518\nEpoch [9/100], Step [40/760], Total Loss: 3.7147\nEpoch [9/100], Step [50/760], Total Loss: 3.7765\nEpoch [9/100], Step [60/760], Total Loss: 3.7727\nEpoch [9/100], Step [70/760], Total Loss: 3.7484\nEpoch [9/100], Step [80/760], Total Loss: 3.6891\nEpoch [9/100], Step [90/760], Total Loss: 3.7660\nEpoch [9/100], Step [100/760], Total Loss: 3.7064\nEpoch [9/100], Step [110/760], Total Loss: 3.7415\nEpoch [9/100], Step [120/760], Total Loss: 3.7354\nEpoch [9/100], Step [130/760], Total Loss: 3.7451\nEpoch [9/100], Step [140/760], Total Loss: 3.7792\nEpoch [9/100], Step [150/760], Total Loss: 3.6852\nEpoch [9/100], Step [160/760], Total Loss: 3.8236\nEpoch [9/100], Step [170/760], Total Loss: 3.7433\nEpoch [9/100], Step [180/760], Total Loss: 3.8504\nEpoch [9/100], Step [190/760], Total Loss: 3.6785\nEpoch [9/100], Step [200/760], Total Loss: 3.7362\nEpoch [9/100], Step [210/760], Total Loss: 3.7028\nEpoch [9/100], Step [220/760], Total Loss: 3.7353\nEpoch [9/100], Step [230/760], Total Loss: 3.6994\nEpoch [9/100], Step [240/760], Total Loss: 3.7309\nEpoch [9/100], Step [250/760], Total Loss: 3.7234\nEpoch [9/100], Step [260/760], Total Loss: 3.7654\nEpoch [9/100], Step [270/760], Total Loss: 3.8409\nEpoch [9/100], Step [280/760], Total Loss: 3.7130\nEpoch [9/100], Step [290/760], Total Loss: 3.6454\nEpoch [9/100], Step [300/760], Total Loss: 3.8348\nEpoch [9/100], Step [310/760], Total Loss: 3.6705\nEpoch [9/100], Step [320/760], Total Loss: 3.6871\nEpoch [9/100], Step [330/760], Total Loss: 3.7640\nEpoch [9/100], Step [340/760], Total Loss: 3.6156\nEpoch [9/100], Step [350/760], Total Loss: 3.7143\nEpoch [9/100], Step [360/760], Total Loss: 3.7999\nEpoch [9/100], Step [370/760], Total Loss: 3.7217\nEpoch [9/100], Step [380/760], Total Loss: 3.7519\nEpoch [9/100], Step [390/760], Total Loss: 3.6196\nEpoch [9/100], Step [400/760], Total Loss: 3.7577\nEpoch [9/100], Step [410/760], Total Loss: 3.7909\nEpoch [9/100], Step [420/760], Total Loss: 3.7419\nEpoch [9/100], Step [430/760], Total Loss: 3.7427\nEpoch [9/100], Step [440/760], Total Loss: 3.6945\nEpoch [9/100], Step [450/760], Total Loss: 3.6628\nEpoch [9/100], Step [460/760], Total Loss: 3.7124\nEpoch [9/100], Step [470/760], Total Loss: 3.7527\nEpoch [9/100], Step [480/760], Total Loss: 3.6758\nEpoch [9/100], Step [490/760], Total Loss: 3.6847\nEpoch [9/100], Step [500/760], Total Loss: 3.6638\nEpoch [9/100], Step [510/760], Total Loss: 3.6430\nEpoch [9/100], Step [520/760], Total Loss: 3.7590\nEpoch [9/100], Step [530/760], Total Loss: 3.7148\nEpoch [9/100], Step [540/760], Total Loss: 3.7116\nEpoch [9/100], Step [550/760], Total Loss: 3.6557\nEpoch [9/100], Step [560/760], Total Loss: 3.7205\nEpoch [9/100], Step [570/760], Total Loss: 3.6582\nEpoch [9/100], Step [580/760], Total Loss: 3.7912\nEpoch [9/100], Step [590/760], Total Loss: 3.8416\nEpoch [9/100], Step [600/760], Total Loss: 3.7253\nEpoch [9/100], Step [610/760], Total Loss: 3.7119\nEpoch [9/100], Step [620/760], Total Loss: 3.7074\nEpoch [9/100], Step [630/760], Total Loss: 3.6613\nEpoch [9/100], Step [640/760], Total Loss: 3.6637\nEpoch [9/100], Step [650/760], Total Loss: 3.8087\nEpoch [9/100], Step [660/760], Total Loss: 3.7342\nEpoch [9/100], Step [670/760], Total Loss: 3.6955\nEpoch [9/100], Step [680/760], Total Loss: 3.7195\nEpoch [9/100], Step [690/760], Total Loss: 3.6920\nEpoch [9/100], Step [700/760], Total Loss: 3.5931\nEpoch [9/100], Step [710/760], Total Loss: 3.7906\nEpoch [9/100], Step [720/760], Total Loss: 3.7298\nEpoch [9/100], Step [730/760], Total Loss: 3.6554\nEpoch [9/100], Step [740/760], Total Loss: 3.6814\nEpoch [9/100], Step [750/760], Total Loss: 3.6389\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 9/100 [21:02<3:32:29, 140.11s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [9/100], Step [760/760], Total Loss: 3.6895\nEpoch [10/100], Step [10/760], Total Loss: 3.7001\nEpoch [10/100], Step [20/760], Total Loss: 3.7156\nEpoch [10/100], Step [30/760], Total Loss: 3.7888\nEpoch [10/100], Step [40/760], Total Loss: 3.7045\nEpoch [10/100], Step [50/760], Total Loss: 3.6961\nEpoch [10/100], Step [60/760], Total Loss: 3.7285\nEpoch [10/100], Step [70/760], Total Loss: 3.6482\nEpoch [10/100], Step [80/760], Total Loss: 3.6392\nEpoch [10/100], Step [90/760], Total Loss: 3.6467\nEpoch [10/100], Step [100/760], Total Loss: 3.8077\nEpoch [10/100], Step [110/760], Total Loss: 3.6796\nEpoch [10/100], Step [120/760], Total Loss: 3.6828\nEpoch [10/100], Step [130/760], Total Loss: 3.6848\nEpoch [10/100], Step [140/760], Total Loss: 3.6179\nEpoch [10/100], Step [150/760], Total Loss: 3.6406\nEpoch [10/100], Step [160/760], Total Loss: 3.8023\nEpoch [10/100], Step [170/760], Total Loss: 3.6690\nEpoch [10/100], Step [180/760], Total Loss: 3.6751\nEpoch [10/100], Step [190/760], Total Loss: 3.6760\nEpoch [10/100], Step [200/760], Total Loss: 3.6874\nEpoch [10/100], Step [210/760], Total Loss: 3.6853\nEpoch [10/100], Step [220/760], Total Loss: 3.7064\nEpoch [10/100], Step [230/760], Total Loss: 3.6450\nEpoch [10/100], Step [240/760], Total Loss: 3.6423\nEpoch [10/100], Step [250/760], Total Loss: 3.7018\nEpoch [10/100], Step [260/760], Total Loss: 3.6669\nEpoch [10/100], Step [270/760], Total Loss: 3.6854\nEpoch [10/100], Step [280/760], Total Loss: 3.7187\nEpoch [10/100], Step [290/760], Total Loss: 3.5799\nEpoch [10/100], Step [300/760], Total Loss: 3.6768\nEpoch [10/100], Step [310/760], Total Loss: 3.6069\nEpoch [10/100], Step [320/760], Total Loss: 3.7097\nEpoch [10/100], Step [330/760], Total Loss: 3.7703\nEpoch [10/100], Step [340/760], Total Loss: 3.7162\nEpoch [10/100], Step [350/760], Total Loss: 3.6422\nEpoch [10/100], Step [360/760], Total Loss: 3.7566\nEpoch [10/100], Step [370/760], Total Loss: 3.5927\nEpoch [10/100], Step [380/760], Total Loss: 3.7672\nEpoch [10/100], Step [390/760], Total Loss: 3.6606\nEpoch [10/100], Step [400/760], Total Loss: 3.7211\nEpoch [10/100], Step [410/760], Total Loss: 3.6649\nEpoch [10/100], Step [420/760], Total Loss: 3.6863\nEpoch [10/100], Step [430/760], Total Loss: 3.7291\nEpoch [10/100], Step [440/760], Total Loss: 3.7624\nEpoch [10/100], Step [450/760], Total Loss: 3.6732\nEpoch [10/100], Step [460/760], Total Loss: 3.7447\nEpoch [10/100], Step [470/760], Total Loss: 3.6756\nEpoch [10/100], Step [480/760], Total Loss: 3.7240\nEpoch [10/100], Step [490/760], Total Loss: 3.7758\nEpoch [10/100], Step [500/760], Total Loss: 3.6228\nEpoch [10/100], Step [510/760], Total Loss: 3.6311\nEpoch [10/100], Step [520/760], Total Loss: 3.6701\nEpoch [10/100], Step [530/760], Total Loss: 3.6792\nEpoch [10/100], Step [540/760], Total Loss: 3.6668\nEpoch [10/100], Step [550/760], Total Loss: 3.6260\nEpoch [10/100], Step [560/760], Total Loss: 3.6702\nEpoch [10/100], Step [570/760], Total Loss: 3.7129\nEpoch [10/100], Step [580/760], Total Loss: 3.7080\nEpoch [10/100], Step [590/760], Total Loss: 3.6404\nEpoch [10/100], Step [600/760], Total Loss: 3.6968\nEpoch [10/100], Step [610/760], Total Loss: 3.5745\nEpoch [10/100], Step [620/760], Total Loss: 3.7597\nEpoch [10/100], Step [630/760], Total Loss: 3.7246\nEpoch [10/100], Step [640/760], Total Loss: 3.6492\nEpoch [10/100], Step [650/760], Total Loss: 3.7438\nEpoch [10/100], Step [660/760], Total Loss: 3.6836\nEpoch [10/100], Step [670/760], Total Loss: 3.6528\nEpoch [10/100], Step [680/760], Total Loss: 3.6170\nEpoch [10/100], Step [690/760], Total Loss: 3.6891\nEpoch [10/100], Step [700/760], Total Loss: 3.6423\nEpoch [10/100], Step [710/760], Total Loss: 3.6322\nEpoch [10/100], Step [720/760], Total Loss: 3.7508\nEpoch [10/100], Step [730/760], Total Loss: 3.7232\nEpoch [10/100], Step [740/760], Total Loss: 3.5961\nEpoch [10/100], Step [750/760], Total Loss: 3.6069\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 10/100 [23:22<3:30:08, 140.09s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/100], Step [760/760], Total Loss: 3.7299\nEpoch [11/100], Step [10/760], Total Loss: 3.7379\nEpoch [11/100], Step [20/760], Total Loss: 3.6827\nEpoch [11/100], Step [30/760], Total Loss: 3.6249\nEpoch [11/100], Step [40/760], Total Loss: 3.6061\nEpoch [11/100], Step [50/760], Total Loss: 3.6656\nEpoch [11/100], Step [60/760], Total Loss: 3.6682\nEpoch [11/100], Step [70/760], Total Loss: 3.6964\nEpoch [11/100], Step [80/760], Total Loss: 3.7055\nEpoch [11/100], Step [90/760], Total Loss: 3.6523\nEpoch [11/100], Step [100/760], Total Loss: 3.6439\nEpoch [11/100], Step [110/760], Total Loss: 3.6253\nEpoch [11/100], Step [120/760], Total Loss: 3.7495\nEpoch [11/100], Step [130/760], Total Loss: 3.6233\nEpoch [11/100], Step [140/760], Total Loss: 3.6300\nEpoch [11/100], Step [150/760], Total Loss: 3.6615\nEpoch [11/100], Step [160/760], Total Loss: 3.5889\nEpoch [11/100], Step [170/760], Total Loss: 3.7144\nEpoch [11/100], Step [180/760], Total Loss: 3.5962\nEpoch [11/100], Step [190/760], Total Loss: 3.7457\nEpoch [11/100], Step [200/760], Total Loss: 3.6658\nEpoch [11/100], Step [210/760], Total Loss: 3.5867\nEpoch [11/100], Step [220/760], Total Loss: 3.6819\nEpoch [11/100], Step [230/760], Total Loss: 3.6639\nEpoch [11/100], Step [240/760], Total Loss: 3.5919\nEpoch [11/100], Step [250/760], Total Loss: 3.6652\nEpoch [11/100], Step [260/760], Total Loss: 3.5326\nEpoch [11/100], Step [270/760], Total Loss: 3.5599\nEpoch [11/100], Step [280/760], Total Loss: 3.6785\nEpoch [11/100], Step [290/760], Total Loss: 3.6523\nEpoch [11/100], Step [300/760], Total Loss: 3.6393\nEpoch [11/100], Step [310/760], Total Loss: 3.5850\nEpoch [11/100], Step [320/760], Total Loss: 3.6542\nEpoch [11/100], Step [330/760], Total Loss: 3.6201\nEpoch [11/100], Step [340/760], Total Loss: 3.7143\nEpoch [11/100], Step [350/760], Total Loss: 3.5910\nEpoch [11/100], Step [360/760], Total Loss: 3.7442\nEpoch [11/100], Step [370/760], Total Loss: 3.6542\nEpoch [11/100], Step [380/760], Total Loss: 3.6730\nEpoch [11/100], Step [390/760], Total Loss: 3.7958\nEpoch [11/100], Step [400/760], Total Loss: 3.6338\nEpoch [11/100], Step [410/760], Total Loss: 3.5779\nEpoch [11/100], Step [420/760], Total Loss: 3.5909\nEpoch [11/100], Step [430/760], Total Loss: 3.6635\nEpoch [11/100], Step [440/760], Total Loss: 3.6315\nEpoch [11/100], Step [450/760], Total Loss: 3.6072\nEpoch [11/100], Step [460/760], Total Loss: 3.6880\nEpoch [11/100], Step [470/760], Total Loss: 3.5928\nEpoch [11/100], Step [480/760], Total Loss: 3.5960\nEpoch [11/100], Step [490/760], Total Loss: 3.5708\nEpoch [11/100], Step [500/760], Total Loss: 3.6484\nEpoch [11/100], Step [510/760], Total Loss: 3.6105\nEpoch [11/100], Step [520/760], Total Loss: 3.5308\nEpoch [11/100], Step [530/760], Total Loss: 3.6578\nEpoch [11/100], Step [540/760], Total Loss: 3.6588\nEpoch [11/100], Step [550/760], Total Loss: 3.6238\nEpoch [11/100], Step [560/760], Total Loss: 3.7006\nEpoch [11/100], Step [570/760], Total Loss: 3.6224\nEpoch [11/100], Step [580/760], Total Loss: 3.8061\nEpoch [11/100], Step [590/760], Total Loss: 3.6553\nEpoch [11/100], Step [600/760], Total Loss: 3.5718\nEpoch [11/100], Step [610/760], Total Loss: 3.6816\nEpoch [11/100], Step [620/760], Total Loss: 3.6611\nEpoch [11/100], Step [630/760], Total Loss: 3.6444\nEpoch [11/100], Step [640/760], Total Loss: 3.5144\nEpoch [11/100], Step [650/760], Total Loss: 3.5564\nEpoch [11/100], Step [660/760], Total Loss: 3.6510\nEpoch [11/100], Step [670/760], Total Loss: 3.5069\nEpoch [11/100], Step [680/760], Total Loss: 3.5529\nEpoch [11/100], Step [690/760], Total Loss: 3.6036\nEpoch [11/100], Step [700/760], Total Loss: 3.5935\nEpoch [11/100], Step [710/760], Total Loss: 3.5606\nEpoch [11/100], Step [720/760], Total Loss: 3.5911\nEpoch [11/100], Step [730/760], Total Loss: 3.6341\nEpoch [11/100], Step [740/760], Total Loss: 3.6983\nEpoch [11/100], Step [750/760], Total Loss: 3.5881\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 11/100 [25:42<3:27:46, 140.07s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [11/100], Step [760/760], Total Loss: 3.7555\nEpoch [12/100], Step [10/760], Total Loss: 3.6107\nEpoch [12/100], Step [20/760], Total Loss: 3.4737\nEpoch [12/100], Step [30/760], Total Loss: 3.5980\nEpoch [12/100], Step [40/760], Total Loss: 3.4690\nEpoch [12/100], Step [50/760], Total Loss: 3.6526\nEpoch [12/100], Step [60/760], Total Loss: 3.6353\nEpoch [12/100], Step [70/760], Total Loss: 3.6368\nEpoch [12/100], Step [80/760], Total Loss: 3.6617\nEpoch [12/100], Step [90/760], Total Loss: 3.6070\nEpoch [12/100], Step [100/760], Total Loss: 3.5879\nEpoch [12/100], Step [110/760], Total Loss: 3.5371\nEpoch [12/100], Step [120/760], Total Loss: 3.6346\nEpoch [12/100], Step [130/760], Total Loss: 3.5716\nEpoch [12/100], Step [140/760], Total Loss: 3.6537\nEpoch [12/100], Step [150/760], Total Loss: 3.6179\nEpoch [12/100], Step [160/760], Total Loss: 3.6954\nEpoch [12/100], Step [170/760], Total Loss: 3.5274\nEpoch [12/100], Step [180/760], Total Loss: 3.6494\nEpoch [12/100], Step [190/760], Total Loss: 3.6552\nEpoch [12/100], Step [200/760], Total Loss: 3.6125\nEpoch [12/100], Step [210/760], Total Loss: 3.5996\nEpoch [12/100], Step [220/760], Total Loss: 3.5579\nEpoch [12/100], Step [230/760], Total Loss: 3.5669\nEpoch [12/100], Step [240/760], Total Loss: 3.5565\nEpoch [12/100], Step [250/760], Total Loss: 3.5955\nEpoch [12/100], Step [260/760], Total Loss: 3.6204\nEpoch [12/100], Step [270/760], Total Loss: 3.6135\nEpoch [12/100], Step [280/760], Total Loss: 3.6068\nEpoch [12/100], Step [290/760], Total Loss: 3.6074\nEpoch [12/100], Step [300/760], Total Loss: 3.4849\nEpoch [12/100], Step [310/760], Total Loss: 3.5916\nEpoch [12/100], Step [320/760], Total Loss: 3.6054\nEpoch [12/100], Step [330/760], Total Loss: 3.6205\nEpoch [12/100], Step [340/760], Total Loss: 3.4916\nEpoch [12/100], Step [350/760], Total Loss: 3.6148\nEpoch [12/100], Step [360/760], Total Loss: 3.6571\nEpoch [12/100], Step [370/760], Total Loss: 3.6403\nEpoch [12/100], Step [380/760], Total Loss: 3.5377\nEpoch [12/100], Step [390/760], Total Loss: 3.5923\nEpoch [12/100], Step [400/760], Total Loss: 3.6264\nEpoch [12/100], Step [410/760], Total Loss: 3.5445\nEpoch [12/100], Step [420/760], Total Loss: 3.5526\nEpoch [12/100], Step [430/760], Total Loss: 3.5252\nEpoch [12/100], Step [440/760], Total Loss: 3.5609\nEpoch [12/100], Step [450/760], Total Loss: 3.5962\nEpoch [12/100], Step [460/760], Total Loss: 3.6590\nEpoch [12/100], Step [470/760], Total Loss: 3.6040\nEpoch [12/100], Step [480/760], Total Loss: 3.5520\nEpoch [12/100], Step [490/760], Total Loss: 3.5893\nEpoch [12/100], Step [500/760], Total Loss: 3.5951\nEpoch [12/100], Step [510/760], Total Loss: 3.6159\nEpoch [12/100], Step [520/760], Total Loss: 3.6510\nEpoch [12/100], Step [530/760], Total Loss: 3.6346\nEpoch [12/100], Step [540/760], Total Loss: 3.5071\nEpoch [12/100], Step [550/760], Total Loss: 3.6338\nEpoch [12/100], Step [560/760], Total Loss: 3.5703\nEpoch [12/100], Step [570/760], Total Loss: 3.5522\nEpoch [12/100], Step [580/760], Total Loss: 3.5440\nEpoch [12/100], Step [590/760], Total Loss: 3.6170\nEpoch [12/100], Step [600/760], Total Loss: 3.5573\nEpoch [12/100], Step [610/760], Total Loss: 3.6445\nEpoch [12/100], Step [620/760], Total Loss: 3.6570\nEpoch [12/100], Step [630/760], Total Loss: 3.5599\nEpoch [12/100], Step [640/760], Total Loss: 3.5966\nEpoch [12/100], Step [650/760], Total Loss: 3.5789\nEpoch [12/100], Step [660/760], Total Loss: 3.6414\nEpoch [12/100], Step [670/760], Total Loss: 3.5265\nEpoch [12/100], Step [680/760], Total Loss: 3.5507\nEpoch [12/100], Step [690/760], Total Loss: 3.5438\nEpoch [12/100], Step [700/760], Total Loss: 3.5442\nEpoch [12/100], Step [710/760], Total Loss: 3.5383\nEpoch [12/100], Step [720/760], Total Loss: 3.4373\nEpoch [12/100], Step [730/760], Total Loss: 3.5414\nEpoch [12/100], Step [740/760], Total Loss: 3.5464\nEpoch [12/100], Step [750/760], Total Loss: 3.6185\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 12/100 [28:02<3:25:25, 140.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [12/100], Step [760/760], Total Loss: 3.6177\nEpoch [13/100], Step [10/760], Total Loss: 3.5698\nEpoch [13/100], Step [20/760], Total Loss: 3.5337\nEpoch [13/100], Step [30/760], Total Loss: 3.5261\nEpoch [13/100], Step [40/760], Total Loss: 3.4766\nEpoch [13/100], Step [50/760], Total Loss: 3.5320\nEpoch [13/100], Step [60/760], Total Loss: 3.5204\nEpoch [13/100], Step [70/760], Total Loss: 3.5643\nEpoch [13/100], Step [80/760], Total Loss: 3.6116\nEpoch [13/100], Step [90/760], Total Loss: 3.4778\nEpoch [13/100], Step [100/760], Total Loss: 3.5647\nEpoch [13/100], Step [110/760], Total Loss: 3.6333\nEpoch [13/100], Step [120/760], Total Loss: 3.6120\nEpoch [13/100], Step [130/760], Total Loss: 3.5675\nEpoch [13/100], Step [140/760], Total Loss: 3.5912\nEpoch [13/100], Step [150/760], Total Loss: 3.5944\nEpoch [13/100], Step [160/760], Total Loss: 3.5763\nEpoch [13/100], Step [170/760], Total Loss: 3.6203\nEpoch [13/100], Step [180/760], Total Loss: 3.5376\nEpoch [13/100], Step [190/760], Total Loss: 3.5536\nEpoch [13/100], Step [200/760], Total Loss: 3.5707\nEpoch [13/100], Step [210/760], Total Loss: 3.5027\nEpoch [13/100], Step [220/760], Total Loss: 3.5653\nEpoch [13/100], Step [230/760], Total Loss: 3.5457\nEpoch [13/100], Step [240/760], Total Loss: 3.5004\nEpoch [13/100], Step [250/760], Total Loss: 3.5220\nEpoch [13/100], Step [260/760], Total Loss: 3.6519\nEpoch [13/100], Step [270/760], Total Loss: 3.6301\nEpoch [13/100], Step [280/760], Total Loss: 3.5073\nEpoch [13/100], Step [290/760], Total Loss: 3.4856\nEpoch [13/100], Step [300/760], Total Loss: 3.5864\nEpoch [13/100], Step [310/760], Total Loss: 3.5393\nEpoch [13/100], Step [320/760], Total Loss: 3.5035\nEpoch [13/100], Step [330/760], Total Loss: 3.5298\nEpoch [13/100], Step [340/760], Total Loss: 3.5415\nEpoch [13/100], Step [350/760], Total Loss: 3.5904\nEpoch [13/100], Step [360/760], Total Loss: 3.5878\nEpoch [13/100], Step [370/760], Total Loss: 3.5575\nEpoch [13/100], Step [380/760], Total Loss: 3.4375\nEpoch [13/100], Step [390/760], Total Loss: 3.5177\nEpoch [13/100], Step [400/760], Total Loss: 3.5954\nEpoch [13/100], Step [410/760], Total Loss: 3.5348\nEpoch [13/100], Step [420/760], Total Loss: 3.5636\nEpoch [13/100], Step [430/760], Total Loss: 3.5569\nEpoch [13/100], Step [440/760], Total Loss: 3.6187\nEpoch [13/100], Step [450/760], Total Loss: 3.5322\nEpoch [13/100], Step [460/760], Total Loss: 3.5688\nEpoch [13/100], Step [470/760], Total Loss: 3.5272\nEpoch [13/100], Step [480/760], Total Loss: 3.4544\nEpoch [13/100], Step [490/760], Total Loss: 3.5206\nEpoch [13/100], Step [500/760], Total Loss: 3.5947\nEpoch [13/100], Step [510/760], Total Loss: 3.5148\nEpoch [13/100], Step [520/760], Total Loss: 3.5847\nEpoch [13/100], Step [530/760], Total Loss: 3.5103\nEpoch [13/100], Step [540/760], Total Loss: 3.4902\nEpoch [13/100], Step [550/760], Total Loss: 3.5302\nEpoch [13/100], Step [560/760], Total Loss: 3.4997\nEpoch [13/100], Step [570/760], Total Loss: 3.5858\nEpoch [13/100], Step [580/760], Total Loss: 3.4525\nEpoch [13/100], Step [590/760], Total Loss: 3.4612\nEpoch [13/100], Step [600/760], Total Loss: 3.4001\nEpoch [13/100], Step [610/760], Total Loss: 3.4618\nEpoch [13/100], Step [620/760], Total Loss: 3.5688\nEpoch [13/100], Step [630/760], Total Loss: 3.4294\nEpoch [13/100], Step [640/760], Total Loss: 3.5183\nEpoch [13/100], Step [650/760], Total Loss: 3.5927\nEpoch [13/100], Step [660/760], Total Loss: 3.5001\nEpoch [13/100], Step [670/760], Total Loss: 3.5373\nEpoch [13/100], Step [680/760], Total Loss: 3.5449\nEpoch [13/100], Step [690/760], Total Loss: 3.6103\nEpoch [13/100], Step [700/760], Total Loss: 3.5025\nEpoch [13/100], Step [710/760], Total Loss: 3.5452\nEpoch [13/100], Step [720/760], Total Loss: 3.6623\nEpoch [13/100], Step [730/760], Total Loss: 3.5413\nEpoch [13/100], Step [740/760], Total Loss: 3.6269\nEpoch [13/100], Step [750/760], Total Loss: 3.5855\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 13/100 [30:22<3:23:04, 140.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [13/100], Step [760/760], Total Loss: 3.5112\nEpoch [14/100], Step [10/760], Total Loss: 3.5831\nEpoch [14/100], Step [20/760], Total Loss: 3.6015\nEpoch [14/100], Step [30/760], Total Loss: 3.4425\nEpoch [14/100], Step [40/760], Total Loss: 3.5493\nEpoch [14/100], Step [50/760], Total Loss: 3.4635\nEpoch [14/100], Step [60/760], Total Loss: 3.6271\nEpoch [14/100], Step [70/760], Total Loss: 3.5773\nEpoch [14/100], Step [80/760], Total Loss: 3.4999\nEpoch [14/100], Step [90/760], Total Loss: 3.5059\nEpoch [14/100], Step [100/760], Total Loss: 3.5078\nEpoch [14/100], Step [110/760], Total Loss: 3.5149\nEpoch [14/100], Step [120/760], Total Loss: 3.4576\nEpoch [14/100], Step [130/760], Total Loss: 3.5210\nEpoch [14/100], Step [140/760], Total Loss: 3.4711\nEpoch [14/100], Step [150/760], Total Loss: 3.4593\nEpoch [14/100], Step [160/760], Total Loss: 3.4594\nEpoch [14/100], Step [170/760], Total Loss: 3.4515\nEpoch [14/100], Step [180/760], Total Loss: 3.5298\nEpoch [14/100], Step [190/760], Total Loss: 3.4445\nEpoch [14/100], Step [200/760], Total Loss: 3.4508\nEpoch [14/100], Step [210/760], Total Loss: 3.3884\nEpoch [14/100], Step [220/760], Total Loss: 3.4283\nEpoch [14/100], Step [230/760], Total Loss: 3.4089\nEpoch [14/100], Step [240/760], Total Loss: 3.4226\nEpoch [14/100], Step [250/760], Total Loss: 3.5980\nEpoch [14/100], Step [260/760], Total Loss: 3.4386\nEpoch [14/100], Step [270/760], Total Loss: 3.4948\nEpoch [14/100], Step [280/760], Total Loss: 3.4784\nEpoch [14/100], Step [290/760], Total Loss: 3.5042\nEpoch [14/100], Step [300/760], Total Loss: 3.5564\nEpoch [14/100], Step [310/760], Total Loss: 3.5295\nEpoch [14/100], Step [320/760], Total Loss: 3.4616\nEpoch [14/100], Step [330/760], Total Loss: 3.4669\nEpoch [14/100], Step [340/760], Total Loss: 3.4916\nEpoch [14/100], Step [350/760], Total Loss: 3.5563\nEpoch [14/100], Step [360/760], Total Loss: 3.5456\nEpoch [14/100], Step [370/760], Total Loss: 3.5917\nEpoch [14/100], Step [380/760], Total Loss: 3.5552\nEpoch [14/100], Step [390/760], Total Loss: 3.5194\nEpoch [14/100], Step [400/760], Total Loss: 3.4735\nEpoch [14/100], Step [410/760], Total Loss: 3.4501\nEpoch [14/100], Step [420/760], Total Loss: 3.5382\nEpoch [14/100], Step [430/760], Total Loss: 3.4547\nEpoch [14/100], Step [440/760], Total Loss: 3.4437\nEpoch [14/100], Step [450/760], Total Loss: 3.4155\nEpoch [14/100], Step [460/760], Total Loss: 3.4574\nEpoch [14/100], Step [470/760], Total Loss: 3.5893\nEpoch [14/100], Step [480/760], Total Loss: 3.4153\nEpoch [14/100], Step [490/760], Total Loss: 3.5261\nEpoch [14/100], Step [500/760], Total Loss: 3.6458\nEpoch [14/100], Step [510/760], Total Loss: 3.4036\nEpoch [14/100], Step [520/760], Total Loss: 3.4905\nEpoch [14/100], Step [530/760], Total Loss: 3.6336\nEpoch [14/100], Step [540/760], Total Loss: 3.5691\nEpoch [14/100], Step [550/760], Total Loss: 3.5024\nEpoch [14/100], Step [560/760], Total Loss: 3.4484\nEpoch [14/100], Step [570/760], Total Loss: 3.5224\nEpoch [14/100], Step [580/760], Total Loss: 3.4963\nEpoch [14/100], Step [590/760], Total Loss: 3.4273\nEpoch [14/100], Step [600/760], Total Loss: 3.4491\nEpoch [14/100], Step [610/760], Total Loss: 3.4790\nEpoch [14/100], Step [620/760], Total Loss: 3.4681\nEpoch [14/100], Step [630/760], Total Loss: 3.5076\nEpoch [14/100], Step [640/760], Total Loss: 3.5660\nEpoch [14/100], Step [650/760], Total Loss: 3.5199\nEpoch [14/100], Step [660/760], Total Loss: 3.5565\nEpoch [14/100], Step [670/760], Total Loss: 3.4382\nEpoch [14/100], Step [680/760], Total Loss: 3.4907\nEpoch [14/100], Step [690/760], Total Loss: 3.5575\nEpoch [14/100], Step [700/760], Total Loss: 3.5031\nEpoch [14/100], Step [710/760], Total Loss: 3.6062\nEpoch [14/100], Step [720/760], Total Loss: 3.5674\nEpoch [14/100], Step [730/760], Total Loss: 3.5851\nEpoch [14/100], Step [740/760], Total Loss: 3.5285\nEpoch [14/100], Step [750/760], Total Loss: 3.4258\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 14/100 [32:42<3:20:46, 140.08s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [14/100], Step [760/760], Total Loss: 3.4923\nEpoch [15/100], Step [10/760], Total Loss: 3.5038\nEpoch [15/100], Step [20/760], Total Loss: 3.4832\nEpoch [15/100], Step [30/760], Total Loss: 3.4965\nEpoch [15/100], Step [40/760], Total Loss: 3.4505\nEpoch [15/100], Step [50/760], Total Loss: 3.5339\nEpoch [15/100], Step [60/760], Total Loss: 3.3778\nEpoch [15/100], Step [70/760], Total Loss: 3.4937\nEpoch [15/100], Step [80/760], Total Loss: 3.4709\nEpoch [15/100], Step [90/760], Total Loss: 3.4991\nEpoch [15/100], Step [100/760], Total Loss: 3.4911\nEpoch [15/100], Step [110/760], Total Loss: 3.3751\nEpoch [15/100], Step [120/760], Total Loss: 3.4214\nEpoch [15/100], Step [130/760], Total Loss: 3.4883\nEpoch [15/100], Step [140/760], Total Loss: 3.4431\nEpoch [15/100], Step [150/760], Total Loss: 3.5160\nEpoch [15/100], Step [160/760], Total Loss: 3.4606\nEpoch [15/100], Step [170/760], Total Loss: 3.4601\nEpoch [15/100], Step [180/760], Total Loss: 3.5085\nEpoch [15/100], Step [190/760], Total Loss: 3.4463\nEpoch [15/100], Step [200/760], Total Loss: 3.5755\nEpoch [15/100], Step [210/760], Total Loss: 3.4145\nEpoch [15/100], Step [220/760], Total Loss: 3.4755\nEpoch [15/100], Step [230/760], Total Loss: 3.4498\nEpoch [15/100], Step [240/760], Total Loss: 3.5300\nEpoch [15/100], Step [250/760], Total Loss: 3.5393\nEpoch [15/100], Step [260/760], Total Loss: 3.4336\nEpoch [15/100], Step [270/760], Total Loss: 3.4197\nEpoch [15/100], Step [280/760], Total Loss: 3.4691\nEpoch [15/100], Step [290/760], Total Loss: 3.5239\nEpoch [15/100], Step [300/760], Total Loss: 3.5730\nEpoch [15/100], Step [310/760], Total Loss: 3.3865\nEpoch [15/100], Step [320/760], Total Loss: 3.3768\nEpoch [15/100], Step [330/760], Total Loss: 3.3876\nEpoch [15/100], Step [340/760], Total Loss: 3.4063\nEpoch [15/100], Step [350/760], Total Loss: 3.5178\nEpoch [15/100], Step [360/760], Total Loss: 3.5209\nEpoch [15/100], Step [370/760], Total Loss: 3.4306\nEpoch [15/100], Step [380/760], Total Loss: 3.4271\nEpoch [15/100], Step [390/760], Total Loss: 3.5270\nEpoch [15/100], Step [400/760], Total Loss: 3.3869\nEpoch [15/100], Step [410/760], Total Loss: 3.4936\nEpoch [15/100], Step [420/760], Total Loss: 3.5338\nEpoch [15/100], Step [430/760], Total Loss: 3.5861\nEpoch [15/100], Step [440/760], Total Loss: 3.4408\nEpoch [15/100], Step [450/760], Total Loss: 3.4803\nEpoch [15/100], Step [460/760], Total Loss: 3.4145\nEpoch [15/100], Step [470/760], Total Loss: 3.4584\nEpoch [15/100], Step [480/760], Total Loss: 3.4723\nEpoch [15/100], Step [490/760], Total Loss: 3.5144\nEpoch [15/100], Step [500/760], Total Loss: 3.5338\nEpoch [15/100], Step [510/760], Total Loss: 3.4255\nEpoch [15/100], Step [520/760], Total Loss: 3.4739\nEpoch [15/100], Step [530/760], Total Loss: 3.4240\nEpoch [15/100], Step [540/760], Total Loss: 3.4558\nEpoch [15/100], Step [550/760], Total Loss: 3.5134\nEpoch [15/100], Step [560/760], Total Loss: 3.3157\nEpoch [15/100], Step [570/760], Total Loss: 3.4664\nEpoch [15/100], Step [580/760], Total Loss: 3.4971\nEpoch [15/100], Step [590/760], Total Loss: 3.4518\nEpoch [15/100], Step [600/760], Total Loss: 3.4164\nEpoch [15/100], Step [610/760], Total Loss: 3.4954\nEpoch [15/100], Step [620/760], Total Loss: 3.4257\nEpoch [15/100], Step [630/760], Total Loss: 3.4825\nEpoch [15/100], Step [640/760], Total Loss: 3.4890\nEpoch [15/100], Step [650/760], Total Loss: 3.5252\nEpoch [15/100], Step [660/760], Total Loss: 3.5550\nEpoch [15/100], Step [670/760], Total Loss: 3.5053\nEpoch [15/100], Step [680/760], Total Loss: 3.4412\nEpoch [15/100], Step [690/760], Total Loss: 3.4125\nEpoch [15/100], Step [700/760], Total Loss: 3.4645\nEpoch [15/100], Step [710/760], Total Loss: 3.5280\nEpoch [15/100], Step [720/760], Total Loss: 3.4754\nEpoch [15/100], Step [730/760], Total Loss: 3.4140\nEpoch [15/100], Step [740/760], Total Loss: 3.4452\nEpoch [15/100], Step [750/760], Total Loss: 3.4189\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 15/100 [35:02<3:18:25, 140.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [15/100], Step [760/760], Total Loss: 3.4767\nEpoch [16/100], Step [10/760], Total Loss: 3.4725\nEpoch [16/100], Step [20/760], Total Loss: 3.4326\nEpoch [16/100], Step [30/760], Total Loss: 3.4614\nEpoch [16/100], Step [40/760], Total Loss: 3.3464\nEpoch [16/100], Step [50/760], Total Loss: 3.4551\nEpoch [16/100], Step [60/760], Total Loss: 3.4702\nEpoch [16/100], Step [70/760], Total Loss: 3.4272\nEpoch [16/100], Step [80/760], Total Loss: 3.3480\nEpoch [16/100], Step [90/760], Total Loss: 3.4175\nEpoch [16/100], Step [100/760], Total Loss: 3.4201\nEpoch [16/100], Step [110/760], Total Loss: 3.4719\nEpoch [16/100], Step [120/760], Total Loss: 3.4533\nEpoch [16/100], Step [130/760], Total Loss: 3.4848\nEpoch [16/100], Step [140/760], Total Loss: 3.4145\nEpoch [16/100], Step [150/760], Total Loss: 3.4617\nEpoch [16/100], Step [160/760], Total Loss: 3.3965\nEpoch [16/100], Step [170/760], Total Loss: 3.4992\nEpoch [16/100], Step [180/760], Total Loss: 3.4236\nEpoch [16/100], Step [190/760], Total Loss: 3.4759\nEpoch [16/100], Step [200/760], Total Loss: 3.4272\nEpoch [16/100], Step [210/760], Total Loss: 3.4517\nEpoch [16/100], Step [220/760], Total Loss: 3.5271\nEpoch [16/100], Step [230/760], Total Loss: 3.5703\nEpoch [16/100], Step [240/760], Total Loss: 3.3030\nEpoch [16/100], Step [250/760], Total Loss: 3.3440\nEpoch [16/100], Step [260/760], Total Loss: 3.3937\nEpoch [16/100], Step [270/760], Total Loss: 3.5615\nEpoch [16/100], Step [280/760], Total Loss: 3.3622\nEpoch [16/100], Step [290/760], Total Loss: 3.4986\nEpoch [16/100], Step [300/760], Total Loss: 3.3997\nEpoch [16/100], Step [310/760], Total Loss: 3.4202\nEpoch [16/100], Step [320/760], Total Loss: 3.5065\nEpoch [16/100], Step [330/760], Total Loss: 3.3851\nEpoch [16/100], Step [340/760], Total Loss: 3.3524\nEpoch [16/100], Step [350/760], Total Loss: 3.4302\nEpoch [16/100], Step [360/760], Total Loss: 3.4680\nEpoch [16/100], Step [370/760], Total Loss: 3.4310\nEpoch [16/100], Step [380/760], Total Loss: 3.4303\nEpoch [16/100], Step [390/760], Total Loss: 3.4810\nEpoch [16/100], Step [400/760], Total Loss: 3.3979\nEpoch [16/100], Step [410/760], Total Loss: 3.3881\nEpoch [16/100], Step [420/760], Total Loss: 3.4243\nEpoch [16/100], Step [430/760], Total Loss: 3.3754\nEpoch [16/100], Step [440/760], Total Loss: 3.3841\nEpoch [16/100], Step [450/760], Total Loss: 3.3730\nEpoch [16/100], Step [460/760], Total Loss: 3.3576\nEpoch [16/100], Step [470/760], Total Loss: 3.4803\nEpoch [16/100], Step [480/760], Total Loss: 3.3836\nEpoch [16/100], Step [490/760], Total Loss: 3.3335\nEpoch [16/100], Step [500/760], Total Loss: 3.4005\nEpoch [16/100], Step [510/760], Total Loss: 3.3667\nEpoch [16/100], Step [520/760], Total Loss: 3.4023\nEpoch [16/100], Step [530/760], Total Loss: 3.4316\nEpoch [16/100], Step [540/760], Total Loss: 3.4510\nEpoch [16/100], Step [550/760], Total Loss: 3.4414\nEpoch [16/100], Step [560/760], Total Loss: 3.4475\nEpoch [16/100], Step [570/760], Total Loss: 3.4819\nEpoch [16/100], Step [580/760], Total Loss: 3.4244\nEpoch [16/100], Step [590/760], Total Loss: 3.3640\nEpoch [16/100], Step [600/760], Total Loss: 3.3494\nEpoch [16/100], Step [610/760], Total Loss: 3.5198\nEpoch [16/100], Step [620/760], Total Loss: 3.4527\nEpoch [16/100], Step [630/760], Total Loss: 3.3831\nEpoch [16/100], Step [640/760], Total Loss: 3.3660\nEpoch [16/100], Step [650/760], Total Loss: 3.3187\nEpoch [16/100], Step [660/760], Total Loss: 3.4802\nEpoch [16/100], Step [670/760], Total Loss: 3.3860\nEpoch [16/100], Step [680/760], Total Loss: 3.4307\nEpoch [16/100], Step [690/760], Total Loss: 3.3962\nEpoch [16/100], Step [700/760], Total Loss: 3.4725\nEpoch [16/100], Step [710/760], Total Loss: 3.3734\nEpoch [16/100], Step [720/760], Total Loss: 3.4701\nEpoch [16/100], Step [730/760], Total Loss: 3.3801\nEpoch [16/100], Step [740/760], Total Loss: 3.4209\nEpoch [16/100], Step [750/760], Total Loss: 3.3828\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 16/100 [37:22<3:16:03, 140.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [16/100], Step [760/760], Total Loss: 3.4833\nEpoch [17/100], Step [10/760], Total Loss: 3.4057\nEpoch [17/100], Step [20/760], Total Loss: 3.5521\nEpoch [17/100], Step [30/760], Total Loss: 3.3311\nEpoch [17/100], Step [40/760], Total Loss: 3.3762\nEpoch [17/100], Step [50/760], Total Loss: 3.3621\nEpoch [17/100], Step [60/760], Total Loss: 3.5603\nEpoch [17/100], Step [70/760], Total Loss: 3.3941\nEpoch [17/100], Step [80/760], Total Loss: 3.4372\nEpoch [17/100], Step [90/760], Total Loss: 3.4396\nEpoch [17/100], Step [100/760], Total Loss: 3.3688\nEpoch [17/100], Step [110/760], Total Loss: 3.4566\nEpoch [17/100], Step [120/760], Total Loss: 3.4017\nEpoch [17/100], Step [130/760], Total Loss: 3.4043\nEpoch [17/100], Step [140/760], Total Loss: 3.4016\nEpoch [17/100], Step [150/760], Total Loss: 3.4177\nEpoch [17/100], Step [160/760], Total Loss: 3.4090\nEpoch [17/100], Step [170/760], Total Loss: 3.4220\nEpoch [17/100], Step [180/760], Total Loss: 3.3451\nEpoch [17/100], Step [190/760], Total Loss: 3.4572\nEpoch [17/100], Step [200/760], Total Loss: 3.3864\nEpoch [17/100], Step [210/760], Total Loss: 3.3858\nEpoch [17/100], Step [220/760], Total Loss: 3.3746\nEpoch [17/100], Step [230/760], Total Loss: 3.3673\nEpoch [17/100], Step [240/760], Total Loss: 3.3290\nEpoch [17/100], Step [250/760], Total Loss: 3.4599\nEpoch [17/100], Step [260/760], Total Loss: 3.3466\nEpoch [17/100], Step [270/760], Total Loss: 3.3109\nEpoch [17/100], Step [280/760], Total Loss: 3.4087\nEpoch [17/100], Step [290/760], Total Loss: 3.4377\nEpoch [17/100], Step [300/760], Total Loss: 3.3538\nEpoch [17/100], Step [310/760], Total Loss: 3.3110\nEpoch [17/100], Step [320/760], Total Loss: 3.4036\nEpoch [17/100], Step [330/760], Total Loss: 3.3712\nEpoch [17/100], Step [340/760], Total Loss: 3.3651\nEpoch [17/100], Step [350/760], Total Loss: 3.4217\nEpoch [17/100], Step [360/760], Total Loss: 3.5213\nEpoch [17/100], Step [370/760], Total Loss: 3.3893\nEpoch [17/100], Step [380/760], Total Loss: 3.4255\nEpoch [17/100], Step [390/760], Total Loss: 3.4484\nEpoch [17/100], Step [400/760], Total Loss: 3.4008\nEpoch [17/100], Step [410/760], Total Loss: 3.4790\nEpoch [17/100], Step [420/760], Total Loss: 3.4530\nEpoch [17/100], Step [430/760], Total Loss: 3.4224\nEpoch [17/100], Step [440/760], Total Loss: 3.4454\nEpoch [17/100], Step [450/760], Total Loss: 3.3434\nEpoch [17/100], Step [460/760], Total Loss: 3.4706\nEpoch [17/100], Step [470/760], Total Loss: 3.2714\nEpoch [17/100], Step [480/760], Total Loss: 3.4530\nEpoch [17/100], Step [490/760], Total Loss: 3.4779\nEpoch [17/100], Step [500/760], Total Loss: 3.4365\nEpoch [17/100], Step [510/760], Total Loss: 3.3388\nEpoch [17/100], Step [520/760], Total Loss: 3.3798\nEpoch [17/100], Step [530/760], Total Loss: 3.3124\nEpoch [17/100], Step [540/760], Total Loss: 3.4993\nEpoch [17/100], Step [550/760], Total Loss: 3.4436\nEpoch [17/100], Step [560/760], Total Loss: 3.3656\nEpoch [17/100], Step [570/760], Total Loss: 3.3038\nEpoch [17/100], Step [580/760], Total Loss: 3.4644\nEpoch [17/100], Step [590/760], Total Loss: 3.3768\nEpoch [17/100], Step [600/760], Total Loss: 3.3667\nEpoch [17/100], Step [610/760], Total Loss: 3.3289\nEpoch [17/100], Step [620/760], Total Loss: 3.3410\nEpoch [17/100], Step [630/760], Total Loss: 3.4304\nEpoch [17/100], Step [640/760], Total Loss: 3.4478\nEpoch [17/100], Step [650/760], Total Loss: 3.3379\nEpoch [17/100], Step [660/760], Total Loss: 3.3680\nEpoch [17/100], Step [670/760], Total Loss: 3.3638\nEpoch [17/100], Step [680/760], Total Loss: 3.3891\nEpoch [17/100], Step [690/760], Total Loss: 3.3979\nEpoch [17/100], Step [700/760], Total Loss: 3.2913\nEpoch [17/100], Step [710/760], Total Loss: 3.3603\nEpoch [17/100], Step [720/760], Total Loss: 3.3942\nEpoch [17/100], Step [730/760], Total Loss: 3.4499\nEpoch [17/100], Step [740/760], Total Loss: 3.3613\nEpoch [17/100], Step [750/760], Total Loss: 3.4318\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 17/100 [39:42<3:13:43, 140.04s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [17/100], Step [760/760], Total Loss: 3.2326\nEpoch [18/100], Step [10/760], Total Loss: 3.4003\nEpoch [18/100], Step [20/760], Total Loss: 3.3719\nEpoch [18/100], Step [30/760], Total Loss: 3.3075\nEpoch [18/100], Step [40/760], Total Loss: 3.4624\nEpoch [18/100], Step [50/760], Total Loss: 3.4195\nEpoch [18/100], Step [60/760], Total Loss: 3.4139\nEpoch [18/100], Step [70/760], Total Loss: 3.2915\nEpoch [18/100], Step [80/760], Total Loss: 3.3199\nEpoch [18/100], Step [90/760], Total Loss: 3.3839\nEpoch [18/100], Step [100/760], Total Loss: 3.3265\nEpoch [18/100], Step [110/760], Total Loss: 3.3221\nEpoch [18/100], Step [120/760], Total Loss: 3.4388\nEpoch [18/100], Step [130/760], Total Loss: 3.4131\nEpoch [18/100], Step [140/760], Total Loss: 3.3837\nEpoch [18/100], Step [150/760], Total Loss: 3.3192\nEpoch [18/100], Step [160/760], Total Loss: 3.4011\nEpoch [18/100], Step [170/760], Total Loss: 3.3355\nEpoch [18/100], Step [180/760], Total Loss: 3.3481\nEpoch [18/100], Step [190/760], Total Loss: 3.3617\nEpoch [18/100], Step [200/760], Total Loss: 3.3104\nEpoch [18/100], Step [210/760], Total Loss: 3.3348\nEpoch [18/100], Step [220/760], Total Loss: 3.3038\nEpoch [18/100], Step [230/760], Total Loss: 3.3203\nEpoch [18/100], Step [240/760], Total Loss: 3.3271\nEpoch [18/100], Step [250/760], Total Loss: 3.4073\nEpoch [18/100], Step [260/760], Total Loss: 3.3225\nEpoch [18/100], Step [270/760], Total Loss: 3.3215\nEpoch [18/100], Step [280/760], Total Loss: 3.2803\nEpoch [18/100], Step [290/760], Total Loss: 3.4422\nEpoch [18/100], Step [300/760], Total Loss: 3.2884\nEpoch [18/100], Step [310/760], Total Loss: 3.2880\nEpoch [18/100], Step [320/760], Total Loss: 3.4068\nEpoch [18/100], Step [330/760], Total Loss: 3.3070\nEpoch [18/100], Step [340/760], Total Loss: 3.3408\nEpoch [18/100], Step [350/760], Total Loss: 3.3811\nEpoch [18/100], Step [360/760], Total Loss: 3.2765\nEpoch [18/100], Step [370/760], Total Loss: 3.2854\nEpoch [18/100], Step [380/760], Total Loss: 3.2698\nEpoch [18/100], Step [390/760], Total Loss: 3.4758\nEpoch [18/100], Step [400/760], Total Loss: 3.3686\nEpoch [18/100], Step [410/760], Total Loss: 3.3534\nEpoch [18/100], Step [420/760], Total Loss: 3.3704\nEpoch [18/100], Step [430/760], Total Loss: 3.3563\nEpoch [18/100], Step [440/760], Total Loss: 3.3752\nEpoch [18/100], Step [450/760], Total Loss: 3.2324\nEpoch [18/100], Step [460/760], Total Loss: 3.3966\nEpoch [18/100], Step [470/760], Total Loss: 3.3408\nEpoch [18/100], Step [480/760], Total Loss: 3.2865\nEpoch [18/100], Step [490/760], Total Loss: 3.3904\nEpoch [18/100], Step [500/760], Total Loss: 3.4517\nEpoch [18/100], Step [510/760], Total Loss: 3.3230\nEpoch [18/100], Step [520/760], Total Loss: 3.2500\nEpoch [18/100], Step [530/760], Total Loss: 3.4463\nEpoch [18/100], Step [540/760], Total Loss: 3.2896\nEpoch [18/100], Step [550/760], Total Loss: 3.3588\nEpoch [18/100], Step [560/760], Total Loss: 3.3600\nEpoch [18/100], Step [570/760], Total Loss: 3.2946\nEpoch [18/100], Step [580/760], Total Loss: 3.3944\nEpoch [18/100], Step [590/760], Total Loss: 3.4315\nEpoch [18/100], Step [600/760], Total Loss: 3.4060\nEpoch [18/100], Step [610/760], Total Loss: 3.3611\nEpoch [18/100], Step [620/760], Total Loss: 3.3928\nEpoch [18/100], Step [630/760], Total Loss: 3.3818\nEpoch [18/100], Step [640/760], Total Loss: 3.3295\nEpoch [18/100], Step [650/760], Total Loss: 3.3484\nEpoch [18/100], Step [660/760], Total Loss: 3.2572\nEpoch [18/100], Step [670/760], Total Loss: 3.3464\nEpoch [18/100], Step [680/760], Total Loss: 3.3528\nEpoch [18/100], Step [690/760], Total Loss: 3.3878\nEpoch [18/100], Step [700/760], Total Loss: 3.4019\nEpoch [18/100], Step [710/760], Total Loss: 3.3489\nEpoch [18/100], Step [720/760], Total Loss: 3.4340\nEpoch [18/100], Step [730/760], Total Loss: 3.3972\nEpoch [18/100], Step [740/760], Total Loss: 3.2934\nEpoch [18/100], Step [750/760], Total Loss: 3.3551\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 18/100 [42:02<3:11:26, 140.08s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [18/100], Step [760/760], Total Loss: 3.2117\nEpoch [19/100], Step [10/760], Total Loss: 3.3506\nEpoch [19/100], Step [20/760], Total Loss: 3.3743\nEpoch [19/100], Step [30/760], Total Loss: 3.3480\nEpoch [19/100], Step [40/760], Total Loss: 3.4184\nEpoch [19/100], Step [50/760], Total Loss: 3.2826\nEpoch [19/100], Step [60/760], Total Loss: 3.3182\nEpoch [19/100], Step [70/760], Total Loss: 3.4635\nEpoch [19/100], Step [80/760], Total Loss: 3.3908\nEpoch [19/100], Step [90/760], Total Loss: 3.3161\nEpoch [19/100], Step [100/760], Total Loss: 3.4087\nEpoch [19/100], Step [110/760], Total Loss: 3.3583\nEpoch [19/100], Step [120/760], Total Loss: 3.3306\nEpoch [19/100], Step [130/760], Total Loss: 3.2848\nEpoch [19/100], Step [140/760], Total Loss: 3.3329\nEpoch [19/100], Step [150/760], Total Loss: 3.3308\nEpoch [19/100], Step [160/760], Total Loss: 3.4274\nEpoch [19/100], Step [170/760], Total Loss: 3.3180\nEpoch [19/100], Step [180/760], Total Loss: 3.2296\nEpoch [19/100], Step [190/760], Total Loss: 3.3286\nEpoch [19/100], Step [200/760], Total Loss: 3.3273\nEpoch [19/100], Step [210/760], Total Loss: 3.2823\nEpoch [19/100], Step [220/760], Total Loss: 3.4095\nEpoch [19/100], Step [230/760], Total Loss: 3.3699\nEpoch [19/100], Step [240/760], Total Loss: 3.3157\nEpoch [19/100], Step [250/760], Total Loss: 3.2769\nEpoch [19/100], Step [260/760], Total Loss: 3.3639\nEpoch [19/100], Step [270/760], Total Loss: 3.3261\nEpoch [19/100], Step [280/760], Total Loss: 3.3617\nEpoch [19/100], Step [290/760], Total Loss: 3.2849\nEpoch [19/100], Step [300/760], Total Loss: 3.3047\nEpoch [19/100], Step [310/760], Total Loss: 3.3772\nEpoch [19/100], Step [320/760], Total Loss: 3.2236\nEpoch [19/100], Step [330/760], Total Loss: 3.3576\nEpoch [19/100], Step [340/760], Total Loss: 3.2862\nEpoch [19/100], Step [350/760], Total Loss: 3.3936\nEpoch [19/100], Step [360/760], Total Loss: 3.4559\nEpoch [19/100], Step [370/760], Total Loss: 3.2452\nEpoch [19/100], Step [380/760], Total Loss: 3.4436\nEpoch [19/100], Step [390/760], Total Loss: 3.3769\nEpoch [19/100], Step [400/760], Total Loss: 3.3354\nEpoch [19/100], Step [410/760], Total Loss: 3.3308\nEpoch [19/100], Step [420/760], Total Loss: 3.3449\nEpoch [19/100], Step [430/760], Total Loss: 3.3226\nEpoch [19/100], Step [440/760], Total Loss: 3.2755\nEpoch [19/100], Step [450/760], Total Loss: 3.2637\nEpoch [19/100], Step [460/760], Total Loss: 3.3371\nEpoch [19/100], Step [470/760], Total Loss: 3.3859\nEpoch [19/100], Step [480/760], Total Loss: 3.2752\nEpoch [19/100], Step [490/760], Total Loss: 3.2918\nEpoch [19/100], Step [500/760], Total Loss: 3.2948\nEpoch [19/100], Step [510/760], Total Loss: 3.3733\nEpoch [19/100], Step [520/760], Total Loss: 3.3585\nEpoch [19/100], Step [530/760], Total Loss: 3.3192\nEpoch [19/100], Step [540/760], Total Loss: 3.3595\nEpoch [19/100], Step [550/760], Total Loss: 3.4102\nEpoch [19/100], Step [560/760], Total Loss: 3.2880\nEpoch [19/100], Step [570/760], Total Loss: 3.3108\nEpoch [19/100], Step [580/760], Total Loss: 3.3068\nEpoch [19/100], Step [590/760], Total Loss: 3.3501\nEpoch [19/100], Step [600/760], Total Loss: 3.2863\nEpoch [19/100], Step [610/760], Total Loss: 3.3404\nEpoch [19/100], Step [620/760], Total Loss: 3.3722\nEpoch [19/100], Step [630/760], Total Loss: 3.2976\nEpoch [19/100], Step [640/760], Total Loss: 3.3700\nEpoch [19/100], Step [650/760], Total Loss: 3.3009\nEpoch [19/100], Step [660/760], Total Loss: 3.3071\nEpoch [19/100], Step [670/760], Total Loss: 3.3724\nEpoch [19/100], Step [680/760], Total Loss: 3.4472\nEpoch [19/100], Step [690/760], Total Loss: 3.4919\nEpoch [19/100], Step [700/760], Total Loss: 3.3437\nEpoch [19/100], Step [710/760], Total Loss: 3.3068\nEpoch [19/100], Step [720/760], Total Loss: 3.3422\nEpoch [19/100], Step [730/760], Total Loss: 3.3027\nEpoch [19/100], Step [740/760], Total Loss: 3.3330\nEpoch [19/100], Step [750/760], Total Loss: 3.3975\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 19/100 [44:22<3:09:05, 140.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [19/100], Step [760/760], Total Loss: 3.3388\nEpoch [20/100], Step [10/760], Total Loss: 3.4515\nEpoch [20/100], Step [20/760], Total Loss: 3.3697\nEpoch [20/100], Step [30/760], Total Loss: 3.4326\nEpoch [20/100], Step [40/760], Total Loss: 3.2810\nEpoch [20/100], Step [50/760], Total Loss: 3.2457\nEpoch [20/100], Step [60/760], Total Loss: 3.2710\nEpoch [20/100], Step [70/760], Total Loss: 3.3430\nEpoch [20/100], Step [80/760], Total Loss: 3.4720\nEpoch [20/100], Step [90/760], Total Loss: 3.2651\nEpoch [20/100], Step [100/760], Total Loss: 3.3634\nEpoch [20/100], Step [110/760], Total Loss: 3.2315\nEpoch [20/100], Step [120/760], Total Loss: 3.2273\nEpoch [20/100], Step [130/760], Total Loss: 3.2995\nEpoch [20/100], Step [140/760], Total Loss: 3.3637\nEpoch [20/100], Step [150/760], Total Loss: 3.4164\nEpoch [20/100], Step [160/760], Total Loss: 3.2794\nEpoch [20/100], Step [170/760], Total Loss: 3.3930\nEpoch [20/100], Step [180/760], Total Loss: 3.3356\nEpoch [20/100], Step [190/760], Total Loss: 3.3056\nEpoch [20/100], Step [200/760], Total Loss: 3.3577\nEpoch [20/100], Step [210/760], Total Loss: 3.3525\nEpoch [20/100], Step [220/760], Total Loss: 3.3177\nEpoch [20/100], Step [230/760], Total Loss: 3.3866\nEpoch [20/100], Step [240/760], Total Loss: 3.3014\nEpoch [20/100], Step [250/760], Total Loss: 3.3934\nEpoch [20/100], Step [260/760], Total Loss: 3.2948\nEpoch [20/100], Step [270/760], Total Loss: 3.3724\nEpoch [20/100], Step [280/760], Total Loss: 3.4349\nEpoch [20/100], Step [290/760], Total Loss: 3.3096\nEpoch [20/100], Step [300/760], Total Loss: 3.3597\nEpoch [20/100], Step [310/760], Total Loss: 3.2386\nEpoch [20/100], Step [320/760], Total Loss: 3.3901\nEpoch [20/100], Step [330/760], Total Loss: 3.2978\nEpoch [20/100], Step [340/760], Total Loss: 3.3557\nEpoch [20/100], Step [350/760], Total Loss: 3.3261\nEpoch [20/100], Step [360/760], Total Loss: 3.3783\nEpoch [20/100], Step [370/760], Total Loss: 3.3561\nEpoch [20/100], Step [380/760], Total Loss: 3.3585\nEpoch [20/100], Step [390/760], Total Loss: 3.3487\nEpoch [20/100], Step [400/760], Total Loss: 3.3518\nEpoch [20/100], Step [410/760], Total Loss: 3.2866\nEpoch [20/100], Step [420/760], Total Loss: 3.3137\nEpoch [20/100], Step [430/760], Total Loss: 3.3216\nEpoch [20/100], Step [440/760], Total Loss: 3.2174\nEpoch [20/100], Step [450/760], Total Loss: 3.4381\nEpoch [20/100], Step [460/760], Total Loss: 3.3456\nEpoch [20/100], Step [470/760], Total Loss: 3.2787\nEpoch [20/100], Step [480/760], Total Loss: 3.3073\nEpoch [20/100], Step [490/760], Total Loss: 3.3755\nEpoch [20/100], Step [500/760], Total Loss: 3.2815\nEpoch [20/100], Step [510/760], Total Loss: 3.3720\nEpoch [20/100], Step [520/760], Total Loss: 3.2838\nEpoch [20/100], Step [530/760], Total Loss: 3.3315\nEpoch [20/100], Step [540/760], Total Loss: 3.3302\nEpoch [20/100], Step [550/760], Total Loss: 3.3781\nEpoch [20/100], Step [560/760], Total Loss: 3.2941\nEpoch [20/100], Step [570/760], Total Loss: 3.2549\nEpoch [20/100], Step [580/760], Total Loss: 3.3177\nEpoch [20/100], Step [590/760], Total Loss: 3.2878\nEpoch [20/100], Step [600/760], Total Loss: 3.3188\nEpoch [20/100], Step [610/760], Total Loss: 3.3664\nEpoch [20/100], Step [620/760], Total Loss: 3.2995\nEpoch [20/100], Step [630/760], Total Loss: 3.3441\nEpoch [20/100], Step [640/760], Total Loss: 3.3176\nEpoch [20/100], Step [650/760], Total Loss: 3.2742\nEpoch [20/100], Step [660/760], Total Loss: 3.4346\nEpoch [20/100], Step [670/760], Total Loss: 3.3545\nEpoch [20/100], Step [680/760], Total Loss: 3.4196\nEpoch [20/100], Step [690/760], Total Loss: 3.2522\nEpoch [20/100], Step [700/760], Total Loss: 3.3577\nEpoch [20/100], Step [710/760], Total Loss: 3.3321\nEpoch [20/100], Step [720/760], Total Loss: 3.3132\nEpoch [20/100], Step [730/760], Total Loss: 3.3538\nEpoch [20/100], Step [740/760], Total Loss: 3.3307\nEpoch [20/100], Step [750/760], Total Loss: 3.3068\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 20/100 [46:42<3:06:43, 140.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [20/100], Step [760/760], Total Loss: 3.1274\nEpoch [21/100], Step [10/760], Total Loss: 3.2571\nEpoch [21/100], Step [20/760], Total Loss: 3.2906\nEpoch [21/100], Step [30/760], Total Loss: 3.3391\nEpoch [21/100], Step [40/760], Total Loss: 3.2580\nEpoch [21/100], Step [50/760], Total Loss: 3.3224\nEpoch [21/100], Step [60/760], Total Loss: 3.4066\nEpoch [21/100], Step [70/760], Total Loss: 3.2880\nEpoch [21/100], Step [80/760], Total Loss: 3.4096\nEpoch [21/100], Step [90/760], Total Loss: 3.3553\nEpoch [21/100], Step [100/760], Total Loss: 3.2907\nEpoch [21/100], Step [110/760], Total Loss: 3.3963\nEpoch [21/100], Step [120/760], Total Loss: 3.3021\nEpoch [21/100], Step [130/760], Total Loss: 3.2561\nEpoch [21/100], Step [140/760], Total Loss: 3.2877\nEpoch [21/100], Step [150/760], Total Loss: 3.3514\nEpoch [21/100], Step [160/760], Total Loss: 3.3348\nEpoch [21/100], Step [170/760], Total Loss: 3.3989\nEpoch [21/100], Step [180/760], Total Loss: 3.3187\nEpoch [21/100], Step [190/760], Total Loss: 3.2821\nEpoch [21/100], Step [200/760], Total Loss: 3.2858\nEpoch [21/100], Step [210/760], Total Loss: 3.2444\nEpoch [21/100], Step [220/760], Total Loss: 3.2851\nEpoch [21/100], Step [230/760], Total Loss: 3.3779\nEpoch [21/100], Step [240/760], Total Loss: 3.3254\nEpoch [21/100], Step [250/760], Total Loss: 3.3387\nEpoch [21/100], Step [260/760], Total Loss: 3.3401\nEpoch [21/100], Step [270/760], Total Loss: 3.4288\nEpoch [21/100], Step [280/760], Total Loss: 3.3196\nEpoch [21/100], Step [290/760], Total Loss: 3.1940\nEpoch [21/100], Step [300/760], Total Loss: 3.3109\nEpoch [21/100], Step [310/760], Total Loss: 3.4100\nEpoch [21/100], Step [320/760], Total Loss: 3.3602\nEpoch [21/100], Step [330/760], Total Loss: 3.2154\nEpoch [21/100], Step [340/760], Total Loss: 3.3254\nEpoch [21/100], Step [350/760], Total Loss: 3.4564\nEpoch [21/100], Step [360/760], Total Loss: 3.2913\nEpoch [21/100], Step [370/760], Total Loss: 3.3967\nEpoch [21/100], Step [380/760], Total Loss: 3.3740\nEpoch [21/100], Step [390/760], Total Loss: 3.3014\nEpoch [21/100], Step [400/760], Total Loss: 3.2488\nEpoch [21/100], Step [410/760], Total Loss: 3.3490\nEpoch [21/100], Step [420/760], Total Loss: 3.3186\nEpoch [21/100], Step [430/760], Total Loss: 3.3086\nEpoch [21/100], Step [440/760], Total Loss: 3.3270\nEpoch [21/100], Step [450/760], Total Loss: 3.3391\nEpoch [21/100], Step [460/760], Total Loss: 3.2690\nEpoch [21/100], Step [470/760], Total Loss: 3.2158\nEpoch [21/100], Step [480/760], Total Loss: 3.2799\nEpoch [21/100], Step [490/760], Total Loss: 3.3450\nEpoch [21/100], Step [500/760], Total Loss: 3.2367\nEpoch [21/100], Step [510/760], Total Loss: 3.3518\nEpoch [21/100], Step [520/760], Total Loss: 3.4147\nEpoch [21/100], Step [530/760], Total Loss: 3.2894\nEpoch [21/100], Step [540/760], Total Loss: 3.2711\nEpoch [21/100], Step [550/760], Total Loss: 3.2654\nEpoch [21/100], Step [560/760], Total Loss: 3.2375\nEpoch [21/100], Step [570/760], Total Loss: 3.3801\nEpoch [21/100], Step [580/760], Total Loss: 3.3674\nEpoch [21/100], Step [590/760], Total Loss: 3.3548\nEpoch [21/100], Step [600/760], Total Loss: 3.3127\nEpoch [21/100], Step [610/760], Total Loss: 3.2972\nEpoch [21/100], Step [620/760], Total Loss: 3.3797\nEpoch [21/100], Step [630/760], Total Loss: 3.3080\nEpoch [21/100], Step [640/760], Total Loss: 3.2559\nEpoch [21/100], Step [650/760], Total Loss: 3.4259\nEpoch [21/100], Step [660/760], Total Loss: 3.3179\nEpoch [21/100], Step [670/760], Total Loss: 3.3374\nEpoch [21/100], Step [680/760], Total Loss: 3.3471\nEpoch [21/100], Step [690/760], Total Loss: 3.3344\nEpoch [21/100], Step [700/760], Total Loss: 3.3038\nEpoch [21/100], Step [710/760], Total Loss: 3.3259\nEpoch [21/100], Step [720/760], Total Loss: 3.2934\nEpoch [21/100], Step [730/760], Total Loss: 3.3184\nEpoch [21/100], Step [740/760], Total Loss: 3.3032\nEpoch [21/100], Step [750/760], Total Loss: 3.2894\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 21/100 [49:02<3:04:22, 140.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [21/100], Step [760/760], Total Loss: 3.3200\nEpoch [22/100], Step [10/760], Total Loss: 3.3519\nEpoch [22/100], Step [20/760], Total Loss: 3.3785\nEpoch [22/100], Step [30/760], Total Loss: 3.2362\nEpoch [22/100], Step [40/760], Total Loss: 3.2619\nEpoch [22/100], Step [50/760], Total Loss: 3.3046\nEpoch [22/100], Step [60/760], Total Loss: 3.3048\nEpoch [22/100], Step [70/760], Total Loss: 3.3098\nEpoch [22/100], Step [80/760], Total Loss: 3.3132\nEpoch [22/100], Step [90/760], Total Loss: 3.2293\nEpoch [22/100], Step [100/760], Total Loss: 3.2933\nEpoch [22/100], Step [110/760], Total Loss: 3.2943\nEpoch [22/100], Step [120/760], Total Loss: 3.3218\nEpoch [22/100], Step [130/760], Total Loss: 3.3314\nEpoch [22/100], Step [140/760], Total Loss: 3.4117\nEpoch [22/100], Step [150/760], Total Loss: 3.2813\nEpoch [22/100], Step [160/760], Total Loss: 3.4230\nEpoch [22/100], Step [170/760], Total Loss: 3.2637\nEpoch [22/100], Step [180/760], Total Loss: 3.3206\nEpoch [22/100], Step [190/760], Total Loss: 3.2255\nEpoch [22/100], Step [200/760], Total Loss: 3.3416\nEpoch [22/100], Step [210/760], Total Loss: 3.3150\nEpoch [22/100], Step [220/760], Total Loss: 3.3121\nEpoch [22/100], Step [230/760], Total Loss: 3.2621\nEpoch [22/100], Step [240/760], Total Loss: 3.2212\nEpoch [22/100], Step [250/760], Total Loss: 3.2425\nEpoch [22/100], Step [260/760], Total Loss: 3.3511\nEpoch [22/100], Step [270/760], Total Loss: 3.2014\nEpoch [22/100], Step [280/760], Total Loss: 3.3044\nEpoch [22/100], Step [290/760], Total Loss: 3.2984\nEpoch [22/100], Step [300/760], Total Loss: 3.2644\nEpoch [22/100], Step [310/760], Total Loss: 3.3314\nEpoch [22/100], Step [320/760], Total Loss: 3.3274\nEpoch [22/100], Step [330/760], Total Loss: 3.2548\nEpoch [22/100], Step [340/760], Total Loss: 3.2765\nEpoch [22/100], Step [350/760], Total Loss: 3.3403\nEpoch [22/100], Step [360/760], Total Loss: 3.3075\nEpoch [22/100], Step [370/760], Total Loss: 3.3700\nEpoch [22/100], Step [380/760], Total Loss: 3.2911\nEpoch [22/100], Step [390/760], Total Loss: 3.2731\nEpoch [22/100], Step [400/760], Total Loss: 3.2429\nEpoch [22/100], Step [410/760], Total Loss: 3.3488\nEpoch [22/100], Step [420/760], Total Loss: 3.2123\nEpoch [22/100], Step [430/760], Total Loss: 3.3307\nEpoch [22/100], Step [440/760], Total Loss: 3.2414\nEpoch [22/100], Step [450/760], Total Loss: 3.3009\nEpoch [22/100], Step [460/760], Total Loss: 3.3071\nEpoch [22/100], Step [470/760], Total Loss: 3.3090\nEpoch [22/100], Step [480/760], Total Loss: 3.2624\nEpoch [22/100], Step [490/760], Total Loss: 3.2806\nEpoch [22/100], Step [500/760], Total Loss: 3.3059\nEpoch [22/100], Step [510/760], Total Loss: 3.3048\nEpoch [22/100], Step [520/760], Total Loss: 3.2944\nEpoch [22/100], Step [530/760], Total Loss: 3.3608\nEpoch [22/100], Step [540/760], Total Loss: 3.3474\nEpoch [22/100], Step [550/760], Total Loss: 3.3127\nEpoch [22/100], Step [560/760], Total Loss: 3.3551\nEpoch [22/100], Step [570/760], Total Loss: 3.3439\nEpoch [22/100], Step [580/760], Total Loss: 3.3577\nEpoch [22/100], Step [590/760], Total Loss: 3.3410\nEpoch [22/100], Step [600/760], Total Loss: 3.2879\nEpoch [22/100], Step [610/760], Total Loss: 3.3306\nEpoch [22/100], Step [620/760], Total Loss: 3.3658\nEpoch [22/100], Step [630/760], Total Loss: 3.3197\nEpoch [22/100], Step [640/760], Total Loss: 3.2064\nEpoch [22/100], Step [650/760], Total Loss: 3.3198\nEpoch [22/100], Step [660/760], Total Loss: 3.3071\nEpoch [22/100], Step [670/760], Total Loss: 3.3496\nEpoch [22/100], Step [680/760], Total Loss: 3.2229\nEpoch [22/100], Step [690/760], Total Loss: 3.3971\nEpoch [22/100], Step [700/760], Total Loss: 3.2425\nEpoch [22/100], Step [710/760], Total Loss: 3.2777\nEpoch [22/100], Step [720/760], Total Loss: 3.3257\nEpoch [22/100], Step [730/760], Total Loss: 3.3337\nEpoch [22/100], Step [740/760], Total Loss: 3.4140\nEpoch [22/100], Step [750/760], Total Loss: 3.2937\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 22/100 [51:22<3:02:05, 140.07s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [22/100], Step [760/760], Total Loss: 3.1567\nEpoch [23/100], Step [10/760], Total Loss: 3.2376\nEpoch [23/100], Step [20/760], Total Loss: 3.2530\nEpoch [23/100], Step [30/760], Total Loss: 3.3148\nEpoch [23/100], Step [40/760], Total Loss: 3.2859\nEpoch [23/100], Step [50/760], Total Loss: 3.3919\nEpoch [23/100], Step [60/760], Total Loss: 3.2448\nEpoch [23/100], Step [70/760], Total Loss: 3.2851\nEpoch [23/100], Step [80/760], Total Loss: 3.2214\nEpoch [23/100], Step [90/760], Total Loss: 3.2917\nEpoch [23/100], Step [100/760], Total Loss: 3.2677\nEpoch [23/100], Step [110/760], Total Loss: 3.1803\nEpoch [23/100], Step [120/760], Total Loss: 3.3019\nEpoch [23/100], Step [130/760], Total Loss: 3.2931\nEpoch [23/100], Step [140/760], Total Loss: 3.1821\nEpoch [23/100], Step [150/760], Total Loss: 3.3893\nEpoch [23/100], Step [160/760], Total Loss: 3.2063\nEpoch [23/100], Step [170/760], Total Loss: 3.3056\nEpoch [23/100], Step [180/760], Total Loss: 3.1882\nEpoch [23/100], Step [190/760], Total Loss: 3.3289\nEpoch [23/100], Step [200/760], Total Loss: 3.2271\nEpoch [23/100], Step [210/760], Total Loss: 3.2725\nEpoch [23/100], Step [220/760], Total Loss: 3.3008\nEpoch [23/100], Step [230/760], Total Loss: 3.2789\nEpoch [23/100], Step [240/760], Total Loss: 3.2630\nEpoch [23/100], Step [250/760], Total Loss: 3.2840\nEpoch [23/100], Step [260/760], Total Loss: 3.3149\nEpoch [23/100], Step [270/760], Total Loss: 3.3472\nEpoch [23/100], Step [280/760], Total Loss: 3.2393\nEpoch [23/100], Step [290/760], Total Loss: 3.1593\nEpoch [23/100], Step [300/760], Total Loss: 3.3604\nEpoch [23/100], Step [310/760], Total Loss: 3.2494\nEpoch [23/100], Step [320/760], Total Loss: 3.2855\nEpoch [23/100], Step [330/760], Total Loss: 3.2761\nEpoch [23/100], Step [340/760], Total Loss: 3.3525\nEpoch [23/100], Step [350/760], Total Loss: 3.2859\nEpoch [23/100], Step [360/760], Total Loss: 3.2554\nEpoch [23/100], Step [370/760], Total Loss: 3.3137\nEpoch [23/100], Step [380/760], Total Loss: 3.3394\nEpoch [23/100], Step [390/760], Total Loss: 3.2873\nEpoch [23/100], Step [400/760], Total Loss: 3.2543\nEpoch [23/100], Step [410/760], Total Loss: 3.2228\nEpoch [23/100], Step [420/760], Total Loss: 3.2888\nEpoch [23/100], Step [430/760], Total Loss: 3.3358\nEpoch [23/100], Step [440/760], Total Loss: 3.3466\nEpoch [23/100], Step [450/760], Total Loss: 3.2011\nEpoch [23/100], Step [460/760], Total Loss: 3.3570\nEpoch [23/100], Step [470/760], Total Loss: 3.3427\nEpoch [23/100], Step [480/760], Total Loss: 3.2626\nEpoch [23/100], Step [490/760], Total Loss: 3.3338\nEpoch [23/100], Step [500/760], Total Loss: 3.2577\nEpoch [23/100], Step [510/760], Total Loss: 3.3798\nEpoch [23/100], Step [520/760], Total Loss: 3.2965\nEpoch [23/100], Step [530/760], Total Loss: 3.2540\nEpoch [23/100], Step [540/760], Total Loss: 3.2714\nEpoch [23/100], Step [550/760], Total Loss: 3.3404\nEpoch [23/100], Step [560/760], Total Loss: 3.2936\nEpoch [23/100], Step [570/760], Total Loss: 3.3163\nEpoch [23/100], Step [580/760], Total Loss: 3.3189\nEpoch [23/100], Step [590/760], Total Loss: 3.1908\nEpoch [23/100], Step [600/760], Total Loss: 3.3209\nEpoch [23/100], Step [610/760], Total Loss: 3.2551\nEpoch [23/100], Step [620/760], Total Loss: 3.3184\nEpoch [23/100], Step [630/760], Total Loss: 3.2190\nEpoch [23/100], Step [640/760], Total Loss: 3.2975\nEpoch [23/100], Step [650/760], Total Loss: 3.3020\nEpoch [23/100], Step [660/760], Total Loss: 3.2051\nEpoch [23/100], Step [670/760], Total Loss: 3.2531\nEpoch [23/100], Step [680/760], Total Loss: 3.2536\nEpoch [23/100], Step [690/760], Total Loss: 3.3032\nEpoch [23/100], Step [700/760], Total Loss: 3.2574\nEpoch [23/100], Step [710/760], Total Loss: 3.2355\nEpoch [23/100], Step [720/760], Total Loss: 3.3487\nEpoch [23/100], Step [730/760], Total Loss: 3.2358\nEpoch [23/100], Step [740/760], Total Loss: 3.2768\nEpoch [23/100], Step [750/760], Total Loss: 3.2131\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 23/100 [53:42<2:59:43, 140.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [23/100], Step [760/760], Total Loss: 3.2319\nEpoch [24/100], Step [10/760], Total Loss: 3.2406\nEpoch [24/100], Step [20/760], Total Loss: 3.3067\nEpoch [24/100], Step [30/760], Total Loss: 3.3905\nEpoch [24/100], Step [40/760], Total Loss: 3.3215\nEpoch [24/100], Step [50/760], Total Loss: 3.1655\nEpoch [24/100], Step [60/760], Total Loss: 3.3550\nEpoch [24/100], Step [70/760], Total Loss: 3.3018\nEpoch [24/100], Step [80/760], Total Loss: 3.3586\nEpoch [24/100], Step [90/760], Total Loss: 3.3014\nEpoch [24/100], Step [100/760], Total Loss: 3.2341\nEpoch [24/100], Step [110/760], Total Loss: 3.3325\nEpoch [24/100], Step [120/760], Total Loss: 3.2370\nEpoch [24/100], Step [130/760], Total Loss: 3.1816\nEpoch [24/100], Step [140/760], Total Loss: 3.2431\nEpoch [24/100], Step [150/760], Total Loss: 3.2831\nEpoch [24/100], Step [160/760], Total Loss: 3.2957\nEpoch [24/100], Step [170/760], Total Loss: 3.2518\nEpoch [24/100], Step [180/760], Total Loss: 3.2882\nEpoch [24/100], Step [190/760], Total Loss: 3.3116\nEpoch [24/100], Step [200/760], Total Loss: 3.3192\nEpoch [24/100], Step [210/760], Total Loss: 3.3263\nEpoch [24/100], Step [220/760], Total Loss: 3.2414\nEpoch [24/100], Step [230/760], Total Loss: 3.3209\nEpoch [24/100], Step [240/760], Total Loss: 3.1833\nEpoch [24/100], Step [250/760], Total Loss: 3.2955\nEpoch [24/100], Step [260/760], Total Loss: 3.2156\nEpoch [24/100], Step [270/760], Total Loss: 3.2155\nEpoch [24/100], Step [280/760], Total Loss: 3.1679\nEpoch [24/100], Step [290/760], Total Loss: 3.2967\nEpoch [24/100], Step [300/760], Total Loss: 3.2400\nEpoch [24/100], Step [310/760], Total Loss: 3.2623\nEpoch [24/100], Step [320/760], Total Loss: 3.3134\nEpoch [24/100], Step [330/760], Total Loss: 3.2867\nEpoch [24/100], Step [340/760], Total Loss: 3.2296\nEpoch [24/100], Step [350/760], Total Loss: 3.2982\nEpoch [24/100], Step [360/760], Total Loss: 3.2831\nEpoch [24/100], Step [370/760], Total Loss: 3.2478\nEpoch [24/100], Step [380/760], Total Loss: 3.2550\nEpoch [24/100], Step [390/760], Total Loss: 3.3231\nEpoch [24/100], Step [400/760], Total Loss: 3.3177\nEpoch [24/100], Step [410/760], Total Loss: 3.2862\nEpoch [24/100], Step [420/760], Total Loss: 3.3063\nEpoch [24/100], Step [430/760], Total Loss: 3.3463\nEpoch [24/100], Step [440/760], Total Loss: 3.2685\nEpoch [24/100], Step [450/760], Total Loss: 3.2278\nEpoch [24/100], Step [460/760], Total Loss: 3.2975\nEpoch [24/100], Step [470/760], Total Loss: 3.3495\nEpoch [24/100], Step [480/760], Total Loss: 3.1628\nEpoch [24/100], Step [490/760], Total Loss: 3.3965\nEpoch [24/100], Step [500/760], Total Loss: 3.3139\nEpoch [24/100], Step [510/760], Total Loss: 3.3143\nEpoch [24/100], Step [520/760], Total Loss: 3.2031\nEpoch [24/100], Step [530/760], Total Loss: 3.3198\nEpoch [24/100], Step [540/760], Total Loss: 3.2854\nEpoch [24/100], Step [550/760], Total Loss: 3.1920\nEpoch [24/100], Step [560/760], Total Loss: 3.2173\nEpoch [24/100], Step [570/760], Total Loss: 3.2524\nEpoch [24/100], Step [580/760], Total Loss: 3.3151\nEpoch [24/100], Step [590/760], Total Loss: 3.3079\nEpoch [24/100], Step [600/760], Total Loss: 3.3092\nEpoch [24/100], Step [610/760], Total Loss: 3.2229\nEpoch [24/100], Step [620/760], Total Loss: 3.2804\nEpoch [24/100], Step [630/760], Total Loss: 3.2869\nEpoch [24/100], Step [640/760], Total Loss: 3.2001\nEpoch [24/100], Step [650/760], Total Loss: 3.3135\nEpoch [24/100], Step [660/760], Total Loss: 3.2343\nEpoch [24/100], Step [670/760], Total Loss: 3.2653\nEpoch [24/100], Step [680/760], Total Loss: 3.2513\nEpoch [24/100], Step [690/760], Total Loss: 3.3510\nEpoch [24/100], Step [700/760], Total Loss: 3.2576\nEpoch [24/100], Step [710/760], Total Loss: 3.2540\nEpoch [24/100], Step [720/760], Total Loss: 3.2026\nEpoch [24/100], Step [730/760], Total Loss: 3.1994\nEpoch [24/100], Step [740/760], Total Loss: 3.3074\nEpoch [24/100], Step [750/760], Total Loss: 3.1917\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 24/100 [56:02<2:57:22, 140.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [24/100], Step [760/760], Total Loss: 3.3740\nEpoch [25/100], Step [10/760], Total Loss: 3.3893\nEpoch [25/100], Step [20/760], Total Loss: 3.2293\nEpoch [25/100], Step [30/760], Total Loss: 3.2682\nEpoch [25/100], Step [40/760], Total Loss: 3.3224\nEpoch [25/100], Step [50/760], Total Loss: 3.2571\nEpoch [25/100], Step [60/760], Total Loss: 3.3236\nEpoch [25/100], Step [70/760], Total Loss: 3.2408\nEpoch [25/100], Step [80/760], Total Loss: 3.2067\nEpoch [25/100], Step [90/760], Total Loss: 3.2347\nEpoch [25/100], Step [100/760], Total Loss: 3.2830\nEpoch [25/100], Step [110/760], Total Loss: 3.2497\nEpoch [25/100], Step [120/760], Total Loss: 3.2104\nEpoch [25/100], Step [130/760], Total Loss: 3.2482\nEpoch [25/100], Step [140/760], Total Loss: 3.2384\nEpoch [25/100], Step [150/760], Total Loss: 3.3011\nEpoch [25/100], Step [160/760], Total Loss: 3.1979\nEpoch [25/100], Step [170/760], Total Loss: 3.2655\nEpoch [25/100], Step [180/760], Total Loss: 3.2369\nEpoch [25/100], Step [190/760], Total Loss: 3.2893\nEpoch [25/100], Step [200/760], Total Loss: 3.2785\nEpoch [25/100], Step [210/760], Total Loss: 3.2429\nEpoch [25/100], Step [220/760], Total Loss: 3.2296\nEpoch [25/100], Step [230/760], Total Loss: 3.2174\nEpoch [25/100], Step [240/760], Total Loss: 3.3311\nEpoch [25/100], Step [250/760], Total Loss: 3.2809\nEpoch [25/100], Step [260/760], Total Loss: 3.2089\nEpoch [25/100], Step [270/760], Total Loss: 3.2471\nEpoch [25/100], Step [280/760], Total Loss: 3.2073\nEpoch [25/100], Step [290/760], Total Loss: 3.2814\nEpoch [25/100], Step [300/760], Total Loss: 3.3062\nEpoch [25/100], Step [310/760], Total Loss: 3.3008\nEpoch [25/100], Step [320/760], Total Loss: 3.2439\nEpoch [25/100], Step [330/760], Total Loss: 3.2177\nEpoch [25/100], Step [340/760], Total Loss: 3.2303\nEpoch [25/100], Step [350/760], Total Loss: 3.2164\nEpoch [25/100], Step [360/760], Total Loss: 3.1889\nEpoch [25/100], Step [370/760], Total Loss: 3.2343\nEpoch [25/100], Step [380/760], Total Loss: 3.2940\nEpoch [25/100], Step [390/760], Total Loss: 3.3083\nEpoch [25/100], Step [400/760], Total Loss: 3.2377\nEpoch [25/100], Step [410/760], Total Loss: 3.2981\nEpoch [25/100], Step [420/760], Total Loss: 3.2577\nEpoch [25/100], Step [430/760], Total Loss: 3.2771\nEpoch [25/100], Step [440/760], Total Loss: 3.2766\nEpoch [25/100], Step [450/760], Total Loss: 3.2368\nEpoch [25/100], Step [460/760], Total Loss: 3.3115\nEpoch [25/100], Step [470/760], Total Loss: 3.2554\nEpoch [25/100], Step [480/760], Total Loss: 3.2007\nEpoch [25/100], Step [490/760], Total Loss: 3.2334\nEpoch [25/100], Step [500/760], Total Loss: 3.1929\nEpoch [25/100], Step [510/760], Total Loss: 3.2614\nEpoch [25/100], Step [520/760], Total Loss: 3.2694\nEpoch [25/100], Step [530/760], Total Loss: 3.1796\nEpoch [25/100], Step [540/760], Total Loss: 3.2657\nEpoch [25/100], Step [550/760], Total Loss: 3.2391\nEpoch [25/100], Step [560/760], Total Loss: 3.2093\nEpoch [25/100], Step [570/760], Total Loss: 3.2386\nEpoch [25/100], Step [580/760], Total Loss: 3.3085\nEpoch [25/100], Step [590/760], Total Loss: 3.2577\nEpoch [25/100], Step [600/760], Total Loss: 3.2612\nEpoch [25/100], Step [610/760], Total Loss: 3.2898\nEpoch [25/100], Step [620/760], Total Loss: 3.3292\nEpoch [25/100], Step [630/760], Total Loss: 3.2099\nEpoch [25/100], Step [640/760], Total Loss: 3.2763\nEpoch [25/100], Step [650/760], Total Loss: 3.3283\nEpoch [25/100], Step [660/760], Total Loss: 3.2601\nEpoch [25/100], Step [670/760], Total Loss: 3.2681\nEpoch [25/100], Step [680/760], Total Loss: 3.1331\nEpoch [25/100], Step [690/760], Total Loss: 3.1966\nEpoch [25/100], Step [700/760], Total Loss: 3.3162\nEpoch [25/100], Step [710/760], Total Loss: 3.3654\nEpoch [25/100], Step [720/760], Total Loss: 3.2340\nEpoch [25/100], Step [730/760], Total Loss: 3.1961\nEpoch [25/100], Step [740/760], Total Loss: 3.2925\nEpoch [25/100], Step [750/760], Total Loss: 3.2403\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 25/100 [58:22<2:55:01, 140.02s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [25/100], Step [760/760], Total Loss: 3.2217\nEpoch [26/100], Step [10/760], Total Loss: 3.2073\nEpoch [26/100], Step [20/760], Total Loss: 3.2996\nEpoch [26/100], Step [30/760], Total Loss: 3.3005\nEpoch [26/100], Step [40/760], Total Loss: 3.2838\nEpoch [26/100], Step [50/760], Total Loss: 3.2082\nEpoch [26/100], Step [60/760], Total Loss: 3.3311\nEpoch [26/100], Step [70/760], Total Loss: 3.4024\nEpoch [26/100], Step [80/760], Total Loss: 3.2278\nEpoch [26/100], Step [90/760], Total Loss: 3.1758\nEpoch [26/100], Step [100/760], Total Loss: 3.2444\nEpoch [26/100], Step [110/760], Total Loss: 3.2786\nEpoch [26/100], Step [120/760], Total Loss: 3.2282\nEpoch [26/100], Step [130/760], Total Loss: 3.2920\nEpoch [26/100], Step [140/760], Total Loss: 3.3168\nEpoch [26/100], Step [150/760], Total Loss: 3.2723\nEpoch [26/100], Step [160/760], Total Loss: 3.2264\nEpoch [26/100], Step [170/760], Total Loss: 3.2953\nEpoch [26/100], Step [180/760], Total Loss: 3.3244\nEpoch [26/100], Step [190/760], Total Loss: 3.1907\nEpoch [26/100], Step [200/760], Total Loss: 3.1953\nEpoch [26/100], Step [210/760], Total Loss: 3.2717\nEpoch [26/100], Step [220/760], Total Loss: 3.3226\nEpoch [26/100], Step [230/760], Total Loss: 3.2287\nEpoch [26/100], Step [240/760], Total Loss: 3.2111\nEpoch [26/100], Step [250/760], Total Loss: 3.2085\nEpoch [26/100], Step [260/760], Total Loss: 3.2599\nEpoch [26/100], Step [270/760], Total Loss: 3.2152\nEpoch [26/100], Step [280/760], Total Loss: 3.2112\nEpoch [26/100], Step [290/760], Total Loss: 3.3272\nEpoch [26/100], Step [300/760], Total Loss: 3.2642\nEpoch [26/100], Step [310/760], Total Loss: 3.2936\nEpoch [26/100], Step [320/760], Total Loss: 3.1952\nEpoch [26/100], Step [330/760], Total Loss: 3.2796\nEpoch [26/100], Step [340/760], Total Loss: 3.2612\nEpoch [26/100], Step [350/760], Total Loss: 3.2344\nEpoch [26/100], Step [360/760], Total Loss: 3.2532\nEpoch [26/100], Step [370/760], Total Loss: 3.2113\nEpoch [26/100], Step [380/760], Total Loss: 3.2518\nEpoch [26/100], Step [390/760], Total Loss: 3.1804\nEpoch [26/100], Step [400/760], Total Loss: 3.2350\nEpoch [26/100], Step [410/760], Total Loss: 3.2950\nEpoch [26/100], Step [420/760], Total Loss: 3.2267\nEpoch [26/100], Step [430/760], Total Loss: 3.2034\nEpoch [26/100], Step [440/760], Total Loss: 3.2697\nEpoch [26/100], Step [450/760], Total Loss: 3.2744\nEpoch [26/100], Step [460/760], Total Loss: 3.3506\nEpoch [26/100], Step [470/760], Total Loss: 3.1799\nEpoch [26/100], Step [480/760], Total Loss: 3.2938\nEpoch [26/100], Step [490/760], Total Loss: 3.2090\nEpoch [26/100], Step [500/760], Total Loss: 3.2450\nEpoch [26/100], Step [510/760], Total Loss: 3.2461\nEpoch [26/100], Step [520/760], Total Loss: 3.2593\nEpoch [26/100], Step [530/760], Total Loss: 3.2218\nEpoch [26/100], Step [540/760], Total Loss: 3.2518\nEpoch [26/100], Step [550/760], Total Loss: 3.2318\nEpoch [26/100], Step [560/760], Total Loss: 3.2390\nEpoch [26/100], Step [570/760], Total Loss: 3.2290\nEpoch [26/100], Step [580/760], Total Loss: 3.2589\nEpoch [26/100], Step [590/760], Total Loss: 3.2704\nEpoch [26/100], Step [600/760], Total Loss: 3.1929\nEpoch [26/100], Step [610/760], Total Loss: 3.2624\nEpoch [26/100], Step [620/760], Total Loss: 3.2334\nEpoch [26/100], Step [630/760], Total Loss: 3.2382\nEpoch [26/100], Step [640/760], Total Loss: 3.2956\nEpoch [26/100], Step [650/760], Total Loss: 3.2887\nEpoch [26/100], Step [660/760], Total Loss: 3.2722\nEpoch [26/100], Step [670/760], Total Loss: 3.1973\nEpoch [26/100], Step [680/760], Total Loss: 3.2107\nEpoch [26/100], Step [690/760], Total Loss: 3.2036\nEpoch [26/100], Step [700/760], Total Loss: 3.2767\nEpoch [26/100], Step [710/760], Total Loss: 3.2289\nEpoch [26/100], Step [720/760], Total Loss: 3.1944\nEpoch [26/100], Step [730/760], Total Loss: 3.2557\nEpoch [26/100], Step [740/760], Total Loss: 3.2432\nEpoch [26/100], Step [750/760], Total Loss: 3.2043\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 26/100 [1:00:43<2:52:44, 140.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [26/100], Step [760/760], Total Loss: 3.3003\nEpoch [27/100], Step [10/760], Total Loss: 3.2838\nEpoch [27/100], Step [20/760], Total Loss: 3.2171\nEpoch [27/100], Step [30/760], Total Loss: 3.2394\nEpoch [27/100], Step [40/760], Total Loss: 3.3047\nEpoch [27/100], Step [50/760], Total Loss: 3.2309\nEpoch [27/100], Step [60/760], Total Loss: 3.3400\nEpoch [27/100], Step [70/760], Total Loss: 3.2474\nEpoch [27/100], Step [80/760], Total Loss: 3.2331\nEpoch [27/100], Step [90/760], Total Loss: 3.2003\nEpoch [27/100], Step [100/760], Total Loss: 3.1762\nEpoch [27/100], Step [110/760], Total Loss: 3.2539\nEpoch [27/100], Step [120/760], Total Loss: 3.2406\nEpoch [27/100], Step [130/760], Total Loss: 3.3127\nEpoch [27/100], Step [140/760], Total Loss: 3.2077\nEpoch [27/100], Step [150/760], Total Loss: 3.2338\nEpoch [27/100], Step [160/760], Total Loss: 3.1713\nEpoch [27/100], Step [170/760], Total Loss: 3.2846\nEpoch [27/100], Step [180/760], Total Loss: 3.2121\nEpoch [27/100], Step [190/760], Total Loss: 3.2990\nEpoch [27/100], Step [200/760], Total Loss: 3.2214\nEpoch [27/100], Step [210/760], Total Loss: 3.2325\nEpoch [27/100], Step [220/760], Total Loss: 3.2788\nEpoch [27/100], Step [230/760], Total Loss: 3.2470\nEpoch [27/100], Step [240/760], Total Loss: 3.2710\nEpoch [27/100], Step [250/760], Total Loss: 3.2307\nEpoch [27/100], Step [260/760], Total Loss: 3.3032\nEpoch [27/100], Step [270/760], Total Loss: 3.1910\nEpoch [27/100], Step [280/760], Total Loss: 3.3063\nEpoch [27/100], Step [290/760], Total Loss: 3.2773\nEpoch [27/100], Step [300/760], Total Loss: 3.3467\nEpoch [27/100], Step [310/760], Total Loss: 3.2468\nEpoch [27/100], Step [320/760], Total Loss: 3.3326\nEpoch [27/100], Step [330/760], Total Loss: 3.2297\nEpoch [27/100], Step [340/760], Total Loss: 3.2013\nEpoch [27/100], Step [350/760], Total Loss: 3.2754\nEpoch [27/100], Step [360/760], Total Loss: 3.2994\nEpoch [27/100], Step [370/760], Total Loss: 3.2957\nEpoch [27/100], Step [380/760], Total Loss: 3.2971\nEpoch [27/100], Step [390/760], Total Loss: 3.3099\nEpoch [27/100], Step [400/760], Total Loss: 3.2686\nEpoch [27/100], Step [410/760], Total Loss: 3.2710\nEpoch [27/100], Step [420/760], Total Loss: 3.1873\nEpoch [27/100], Step [430/760], Total Loss: 3.2807\nEpoch [27/100], Step [440/760], Total Loss: 3.2294\nEpoch [27/100], Step [450/760], Total Loss: 3.2391\nEpoch [27/100], Step [460/760], Total Loss: 3.2903\nEpoch [27/100], Step [470/760], Total Loss: 3.3276\nEpoch [27/100], Step [480/760], Total Loss: 3.3513\nEpoch [27/100], Step [490/760], Total Loss: 3.1852\nEpoch [27/100], Step [500/760], Total Loss: 3.2593\nEpoch [27/100], Step [510/760], Total Loss: 3.2881\nEpoch [27/100], Step [520/760], Total Loss: 3.2908\nEpoch [27/100], Step [530/760], Total Loss: 3.2803\nEpoch [27/100], Step [540/760], Total Loss: 3.1788\nEpoch [27/100], Step [550/760], Total Loss: 3.2851\nEpoch [27/100], Step [560/760], Total Loss: 3.3250\nEpoch [27/100], Step [570/760], Total Loss: 3.1785\nEpoch [27/100], Step [580/760], Total Loss: 3.2854\nEpoch [27/100], Step [590/760], Total Loss: 3.2368\nEpoch [27/100], Step [600/760], Total Loss: 3.2955\nEpoch [27/100], Step [610/760], Total Loss: 3.2924\nEpoch [27/100], Step [620/760], Total Loss: 3.2203\nEpoch [27/100], Step [630/760], Total Loss: 3.2144\nEpoch [27/100], Step [640/760], Total Loss: 3.2094\nEpoch [27/100], Step [650/760], Total Loss: 3.2723\nEpoch [27/100], Step [660/760], Total Loss: 3.2879\nEpoch [27/100], Step [670/760], Total Loss: 3.2504\nEpoch [27/100], Step [680/760], Total Loss: 3.2116\nEpoch [27/100], Step [690/760], Total Loss: 3.1752\nEpoch [27/100], Step [700/760], Total Loss: 3.2278\nEpoch [27/100], Step [710/760], Total Loss: 3.2121\nEpoch [27/100], Step [720/760], Total Loss: 3.1843\nEpoch [27/100], Step [730/760], Total Loss: 3.2511\nEpoch [27/100], Step [740/760], Total Loss: 3.1798\nEpoch [27/100], Step [750/760], Total Loss: 3.2540\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 27/100 [1:03:03<2:50:23, 140.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [27/100], Step [760/760], Total Loss: 3.3224\nEpoch [28/100], Step [10/760], Total Loss: 3.3443\nEpoch [28/100], Step [20/760], Total Loss: 3.2763\nEpoch [28/100], Step [30/760], Total Loss: 3.2167\nEpoch [28/100], Step [40/760], Total Loss: 3.2316\nEpoch [28/100], Step [50/760], Total Loss: 3.1913\nEpoch [28/100], Step [60/760], Total Loss: 3.1940\nEpoch [28/100], Step [70/760], Total Loss: 3.2366\nEpoch [28/100], Step [80/760], Total Loss: 3.2724\nEpoch [28/100], Step [90/760], Total Loss: 3.2103\nEpoch [28/100], Step [100/760], Total Loss: 3.2426\nEpoch [28/100], Step [110/760], Total Loss: 3.1634\nEpoch [28/100], Step [120/760], Total Loss: 3.2593\nEpoch [28/100], Step [130/760], Total Loss: 3.2369\nEpoch [28/100], Step [140/760], Total Loss: 3.2821\nEpoch [28/100], Step [150/760], Total Loss: 3.1945\nEpoch [28/100], Step [160/760], Total Loss: 3.1816\nEpoch [28/100], Step [170/760], Total Loss: 3.2228\nEpoch [28/100], Step [180/760], Total Loss: 3.2210\nEpoch [28/100], Step [190/760], Total Loss: 3.2217\nEpoch [28/100], Step [200/760], Total Loss: 3.2534\nEpoch [28/100], Step [210/760], Total Loss: 3.2641\nEpoch [28/100], Step [220/760], Total Loss: 3.2019\nEpoch [28/100], Step [230/760], Total Loss: 3.3153\nEpoch [28/100], Step [240/760], Total Loss: 3.2695\nEpoch [28/100], Step [250/760], Total Loss: 3.2739\nEpoch [28/100], Step [260/760], Total Loss: 3.2487\nEpoch [28/100], Step [270/760], Total Loss: 3.1795\nEpoch [28/100], Step [280/760], Total Loss: 3.1108\nEpoch [28/100], Step [290/760], Total Loss: 3.1806\nEpoch [28/100], Step [300/760], Total Loss: 3.2472\nEpoch [28/100], Step [310/760], Total Loss: 3.2233\nEpoch [28/100], Step [320/760], Total Loss: 3.2391\nEpoch [28/100], Step [330/760], Total Loss: 3.2576\nEpoch [28/100], Step [340/760], Total Loss: 3.2137\nEpoch [28/100], Step [350/760], Total Loss: 3.2373\nEpoch [28/100], Step [360/760], Total Loss: 3.2561\nEpoch [28/100], Step [370/760], Total Loss: 3.2243\nEpoch [28/100], Step [380/760], Total Loss: 3.2056\nEpoch [28/100], Step [390/760], Total Loss: 3.2214\nEpoch [28/100], Step [400/760], Total Loss: 3.1746\nEpoch [28/100], Step [410/760], Total Loss: 3.1627\nEpoch [28/100], Step [420/760], Total Loss: 3.1936\nEpoch [28/100], Step [430/760], Total Loss: 3.1632\nEpoch [28/100], Step [440/760], Total Loss: 3.2265\nEpoch [28/100], Step [450/760], Total Loss: 3.1878\nEpoch [28/100], Step [460/760], Total Loss: 3.1869\nEpoch [28/100], Step [470/760], Total Loss: 3.1936\nEpoch [28/100], Step [480/760], Total Loss: 3.2419\nEpoch [28/100], Step [490/760], Total Loss: 3.2696\nEpoch [28/100], Step [500/760], Total Loss: 3.2853\nEpoch [28/100], Step [510/760], Total Loss: 3.2564\nEpoch [28/100], Step [520/760], Total Loss: 3.1926\nEpoch [28/100], Step [530/760], Total Loss: 3.2706\nEpoch [28/100], Step [540/760], Total Loss: 3.2130\nEpoch [28/100], Step [550/760], Total Loss: 3.2232\nEpoch [28/100], Step [560/760], Total Loss: 3.2919\nEpoch [28/100], Step [570/760], Total Loss: 3.2671\nEpoch [28/100], Step [580/760], Total Loss: 3.2028\nEpoch [28/100], Step [590/760], Total Loss: 3.1622\nEpoch [28/100], Step [600/760], Total Loss: 3.2783\nEpoch [28/100], Step [610/760], Total Loss: 3.1829\nEpoch [28/100], Step [620/760], Total Loss: 3.2768\nEpoch [28/100], Step [630/760], Total Loss: 3.2947\nEpoch [28/100], Step [640/760], Total Loss: 3.1794\nEpoch [28/100], Step [650/760], Total Loss: 3.2726\nEpoch [28/100], Step [660/760], Total Loss: 3.3115\nEpoch [28/100], Step [670/760], Total Loss: 3.2813\nEpoch [28/100], Step [680/760], Total Loss: 3.2135\nEpoch [28/100], Step [690/760], Total Loss: 3.2421\nEpoch [28/100], Step [700/760], Total Loss: 3.3060\nEpoch [28/100], Step [710/760], Total Loss: 3.1953\nEpoch [28/100], Step [720/760], Total Loss: 3.2199\nEpoch [28/100], Step [730/760], Total Loss: 3.2066\nEpoch [28/100], Step [740/760], Total Loss: 3.1849\nEpoch [28/100], Step [750/760], Total Loss: 3.2827\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 28/100 [1:05:23<2:48:02, 140.04s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [28/100], Step [760/760], Total Loss: 3.1642\nEpoch [29/100], Step [10/760], Total Loss: 3.2206\nEpoch [29/100], Step [20/760], Total Loss: 3.2200\nEpoch [29/100], Step [30/760], Total Loss: 3.1849\nEpoch [29/100], Step [40/760], Total Loss: 3.2443\nEpoch [29/100], Step [50/760], Total Loss: 3.1667\nEpoch [29/100], Step [60/760], Total Loss: 3.2412\nEpoch [29/100], Step [70/760], Total Loss: 3.3164\nEpoch [29/100], Step [80/760], Total Loss: 3.2039\nEpoch [29/100], Step [90/760], Total Loss: 3.3086\nEpoch [29/100], Step [100/760], Total Loss: 3.2956\nEpoch [29/100], Step [110/760], Total Loss: 3.2734\nEpoch [29/100], Step [120/760], Total Loss: 3.2514\nEpoch [29/100], Step [130/760], Total Loss: 3.2386\nEpoch [29/100], Step [140/760], Total Loss: 3.2651\nEpoch [29/100], Step [150/760], Total Loss: 3.2651\nEpoch [29/100], Step [160/760], Total Loss: 3.2177\nEpoch [29/100], Step [170/760], Total Loss: 3.2651\nEpoch [29/100], Step [180/760], Total Loss: 3.2872\nEpoch [29/100], Step [190/760], Total Loss: 3.1963\nEpoch [29/100], Step [200/760], Total Loss: 3.2429\nEpoch [29/100], Step [210/760], Total Loss: 3.1832\nEpoch [29/100], Step [220/760], Total Loss: 3.2730\nEpoch [29/100], Step [230/760], Total Loss: 3.2312\nEpoch [29/100], Step [240/760], Total Loss: 3.1867\nEpoch [29/100], Step [250/760], Total Loss: 3.1857\nEpoch [29/100], Step [260/760], Total Loss: 3.2103\nEpoch [29/100], Step [270/760], Total Loss: 3.2618\nEpoch [29/100], Step [280/760], Total Loss: 3.2685\nEpoch [29/100], Step [290/760], Total Loss: 3.2551\nEpoch [29/100], Step [300/760], Total Loss: 3.2901\nEpoch [29/100], Step [310/760], Total Loss: 3.2533\nEpoch [29/100], Step [320/760], Total Loss: 3.2440\nEpoch [29/100], Step [330/760], Total Loss: 3.2084\nEpoch [29/100], Step [340/760], Total Loss: 3.1646\nEpoch [29/100], Step [350/760], Total Loss: 3.2436\nEpoch [29/100], Step [360/760], Total Loss: 3.1975\nEpoch [29/100], Step [370/760], Total Loss: 3.1391\nEpoch [29/100], Step [380/760], Total Loss: 3.2604\nEpoch [29/100], Step [390/760], Total Loss: 3.3226\nEpoch [29/100], Step [400/760], Total Loss: 3.2603\nEpoch [29/100], Step [410/760], Total Loss: 3.3042\nEpoch [29/100], Step [420/760], Total Loss: 3.2542\nEpoch [29/100], Step [430/760], Total Loss: 3.2970\nEpoch [29/100], Step [440/760], Total Loss: 3.2854\nEpoch [29/100], Step [450/760], Total Loss: 3.2656\nEpoch [29/100], Step [460/760], Total Loss: 3.3502\nEpoch [29/100], Step [470/760], Total Loss: 3.2038\nEpoch [29/100], Step [480/760], Total Loss: 3.1360\nEpoch [29/100], Step [490/760], Total Loss: 3.1203\nEpoch [29/100], Step [500/760], Total Loss: 3.2209\nEpoch [29/100], Step [510/760], Total Loss: 3.2141\nEpoch [29/100], Step [520/760], Total Loss: 3.1624\nEpoch [29/100], Step [530/760], Total Loss: 3.2043\nEpoch [29/100], Step [540/760], Total Loss: 3.2254\nEpoch [29/100], Step [550/760], Total Loss: 3.2243\nEpoch [29/100], Step [560/760], Total Loss: 3.2829\nEpoch [29/100], Step [570/760], Total Loss: 3.1726\nEpoch [29/100], Step [580/760], Total Loss: 3.3245\nEpoch [29/100], Step [590/760], Total Loss: 3.1918\nEpoch [29/100], Step [600/760], Total Loss: 3.2420\nEpoch [29/100], Step [610/760], Total Loss: 3.2330\nEpoch [29/100], Step [620/760], Total Loss: 3.2953\nEpoch [29/100], Step [630/760], Total Loss: 3.1689\nEpoch [29/100], Step [640/760], Total Loss: 3.2440\nEpoch [29/100], Step [650/760], Total Loss: 3.1831\nEpoch [29/100], Step [660/760], Total Loss: 3.2961\nEpoch [29/100], Step [670/760], Total Loss: 3.3154\nEpoch [29/100], Step [680/760], Total Loss: 3.1667\nEpoch [29/100], Step [690/760], Total Loss: 3.2389\nEpoch [29/100], Step [700/760], Total Loss: 3.2425\nEpoch [29/100], Step [710/760], Total Loss: 3.3495\nEpoch [29/100], Step [720/760], Total Loss: 3.2901\nEpoch [29/100], Step [730/760], Total Loss: 3.1785\nEpoch [29/100], Step [740/760], Total Loss: 3.2562\nEpoch [29/100], Step [750/760], Total Loss: 3.2447\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 29/100 [1:07:43<2:45:41, 140.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [29/100], Step [760/760], Total Loss: 3.1846\nEpoch [30/100], Step [10/760], Total Loss: 3.2504\nEpoch [30/100], Step [20/760], Total Loss: 3.2422\nEpoch [30/100], Step [30/760], Total Loss: 3.1867\nEpoch [30/100], Step [40/760], Total Loss: 3.2464\nEpoch [30/100], Step [50/760], Total Loss: 3.2351\nEpoch [30/100], Step [60/760], Total Loss: 3.2239\nEpoch [30/100], Step [70/760], Total Loss: 3.2073\nEpoch [30/100], Step [80/760], Total Loss: 3.1296\nEpoch [30/100], Step [90/760], Total Loss: 3.1562\nEpoch [30/100], Step [100/760], Total Loss: 3.2123\nEpoch [30/100], Step [110/760], Total Loss: 3.2213\nEpoch [30/100], Step [120/760], Total Loss: 3.2572\nEpoch [30/100], Step [130/760], Total Loss: 3.2776\nEpoch [30/100], Step [140/760], Total Loss: 3.2369\nEpoch [30/100], Step [150/760], Total Loss: 3.2164\nEpoch [30/100], Step [160/760], Total Loss: 3.1818\nEpoch [30/100], Step [170/760], Total Loss: 3.2010\nEpoch [30/100], Step [180/760], Total Loss: 3.1525\nEpoch [30/100], Step [190/760], Total Loss: 3.1899\nEpoch [30/100], Step [200/760], Total Loss: 3.2290\nEpoch [30/100], Step [210/760], Total Loss: 3.3005\nEpoch [30/100], Step [220/760], Total Loss: 3.2545\nEpoch [30/100], Step [230/760], Total Loss: 3.2844\nEpoch [30/100], Step [240/760], Total Loss: 3.1540\nEpoch [30/100], Step [250/760], Total Loss: 3.1661\nEpoch [30/100], Step [260/760], Total Loss: 3.2003\nEpoch [30/100], Step [270/760], Total Loss: 3.2064\nEpoch [30/100], Step [280/760], Total Loss: 3.2198\nEpoch [30/100], Step [290/760], Total Loss: 3.2152\nEpoch [30/100], Step [300/760], Total Loss: 3.2413\nEpoch [30/100], Step [310/760], Total Loss: 3.2492\nEpoch [30/100], Step [320/760], Total Loss: 3.1862\nEpoch [30/100], Step [330/760], Total Loss: 3.2395\nEpoch [30/100], Step [340/760], Total Loss: 3.2457\nEpoch [30/100], Step [350/760], Total Loss: 3.2580\nEpoch [30/100], Step [360/760], Total Loss: 3.2170\nEpoch [30/100], Step [370/760], Total Loss: 3.2119\nEpoch [30/100], Step [380/760], Total Loss: 3.2346\nEpoch [30/100], Step [390/760], Total Loss: 3.2159\nEpoch [30/100], Step [400/760], Total Loss: 3.1807\nEpoch [30/100], Step [410/760], Total Loss: 3.2224\nEpoch [30/100], Step [420/760], Total Loss: 3.1969\nEpoch [30/100], Step [430/760], Total Loss: 3.1867\nEpoch [30/100], Step [440/760], Total Loss: 3.2206\nEpoch [30/100], Step [450/760], Total Loss: 3.2722\nEpoch [30/100], Step [460/760], Total Loss: 3.2333\nEpoch [30/100], Step [470/760], Total Loss: 3.2686\nEpoch [30/100], Step [480/760], Total Loss: 3.3111\nEpoch [30/100], Step [490/760], Total Loss: 3.1938\nEpoch [30/100], Step [500/760], Total Loss: 3.2595\nEpoch [30/100], Step [510/760], Total Loss: 3.1332\nEpoch [30/100], Step [520/760], Total Loss: 3.2025\nEpoch [30/100], Step [530/760], Total Loss: 3.2116\nEpoch [30/100], Step [540/760], Total Loss: 3.2777\nEpoch [30/100], Step [550/760], Total Loss: 3.2051\nEpoch [30/100], Step [560/760], Total Loss: 3.2393\nEpoch [30/100], Step [570/760], Total Loss: 3.2082\nEpoch [30/100], Step [580/760], Total Loss: 3.1791\nEpoch [30/100], Step [590/760], Total Loss: 3.2296\nEpoch [30/100], Step [600/760], Total Loss: 3.1329\nEpoch [30/100], Step [610/760], Total Loss: 3.2099\nEpoch [30/100], Step [620/760], Total Loss: 3.2299\nEpoch [30/100], Step [630/760], Total Loss: 3.2332\nEpoch [30/100], Step [640/760], Total Loss: 3.3526\nEpoch [30/100], Step [650/760], Total Loss: 3.2015\nEpoch [30/100], Step [660/760], Total Loss: 3.2717\nEpoch [30/100], Step [670/760], Total Loss: 3.2156\nEpoch [30/100], Step [680/760], Total Loss: 3.3085\nEpoch [30/100], Step [690/760], Total Loss: 3.1308\nEpoch [30/100], Step [700/760], Total Loss: 3.2992\nEpoch [30/100], Step [710/760], Total Loss: 3.1412\nEpoch [30/100], Step [720/760], Total Loss: 3.3123\nEpoch [30/100], Step [730/760], Total Loss: 3.1664\nEpoch [30/100], Step [740/760], Total Loss: 3.1296\nEpoch [30/100], Step [750/760], Total Loss: 3.2171\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 30/100 [1:10:03<2:43:24, 140.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [30/100], Step [760/760], Total Loss: 3.1586\nEpoch [31/100], Step [10/760], Total Loss: 3.1705\nEpoch [31/100], Step [20/760], Total Loss: 3.2566\nEpoch [31/100], Step [30/760], Total Loss: 3.1818\nEpoch [31/100], Step [40/760], Total Loss: 3.1613\nEpoch [31/100], Step [50/760], Total Loss: 3.2002\nEpoch [31/100], Step [60/760], Total Loss: 3.2636\nEpoch [31/100], Step [70/760], Total Loss: 3.2437\nEpoch [31/100], Step [80/760], Total Loss: 3.2050\nEpoch [31/100], Step [90/760], Total Loss: 3.2725\nEpoch [31/100], Step [100/760], Total Loss: 3.1719\nEpoch [31/100], Step [110/760], Total Loss: 3.2621\nEpoch [31/100], Step [120/760], Total Loss: 3.1395\nEpoch [31/100], Step [130/760], Total Loss: 3.1718\nEpoch [31/100], Step [140/760], Total Loss: 3.2313\nEpoch [31/100], Step [150/760], Total Loss: 3.3137\nEpoch [31/100], Step [160/760], Total Loss: 3.1641\nEpoch [31/100], Step [170/760], Total Loss: 3.2055\nEpoch [31/100], Step [180/760], Total Loss: 3.2203\nEpoch [31/100], Step [190/760], Total Loss: 3.2577\nEpoch [31/100], Step [200/760], Total Loss: 3.2019\nEpoch [31/100], Step [210/760], Total Loss: 3.1455\nEpoch [31/100], Step [220/760], Total Loss: 3.1718\nEpoch [31/100], Step [230/760], Total Loss: 3.1483\nEpoch [31/100], Step [240/760], Total Loss: 3.1642\nEpoch [31/100], Step [250/760], Total Loss: 3.2244\nEpoch [31/100], Step [260/760], Total Loss: 3.1470\nEpoch [31/100], Step [270/760], Total Loss: 3.1539\nEpoch [31/100], Step [280/760], Total Loss: 3.2144\nEpoch [31/100], Step [290/760], Total Loss: 3.2159\nEpoch [31/100], Step [300/760], Total Loss: 3.1949\nEpoch [31/100], Step [310/760], Total Loss: 3.2572\nEpoch [31/100], Step [320/760], Total Loss: 3.1815\nEpoch [31/100], Step [330/760], Total Loss: 3.2964\nEpoch [31/100], Step [340/760], Total Loss: 3.1504\nEpoch [31/100], Step [350/760], Total Loss: 3.3081\nEpoch [31/100], Step [360/760], Total Loss: 3.1997\nEpoch [31/100], Step [370/760], Total Loss: 3.2147\nEpoch [31/100], Step [380/760], Total Loss: 3.2142\nEpoch [31/100], Step [390/760], Total Loss: 3.2000\nEpoch [31/100], Step [400/760], Total Loss: 3.2871\nEpoch [31/100], Step [410/760], Total Loss: 3.2047\nEpoch [31/100], Step [420/760], Total Loss: 3.3357\nEpoch [31/100], Step [430/760], Total Loss: 3.1966\nEpoch [31/100], Step [440/760], Total Loss: 3.1710\nEpoch [31/100], Step [450/760], Total Loss: 3.1836\nEpoch [31/100], Step [460/760], Total Loss: 3.2521\nEpoch [31/100], Step [470/760], Total Loss: 3.3076\nEpoch [31/100], Step [480/760], Total Loss: 3.2069\nEpoch [31/100], Step [490/760], Total Loss: 3.2624\nEpoch [31/100], Step [500/760], Total Loss: 3.2609\nEpoch [31/100], Step [510/760], Total Loss: 3.2128\nEpoch [31/100], Step [520/760], Total Loss: 3.1822\nEpoch [31/100], Step [530/760], Total Loss: 3.1966\nEpoch [31/100], Step [540/760], Total Loss: 3.3171\nEpoch [31/100], Step [550/760], Total Loss: 3.1823\nEpoch [31/100], Step [560/760], Total Loss: 3.1667\nEpoch [31/100], Step [570/760], Total Loss: 3.2179\nEpoch [31/100], Step [580/760], Total Loss: 3.2391\nEpoch [31/100], Step [590/760], Total Loss: 3.2769\nEpoch [31/100], Step [600/760], Total Loss: 3.2121\nEpoch [31/100], Step [610/760], Total Loss: 3.2168\nEpoch [31/100], Step [620/760], Total Loss: 3.2717\nEpoch [31/100], Step [630/760], Total Loss: 3.1842\nEpoch [31/100], Step [640/760], Total Loss: 3.1629\nEpoch [31/100], Step [650/760], Total Loss: 3.1402\nEpoch [31/100], Step [660/760], Total Loss: 3.2617\nEpoch [31/100], Step [670/760], Total Loss: 3.1737\nEpoch [31/100], Step [680/760], Total Loss: 3.2172\nEpoch [31/100], Step [690/760], Total Loss: 3.2656\nEpoch [31/100], Step [700/760], Total Loss: 3.2771\nEpoch [31/100], Step [710/760], Total Loss: 3.2483\nEpoch [31/100], Step [720/760], Total Loss: 3.1405\nEpoch [31/100], Step [730/760], Total Loss: 3.1755\nEpoch [31/100], Step [740/760], Total Loss: 3.2245\nEpoch [31/100], Step [750/760], Total Loss: 3.2140\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 31/100 [1:12:23<2:41:02, 140.04s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [31/100], Step [760/760], Total Loss: 3.2381\nEpoch [32/100], Step [10/760], Total Loss: 3.1634\nEpoch [32/100], Step [20/760], Total Loss: 3.1790\nEpoch [32/100], Step [30/760], Total Loss: 3.1564\nEpoch [32/100], Step [40/760], Total Loss: 3.3087\nEpoch [32/100], Step [50/760], Total Loss: 3.1869\nEpoch [32/100], Step [60/760], Total Loss: 3.2263\nEpoch [32/100], Step [70/760], Total Loss: 3.2080\nEpoch [32/100], Step [80/760], Total Loss: 3.1833\nEpoch [32/100], Step [90/760], Total Loss: 3.1747\nEpoch [32/100], Step [100/760], Total Loss: 3.1879\nEpoch [32/100], Step [110/760], Total Loss: 3.2380\nEpoch [32/100], Step [120/760], Total Loss: 3.1396\nEpoch [32/100], Step [130/760], Total Loss: 3.2845\nEpoch [32/100], Step [140/760], Total Loss: 3.2489\nEpoch [32/100], Step [150/760], Total Loss: 3.2275\nEpoch [32/100], Step [160/760], Total Loss: 3.1730\nEpoch [32/100], Step [170/760], Total Loss: 3.2537\nEpoch [32/100], Step [180/760], Total Loss: 3.0977\nEpoch [32/100], Step [190/760], Total Loss: 3.1850\nEpoch [32/100], Step [200/760], Total Loss: 3.1291\nEpoch [32/100], Step [210/760], Total Loss: 3.2074\nEpoch [32/100], Step [220/760], Total Loss: 3.1213\nEpoch [32/100], Step [230/760], Total Loss: 3.1586\nEpoch [32/100], Step [240/760], Total Loss: 3.1535\nEpoch [32/100], Step [250/760], Total Loss: 3.1906\nEpoch [32/100], Step [260/760], Total Loss: 3.1824\nEpoch [32/100], Step [270/760], Total Loss: 3.2369\nEpoch [32/100], Step [280/760], Total Loss: 3.2856\nEpoch [32/100], Step [290/760], Total Loss: 3.2421\nEpoch [32/100], Step [300/760], Total Loss: 3.2194\nEpoch [32/100], Step [310/760], Total Loss: 3.2534\nEpoch [32/100], Step [320/760], Total Loss: 3.2466\nEpoch [32/100], Step [330/760], Total Loss: 3.2157\nEpoch [32/100], Step [340/760], Total Loss: 3.1943\nEpoch [32/100], Step [350/760], Total Loss: 3.1647\nEpoch [32/100], Step [360/760], Total Loss: 3.2469\nEpoch [32/100], Step [370/760], Total Loss: 3.1664\nEpoch [32/100], Step [380/760], Total Loss: 3.2498\nEpoch [32/100], Step [390/760], Total Loss: 3.1890\nEpoch [32/100], Step [400/760], Total Loss: 3.2460\nEpoch [32/100], Step [410/760], Total Loss: 3.2588\nEpoch [32/100], Step [420/760], Total Loss: 3.2047\nEpoch [32/100], Step [430/760], Total Loss: 3.1945\nEpoch [32/100], Step [440/760], Total Loss: 3.1643\nEpoch [32/100], Step [450/760], Total Loss: 3.1954\nEpoch [32/100], Step [460/760], Total Loss: 3.1695\nEpoch [32/100], Step [470/760], Total Loss: 3.2303\nEpoch [32/100], Step [480/760], Total Loss: 3.1977\nEpoch [32/100], Step [490/760], Total Loss: 3.2704\nEpoch [32/100], Step [500/760], Total Loss: 3.1598\nEpoch [32/100], Step [510/760], Total Loss: 3.2530\nEpoch [32/100], Step [520/760], Total Loss: 3.2251\nEpoch [32/100], Step [530/760], Total Loss: 3.2450\nEpoch [32/100], Step [540/760], Total Loss: 3.2577\nEpoch [32/100], Step [550/760], Total Loss: 3.2706\nEpoch [32/100], Step [560/760], Total Loss: 3.2013\nEpoch [32/100], Step [570/760], Total Loss: 3.2631\nEpoch [32/100], Step [580/760], Total Loss: 3.1991\nEpoch [32/100], Step [590/760], Total Loss: 3.1682\nEpoch [32/100], Step [600/760], Total Loss: 3.1390\nEpoch [32/100], Step [610/760], Total Loss: 3.2722\nEpoch [32/100], Step [620/760], Total Loss: 3.2299\nEpoch [32/100], Step [630/760], Total Loss: 3.2385\nEpoch [32/100], Step [640/760], Total Loss: 3.1399\nEpoch [32/100], Step [650/760], Total Loss: 3.1268\nEpoch [32/100], Step [660/760], Total Loss: 3.1591\nEpoch [32/100], Step [670/760], Total Loss: 3.2701\nEpoch [32/100], Step [680/760], Total Loss: 3.2450\nEpoch [32/100], Step [690/760], Total Loss: 3.2941\nEpoch [32/100], Step [700/760], Total Loss: 3.2736\nEpoch [32/100], Step [710/760], Total Loss: 3.2468\nEpoch [32/100], Step [720/760], Total Loss: 3.1778\nEpoch [32/100], Step [730/760], Total Loss: 3.2457\nEpoch [32/100], Step [740/760], Total Loss: 3.1669\nEpoch [32/100], Step [750/760], Total Loss: 3.1977\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 32/100 [1:14:43<2:38:41, 140.02s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [32/100], Step [760/760], Total Loss: 3.2508\nEpoch [33/100], Step [10/760], Total Loss: 3.1723\nEpoch [33/100], Step [20/760], Total Loss: 3.2231\nEpoch [33/100], Step [30/760], Total Loss: 3.1494\nEpoch [33/100], Step [40/760], Total Loss: 3.1841\nEpoch [33/100], Step [50/760], Total Loss: 3.2295\nEpoch [33/100], Step [60/760], Total Loss: 3.1496\nEpoch [33/100], Step [70/760], Total Loss: 3.1930\nEpoch [33/100], Step [80/760], Total Loss: 3.1860\nEpoch [33/100], Step [90/760], Total Loss: 3.1728\nEpoch [33/100], Step [100/760], Total Loss: 3.2272\nEpoch [33/100], Step [110/760], Total Loss: 3.2028\nEpoch [33/100], Step [120/760], Total Loss: 3.1604\nEpoch [33/100], Step [130/760], Total Loss: 3.2368\nEpoch [33/100], Step [140/760], Total Loss: 3.1603\nEpoch [33/100], Step [150/760], Total Loss: 3.1412\nEpoch [33/100], Step [160/760], Total Loss: 3.2333\nEpoch [33/100], Step [170/760], Total Loss: 3.2178\nEpoch [33/100], Step [180/760], Total Loss: 3.2452\nEpoch [33/100], Step [190/760], Total Loss: 3.2015\nEpoch [33/100], Step [200/760], Total Loss: 3.2070\nEpoch [33/100], Step [210/760], Total Loss: 3.3093\nEpoch [33/100], Step [220/760], Total Loss: 3.2190\nEpoch [33/100], Step [230/760], Total Loss: 3.1566\nEpoch [33/100], Step [240/760], Total Loss: 3.1980\nEpoch [33/100], Step [250/760], Total Loss: 3.1939\nEpoch [33/100], Step [260/760], Total Loss: 3.2543\nEpoch [33/100], Step [270/760], Total Loss: 3.1471\nEpoch [33/100], Step [280/760], Total Loss: 3.1615\nEpoch [33/100], Step [290/760], Total Loss: 3.1238\nEpoch [33/100], Step [300/760], Total Loss: 3.1820\nEpoch [33/100], Step [310/760], Total Loss: 3.2033\nEpoch [33/100], Step [320/760], Total Loss: 3.2524\nEpoch [33/100], Step [330/760], Total Loss: 3.1941\nEpoch [33/100], Step [340/760], Total Loss: 3.1517\nEpoch [33/100], Step [350/760], Total Loss: 3.2137\nEpoch [33/100], Step [360/760], Total Loss: 3.1376\nEpoch [33/100], Step [370/760], Total Loss: 3.1881\nEpoch [33/100], Step [380/760], Total Loss: 3.1931\nEpoch [33/100], Step [390/760], Total Loss: 3.2124\nEpoch [33/100], Step [400/760], Total Loss: 3.1820\nEpoch [33/100], Step [410/760], Total Loss: 3.2138\nEpoch [33/100], Step [420/760], Total Loss: 3.2199\nEpoch [33/100], Step [430/760], Total Loss: 3.2282\nEpoch [33/100], Step [440/760], Total Loss: 3.2161\nEpoch [33/100], Step [450/760], Total Loss: 3.2350\nEpoch [33/100], Step [460/760], Total Loss: 3.1475\nEpoch [33/100], Step [470/760], Total Loss: 3.2325\nEpoch [33/100], Step [480/760], Total Loss: 3.2010\nEpoch [33/100], Step [490/760], Total Loss: 3.2464\nEpoch [33/100], Step [500/760], Total Loss: 3.2572\nEpoch [33/100], Step [510/760], Total Loss: 3.2033\nEpoch [33/100], Step [520/760], Total Loss: 3.2734\nEpoch [33/100], Step [530/760], Total Loss: 3.2726\nEpoch [33/100], Step [540/760], Total Loss: 3.1799\nEpoch [33/100], Step [550/760], Total Loss: 3.1494\nEpoch [33/100], Step [560/760], Total Loss: 3.2356\nEpoch [33/100], Step [570/760], Total Loss: 3.1497\nEpoch [33/100], Step [580/760], Total Loss: 3.3280\nEpoch [33/100], Step [590/760], Total Loss: 3.2828\nEpoch [33/100], Step [600/760], Total Loss: 3.2263\nEpoch [33/100], Step [610/760], Total Loss: 3.2123\nEpoch [33/100], Step [620/760], Total Loss: 3.1677\nEpoch [33/100], Step [630/760], Total Loss: 3.1823\nEpoch [33/100], Step [640/760], Total Loss: 3.2190\nEpoch [33/100], Step [650/760], Total Loss: 3.2441\nEpoch [33/100], Step [660/760], Total Loss: 3.1755\nEpoch [33/100], Step [670/760], Total Loss: 3.1728\nEpoch [33/100], Step [680/760], Total Loss: 3.2519\nEpoch [33/100], Step [690/760], Total Loss: 3.1716\nEpoch [33/100], Step [700/760], Total Loss: 3.2025\nEpoch [33/100], Step [710/760], Total Loss: 3.2335\nEpoch [33/100], Step [720/760], Total Loss: 3.0977\nEpoch [33/100], Step [730/760], Total Loss: 3.2399\nEpoch [33/100], Step [740/760], Total Loss: 3.2969\nEpoch [33/100], Step [750/760], Total Loss: 3.2416\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 33/100 [1:17:03<2:36:20, 140.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [33/100], Step [760/760], Total Loss: 3.2000\nEpoch [34/100], Step [10/760], Total Loss: 3.2409\nEpoch [34/100], Step [20/760], Total Loss: 3.2212\nEpoch [34/100], Step [30/760], Total Loss: 3.1700\nEpoch [34/100], Step [40/760], Total Loss: 3.2295\nEpoch [34/100], Step [50/760], Total Loss: 3.2316\nEpoch [34/100], Step [60/760], Total Loss: 3.1987\nEpoch [34/100], Step [70/760], Total Loss: 3.1778\nEpoch [34/100], Step [80/760], Total Loss: 3.2244\nEpoch [34/100], Step [90/760], Total Loss: 3.1861\nEpoch [34/100], Step [100/760], Total Loss: 3.1332\nEpoch [34/100], Step [110/760], Total Loss: 3.1579\nEpoch [34/100], Step [120/760], Total Loss: 3.1622\nEpoch [34/100], Step [130/760], Total Loss: 3.1934\nEpoch [34/100], Step [140/760], Total Loss: 3.2190\nEpoch [34/100], Step [150/760], Total Loss: 3.1789\nEpoch [34/100], Step [160/760], Total Loss: 3.1319\nEpoch [34/100], Step [170/760], Total Loss: 3.1852\nEpoch [34/100], Step [180/760], Total Loss: 3.2368\nEpoch [34/100], Step [190/760], Total Loss: 3.2985\nEpoch [34/100], Step [200/760], Total Loss: 3.1809\nEpoch [34/100], Step [210/760], Total Loss: 3.1951\nEpoch [34/100], Step [220/760], Total Loss: 3.2229\nEpoch [34/100], Step [230/760], Total Loss: 3.1908\nEpoch [34/100], Step [240/760], Total Loss: 3.2568\nEpoch [34/100], Step [250/760], Total Loss: 3.2273\nEpoch [34/100], Step [260/760], Total Loss: 3.2320\nEpoch [34/100], Step [270/760], Total Loss: 3.1977\nEpoch [34/100], Step [280/760], Total Loss: 3.2212\nEpoch [34/100], Step [290/760], Total Loss: 3.2895\nEpoch [34/100], Step [300/760], Total Loss: 3.1818\nEpoch [34/100], Step [310/760], Total Loss: 3.2114\nEpoch [34/100], Step [320/760], Total Loss: 3.1965\nEpoch [34/100], Step [330/760], Total Loss: 3.2420\nEpoch [34/100], Step [340/760], Total Loss: 3.1684\nEpoch [34/100], Step [350/760], Total Loss: 3.2670\nEpoch [34/100], Step [360/760], Total Loss: 3.2112\nEpoch [34/100], Step [370/760], Total Loss: 3.3097\nEpoch [34/100], Step [380/760], Total Loss: 3.1550\nEpoch [34/100], Step [390/760], Total Loss: 3.2806\nEpoch [34/100], Step [400/760], Total Loss: 3.1865\nEpoch [34/100], Step [410/760], Total Loss: 3.1329\nEpoch [34/100], Step [420/760], Total Loss: 3.1368\nEpoch [34/100], Step [430/760], Total Loss: 3.1562\nEpoch [34/100], Step [440/760], Total Loss: 3.1088\nEpoch [34/100], Step [450/760], Total Loss: 3.1456\nEpoch [34/100], Step [460/760], Total Loss: 3.1082\nEpoch [34/100], Step [470/760], Total Loss: 3.2254\nEpoch [34/100], Step [480/760], Total Loss: 3.2590\nEpoch [34/100], Step [490/760], Total Loss: 3.2709\nEpoch [34/100], Step [500/760], Total Loss: 3.2362\nEpoch [34/100], Step [510/760], Total Loss: 3.1243\nEpoch [34/100], Step [520/760], Total Loss: 3.1733\nEpoch [34/100], Step [530/760], Total Loss: 3.2090\nEpoch [34/100], Step [540/760], Total Loss: 3.1364\nEpoch [34/100], Step [550/760], Total Loss: 3.1907\nEpoch [34/100], Step [560/760], Total Loss: 3.1415\nEpoch [34/100], Step [570/760], Total Loss: 3.1946\nEpoch [34/100], Step [580/760], Total Loss: 3.1738\nEpoch [34/100], Step [590/760], Total Loss: 3.1473\nEpoch [34/100], Step [600/760], Total Loss: 3.2145\nEpoch [34/100], Step [610/760], Total Loss: 3.2406\nEpoch [34/100], Step [620/760], Total Loss: 3.1650\nEpoch [34/100], Step [630/760], Total Loss: 3.2207\nEpoch [34/100], Step [640/760], Total Loss: 3.2297\nEpoch [34/100], Step [650/760], Total Loss: 3.2033\nEpoch [34/100], Step [660/760], Total Loss: 3.1810\nEpoch [34/100], Step [670/760], Total Loss: 3.2496\nEpoch [34/100], Step [680/760], Total Loss: 3.2103\nEpoch [34/100], Step [690/760], Total Loss: 3.1978\nEpoch [34/100], Step [700/760], Total Loss: 3.2369\nEpoch [34/100], Step [710/760], Total Loss: 3.2093\nEpoch [34/100], Step [720/760], Total Loss: 3.2309\nEpoch [34/100], Step [730/760], Total Loss: 3.2367\nEpoch [34/100], Step [740/760], Total Loss: 3.2091\nEpoch [34/100], Step [750/760], Total Loss: 3.2153\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 34/100 [1:19:23<2:34:02, 140.04s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [34/100], Step [760/760], Total Loss: 3.1580\nEpoch [35/100], Step [10/760], Total Loss: 3.2191\nEpoch [35/100], Step [20/760], Total Loss: 3.1438\nEpoch [35/100], Step [30/760], Total Loss: 3.2206\nEpoch [35/100], Step [40/760], Total Loss: 3.1697\nEpoch [35/100], Step [50/760], Total Loss: 3.2465\nEpoch [35/100], Step [60/760], Total Loss: 3.2185\nEpoch [35/100], Step [70/760], Total Loss: 3.2197\nEpoch [35/100], Step [80/760], Total Loss: 3.2308\nEpoch [35/100], Step [90/760], Total Loss: 3.2114\nEpoch [35/100], Step [100/760], Total Loss: 3.2841\nEpoch [35/100], Step [110/760], Total Loss: 3.1171\nEpoch [35/100], Step [120/760], Total Loss: 3.2003\nEpoch [35/100], Step [130/760], Total Loss: 3.1384\nEpoch [35/100], Step [140/760], Total Loss: 3.2301\nEpoch [35/100], Step [150/760], Total Loss: 3.2046\nEpoch [35/100], Step [160/760], Total Loss: 3.1697\nEpoch [35/100], Step [170/760], Total Loss: 3.1525\nEpoch [35/100], Step [180/760], Total Loss: 3.1824\nEpoch [35/100], Step [190/760], Total Loss: 3.1866\nEpoch [35/100], Step [200/760], Total Loss: 3.1325\nEpoch [35/100], Step [210/760], Total Loss: 3.1973\nEpoch [35/100], Step [220/760], Total Loss: 3.1865\nEpoch [35/100], Step [230/760], Total Loss: 3.1130\nEpoch [35/100], Step [240/760], Total Loss: 3.1937\nEpoch [35/100], Step [250/760], Total Loss: 3.3148\nEpoch [35/100], Step [260/760], Total Loss: 3.2525\nEpoch [35/100], Step [270/760], Total Loss: 3.1993\nEpoch [35/100], Step [280/760], Total Loss: 3.1189\nEpoch [35/100], Step [290/760], Total Loss: 3.1916\nEpoch [35/100], Step [300/760], Total Loss: 3.2146\nEpoch [35/100], Step [310/760], Total Loss: 3.1501\nEpoch [35/100], Step [320/760], Total Loss: 3.1153\nEpoch [35/100], Step [330/760], Total Loss: 3.1481\nEpoch [35/100], Step [340/760], Total Loss: 3.1637\nEpoch [35/100], Step [350/760], Total Loss: 3.1897\nEpoch [35/100], Step [360/760], Total Loss: 3.2332\nEpoch [35/100], Step [370/760], Total Loss: 3.1733\nEpoch [35/100], Step [380/760], Total Loss: 3.2185\nEpoch [35/100], Step [390/760], Total Loss: 3.2658\nEpoch [35/100], Step [400/760], Total Loss: 3.1170\nEpoch [35/100], Step [410/760], Total Loss: 3.2042\nEpoch [35/100], Step [420/760], Total Loss: 3.1914\nEpoch [35/100], Step [430/760], Total Loss: 3.1108\nEpoch [35/100], Step [440/760], Total Loss: 3.1955\nEpoch [35/100], Step [450/760], Total Loss: 3.2201\nEpoch [35/100], Step [460/760], Total Loss: 3.2244\nEpoch [35/100], Step [470/760], Total Loss: 3.1654\nEpoch [35/100], Step [480/760], Total Loss: 3.1990\nEpoch [35/100], Step [490/760], Total Loss: 3.2300\nEpoch [35/100], Step [500/760], Total Loss: 3.2054\nEpoch [35/100], Step [510/760], Total Loss: 3.1737\nEpoch [35/100], Step [520/760], Total Loss: 3.1748\nEpoch [35/100], Step [530/760], Total Loss: 3.2089\nEpoch [35/100], Step [540/760], Total Loss: 3.2176\nEpoch [35/100], Step [550/760], Total Loss: 3.1252\nEpoch [35/100], Step [560/760], Total Loss: 3.2172\nEpoch [35/100], Step [570/760], Total Loss: 3.1673\nEpoch [35/100], Step [580/760], Total Loss: 3.3256\nEpoch [35/100], Step [590/760], Total Loss: 3.1651\nEpoch [35/100], Step [600/760], Total Loss: 3.2059\nEpoch [35/100], Step [610/760], Total Loss: 3.1762\nEpoch [35/100], Step [620/760], Total Loss: 3.1471\nEpoch [35/100], Step [630/760], Total Loss: 3.1959\nEpoch [35/100], Step [640/760], Total Loss: 3.2049\nEpoch [35/100], Step [650/760], Total Loss: 3.1934\nEpoch [35/100], Step [660/760], Total Loss: 3.2083\nEpoch [35/100], Step [670/760], Total Loss: 3.2090\nEpoch [35/100], Step [680/760], Total Loss: 3.1703\nEpoch [35/100], Step [690/760], Total Loss: 3.1578\nEpoch [35/100], Step [700/760], Total Loss: 3.1562\nEpoch [35/100], Step [710/760], Total Loss: 3.2152\nEpoch [35/100], Step [720/760], Total Loss: 3.1895\nEpoch [35/100], Step [730/760], Total Loss: 3.2246\nEpoch [35/100], Step [740/760], Total Loss: 3.1609\nEpoch [35/100], Step [750/760], Total Loss: 3.1986\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 35/100 [1:21:43<2:31:40, 140.01s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [35/100], Step [760/760], Total Loss: 3.2381\nEpoch [36/100], Step [10/760], Total Loss: 3.1908\nEpoch [36/100], Step [20/760], Total Loss: 3.1913\nEpoch [36/100], Step [30/760], Total Loss: 3.1819\nEpoch [36/100], Step [40/760], Total Loss: 3.1463\nEpoch [36/100], Step [50/760], Total Loss: 3.2117\nEpoch [36/100], Step [60/760], Total Loss: 3.2167\nEpoch [36/100], Step [70/760], Total Loss: 3.1945\nEpoch [36/100], Step [80/760], Total Loss: 3.2028\nEpoch [36/100], Step [90/760], Total Loss: 3.2083\nEpoch [36/100], Step [100/760], Total Loss: 3.1707\nEpoch [36/100], Step [110/760], Total Loss: 3.1949\nEpoch [36/100], Step [120/760], Total Loss: 3.1653\nEpoch [36/100], Step [130/760], Total Loss: 3.2220\nEpoch [36/100], Step [140/760], Total Loss: 3.1481\nEpoch [36/100], Step [150/760], Total Loss: 3.2059\nEpoch [36/100], Step [160/760], Total Loss: 3.1601\nEpoch [36/100], Step [170/760], Total Loss: 3.1660\nEpoch [36/100], Step [180/760], Total Loss: 3.2055\nEpoch [36/100], Step [190/760], Total Loss: 3.2018\nEpoch [36/100], Step [200/760], Total Loss: 3.1582\nEpoch [36/100], Step [210/760], Total Loss: 3.1893\nEpoch [36/100], Step [220/760], Total Loss: 3.1949\nEpoch [36/100], Step [230/760], Total Loss: 3.1584\nEpoch [36/100], Step [240/760], Total Loss: 3.0960\nEpoch [36/100], Step [250/760], Total Loss: 3.2536\nEpoch [36/100], Step [260/760], Total Loss: 3.1865\nEpoch [36/100], Step [270/760], Total Loss: 3.1789\nEpoch [36/100], Step [280/760], Total Loss: 3.1704\nEpoch [36/100], Step [290/760], Total Loss: 3.3005\nEpoch [36/100], Step [300/760], Total Loss: 3.1122\nEpoch [36/100], Step [310/760], Total Loss: 3.1869\nEpoch [36/100], Step [320/760], Total Loss: 3.1784\nEpoch [36/100], Step [330/760], Total Loss: 3.1932\nEpoch [36/100], Step [340/760], Total Loss: 3.1279\nEpoch [36/100], Step [350/760], Total Loss: 3.1702\nEpoch [36/100], Step [360/760], Total Loss: 3.2014\nEpoch [36/100], Step [370/760], Total Loss: 3.1880\nEpoch [36/100], Step [380/760], Total Loss: 3.1614\nEpoch [36/100], Step [390/760], Total Loss: 3.2111\nEpoch [36/100], Step [400/760], Total Loss: 3.1759\nEpoch [36/100], Step [410/760], Total Loss: 3.2261\nEpoch [36/100], Step [420/760], Total Loss: 3.1814\nEpoch [36/100], Step [430/760], Total Loss: 3.1776\nEpoch [36/100], Step [440/760], Total Loss: 3.1570\nEpoch [36/100], Step [450/760], Total Loss: 3.1927\nEpoch [36/100], Step [460/760], Total Loss: 3.1928\nEpoch [36/100], Step [470/760], Total Loss: 3.2421\nEpoch [36/100], Step [480/760], Total Loss: 3.2202\nEpoch [36/100], Step [490/760], Total Loss: 3.2024\nEpoch [36/100], Step [500/760], Total Loss: 3.2117\nEpoch [36/100], Step [510/760], Total Loss: 3.1508\nEpoch [36/100], Step [520/760], Total Loss: 3.2131\nEpoch [36/100], Step [530/760], Total Loss: 3.1405\nEpoch [36/100], Step [540/760], Total Loss: 3.1926\nEpoch [36/100], Step [550/760], Total Loss: 3.1826\nEpoch [36/100], Step [560/760], Total Loss: 3.1310\nEpoch [36/100], Step [570/760], Total Loss: 3.1221\nEpoch [36/100], Step [580/760], Total Loss: 3.1431\nEpoch [36/100], Step [590/760], Total Loss: 3.2498\nEpoch [36/100], Step [600/760], Total Loss: 3.1678\nEpoch [36/100], Step [610/760], Total Loss: 3.1837\nEpoch [36/100], Step [620/760], Total Loss: 3.2306\nEpoch [36/100], Step [630/760], Total Loss: 3.2298\nEpoch [36/100], Step [640/760], Total Loss: 3.2062\nEpoch [36/100], Step [650/760], Total Loss: 3.2194\nEpoch [36/100], Step [660/760], Total Loss: 3.2260\nEpoch [36/100], Step [670/760], Total Loss: 3.1788\nEpoch [36/100], Step [680/760], Total Loss: 3.1606\nEpoch [36/100], Step [690/760], Total Loss: 3.1737\nEpoch [36/100], Step [700/760], Total Loss: 3.2484\nEpoch [36/100], Step [710/760], Total Loss: 3.1990\nEpoch [36/100], Step [720/760], Total Loss: 3.1640\nEpoch [36/100], Step [730/760], Total Loss: 3.1540\nEpoch [36/100], Step [740/760], Total Loss: 3.2363\nEpoch [36/100], Step [750/760], Total Loss: 3.1121\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 36/100 [1:24:03<2:29:19, 139.99s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [36/100], Step [760/760], Total Loss: 3.1376\nEpoch [37/100], Step [10/760], Total Loss: 3.1373\nEpoch [37/100], Step [20/760], Total Loss: 3.1181\nEpoch [37/100], Step [30/760], Total Loss: 3.1573\nEpoch [37/100], Step [40/760], Total Loss: 3.1575\nEpoch [37/100], Step [50/760], Total Loss: 3.2839\nEpoch [37/100], Step [60/760], Total Loss: 3.1316\nEpoch [37/100], Step [70/760], Total Loss: 3.1496\nEpoch [37/100], Step [80/760], Total Loss: 3.1110\nEpoch [37/100], Step [90/760], Total Loss: 3.1457\nEpoch [37/100], Step [100/760], Total Loss: 3.1524\nEpoch [37/100], Step [110/760], Total Loss: 3.1892\nEpoch [37/100], Step [120/760], Total Loss: 3.1692\nEpoch [37/100], Step [130/760], Total Loss: 3.1888\nEpoch [37/100], Step [140/760], Total Loss: 3.1794\nEpoch [37/100], Step [150/760], Total Loss: 3.1500\nEpoch [37/100], Step [160/760], Total Loss: 3.1896\nEpoch [37/100], Step [170/760], Total Loss: 3.1556\nEpoch [37/100], Step [180/760], Total Loss: 3.2064\nEpoch [37/100], Step [190/760], Total Loss: 3.1952\nEpoch [37/100], Step [200/760], Total Loss: 3.1996\nEpoch [37/100], Step [210/760], Total Loss: 3.1745\nEpoch [37/100], Step [220/760], Total Loss: 3.1153\nEpoch [37/100], Step [230/760], Total Loss: 3.1912\nEpoch [37/100], Step [240/760], Total Loss: 3.1739\nEpoch [37/100], Step [250/760], Total Loss: 3.1507\nEpoch [37/100], Step [260/760], Total Loss: 3.1570\nEpoch [37/100], Step [270/760], Total Loss: 3.1949\nEpoch [37/100], Step [280/760], Total Loss: 3.1470\nEpoch [37/100], Step [290/760], Total Loss: 3.1254\nEpoch [37/100], Step [300/760], Total Loss: 3.1887\nEpoch [37/100], Step [310/760], Total Loss: 3.2687\nEpoch [37/100], Step [320/760], Total Loss: 3.2332\nEpoch [37/100], Step [330/760], Total Loss: 3.1441\nEpoch [37/100], Step [340/760], Total Loss: 3.2318\nEpoch [37/100], Step [350/760], Total Loss: 3.1349\nEpoch [37/100], Step [360/760], Total Loss: 3.1915\nEpoch [37/100], Step [370/760], Total Loss: 3.2720\nEpoch [37/100], Step [380/760], Total Loss: 3.1289\nEpoch [37/100], Step [390/760], Total Loss: 3.1253\nEpoch [37/100], Step [400/760], Total Loss: 3.1700\nEpoch [37/100], Step [410/760], Total Loss: 3.1842\nEpoch [37/100], Step [420/760], Total Loss: 3.1686\nEpoch [37/100], Step [430/760], Total Loss: 3.2220\nEpoch [37/100], Step [440/760], Total Loss: 3.1696\nEpoch [37/100], Step [450/760], Total Loss: 3.1908\nEpoch [37/100], Step [460/760], Total Loss: 3.2519\nEpoch [37/100], Step [470/760], Total Loss: 3.2208\nEpoch [37/100], Step [480/760], Total Loss: 3.1742\nEpoch [37/100], Step [490/760], Total Loss: 3.2390\nEpoch [37/100], Step [500/760], Total Loss: 3.1735\nEpoch [37/100], Step [510/760], Total Loss: 3.1509\nEpoch [37/100], Step [520/760], Total Loss: 3.1695\nEpoch [37/100], Step [530/760], Total Loss: 3.2106\nEpoch [37/100], Step [540/760], Total Loss: 3.1883\nEpoch [37/100], Step [550/760], Total Loss: 3.2000\nEpoch [37/100], Step [560/760], Total Loss: 3.2311\nEpoch [37/100], Step [570/760], Total Loss: 3.1661\nEpoch [37/100], Step [580/760], Total Loss: 3.1843\nEpoch [37/100], Step [590/760], Total Loss: 3.2440\nEpoch [37/100], Step [600/760], Total Loss: 3.1826\nEpoch [37/100], Step [610/760], Total Loss: 3.1851\nEpoch [37/100], Step [620/760], Total Loss: 3.1372\nEpoch [37/100], Step [630/760], Total Loss: 3.1716\nEpoch [37/100], Step [640/760], Total Loss: 3.2310\nEpoch [37/100], Step [650/760], Total Loss: 3.1591\nEpoch [37/100], Step [660/760], Total Loss: 3.1196\nEpoch [37/100], Step [670/760], Total Loss: 3.1295\nEpoch [37/100], Step [680/760], Total Loss: 3.2234\nEpoch [37/100], Step [690/760], Total Loss: 3.2247\nEpoch [37/100], Step [700/760], Total Loss: 3.0760\nEpoch [37/100], Step [710/760], Total Loss: 3.1525\nEpoch [37/100], Step [720/760], Total Loss: 3.1713\nEpoch [37/100], Step [730/760], Total Loss: 3.2016\nEpoch [37/100], Step [740/760], Total Loss: 3.2283\nEpoch [37/100], Step [750/760], Total Loss: 3.2341\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 37/100 [1:26:23<2:26:58, 139.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [37/100], Step [760/760], Total Loss: 3.3023\nEpoch [38/100], Step [10/760], Total Loss: 3.1832\nEpoch [38/100], Step [20/760], Total Loss: 3.1998\nEpoch [38/100], Step [30/760], Total Loss: 3.1498\nEpoch [38/100], Step [40/760], Total Loss: 3.2243\nEpoch [38/100], Step [50/760], Total Loss: 3.1476\nEpoch [38/100], Step [60/760], Total Loss: 3.2061\nEpoch [38/100], Step [70/760], Total Loss: 3.0922\nEpoch [38/100], Step [80/760], Total Loss: 3.1859\nEpoch [38/100], Step [90/760], Total Loss: 3.2095\nEpoch [38/100], Step [100/760], Total Loss: 3.1866\nEpoch [38/100], Step [110/760], Total Loss: 3.2112\nEpoch [38/100], Step [120/760], Total Loss: 3.0705\nEpoch [38/100], Step [130/760], Total Loss: 3.2081\nEpoch [38/100], Step [140/760], Total Loss: 3.2240\nEpoch [38/100], Step [150/760], Total Loss: 3.2562\nEpoch [38/100], Step [160/760], Total Loss: 3.1831\nEpoch [38/100], Step [170/760], Total Loss: 3.1143\nEpoch [38/100], Step [180/760], Total Loss: 3.1529\nEpoch [38/100], Step [190/760], Total Loss: 3.1376\nEpoch [38/100], Step [200/760], Total Loss: 3.2120\nEpoch [38/100], Step [210/760], Total Loss: 3.1215\nEpoch [38/100], Step [220/760], Total Loss: 3.1576\nEpoch [38/100], Step [230/760], Total Loss: 3.1821\nEpoch [38/100], Step [240/760], Total Loss: 3.2075\nEpoch [38/100], Step [250/760], Total Loss: 3.1844\nEpoch [38/100], Step [260/760], Total Loss: 3.2057\nEpoch [38/100], Step [270/760], Total Loss: 3.2216\nEpoch [38/100], Step [280/760], Total Loss: 3.2267\nEpoch [38/100], Step [290/760], Total Loss: 3.1834\nEpoch [38/100], Step [300/760], Total Loss: 3.1876\nEpoch [38/100], Step [310/760], Total Loss: 3.1355\nEpoch [38/100], Step [320/760], Total Loss: 3.2176\nEpoch [38/100], Step [330/760], Total Loss: 3.1746\nEpoch [38/100], Step [340/760], Total Loss: 3.1678\nEpoch [38/100], Step [350/760], Total Loss: 3.2431\nEpoch [38/100], Step [360/760], Total Loss: 3.1877\nEpoch [38/100], Step [370/760], Total Loss: 3.1433\nEpoch [38/100], Step [380/760], Total Loss: 3.1926\nEpoch [38/100], Step [390/760], Total Loss: 3.1322\nEpoch [38/100], Step [400/760], Total Loss: 3.1325\nEpoch [38/100], Step [410/760], Total Loss: 3.1360\nEpoch [38/100], Step [420/760], Total Loss: 3.2258\nEpoch [38/100], Step [430/760], Total Loss: 3.1709\nEpoch [38/100], Step [440/760], Total Loss: 3.2247\nEpoch [38/100], Step [450/760], Total Loss: 3.1652\nEpoch [38/100], Step [460/760], Total Loss: 3.1808\nEpoch [38/100], Step [470/760], Total Loss: 3.2171\nEpoch [38/100], Step [480/760], Total Loss: 3.2323\nEpoch [38/100], Step [490/760], Total Loss: 3.2100\nEpoch [38/100], Step [500/760], Total Loss: 3.1608\nEpoch [38/100], Step [510/760], Total Loss: 3.1855\nEpoch [38/100], Step [520/760], Total Loss: 3.1426\nEpoch [38/100], Step [530/760], Total Loss: 3.2747\nEpoch [38/100], Step [540/760], Total Loss: 3.1972\nEpoch [38/100], Step [550/760], Total Loss: 3.1115\nEpoch [38/100], Step [560/760], Total Loss: 3.2100\nEpoch [38/100], Step [570/760], Total Loss: 3.1407\nEpoch [38/100], Step [580/760], Total Loss: 3.1838\nEpoch [38/100], Step [590/760], Total Loss: 3.1649\nEpoch [38/100], Step [600/760], Total Loss: 3.1772\nEpoch [38/100], Step [610/760], Total Loss: 3.2012\nEpoch [38/100], Step [620/760], Total Loss: 3.2063\nEpoch [38/100], Step [630/760], Total Loss: 3.2398\nEpoch [38/100], Step [640/760], Total Loss: 3.1952\nEpoch [38/100], Step [650/760], Total Loss: 3.2113\nEpoch [38/100], Step [660/760], Total Loss: 3.1719\nEpoch [38/100], Step [670/760], Total Loss: 3.1807\nEpoch [38/100], Step [680/760], Total Loss: 3.1858\nEpoch [38/100], Step [690/760], Total Loss: 3.2016\nEpoch [38/100], Step [700/760], Total Loss: 3.2195\nEpoch [38/100], Step [710/760], Total Loss: 3.1370\nEpoch [38/100], Step [720/760], Total Loss: 3.1574\nEpoch [38/100], Step [730/760], Total Loss: 3.0863\nEpoch [38/100], Step [740/760], Total Loss: 3.2334\nEpoch [38/100], Step [750/760], Total Loss: 3.1399\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 38/100 [1:28:43<2:24:40, 140.01s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [38/100], Step [760/760], Total Loss: 3.1281\nEpoch [39/100], Step [10/760], Total Loss: 3.1693\nEpoch [39/100], Step [20/760], Total Loss: 3.2007\nEpoch [39/100], Step [30/760], Total Loss: 3.2566\nEpoch [39/100], Step [40/760], Total Loss: 3.1141\nEpoch [39/100], Step [50/760], Total Loss: 3.2508\nEpoch [39/100], Step [60/760], Total Loss: 3.1510\nEpoch [39/100], Step [70/760], Total Loss: 3.1813\nEpoch [39/100], Step [80/760], Total Loss: 3.2444\nEpoch [39/100], Step [90/760], Total Loss: 3.1605\nEpoch [39/100], Step [100/760], Total Loss: 3.2179\nEpoch [39/100], Step [110/760], Total Loss: 3.1957\nEpoch [39/100], Step [120/760], Total Loss: 3.2065\nEpoch [39/100], Step [130/760], Total Loss: 3.0931\nEpoch [39/100], Step [140/760], Total Loss: 3.1560\nEpoch [39/100], Step [150/760], Total Loss: 3.1619\nEpoch [39/100], Step [160/760], Total Loss: 3.1546\nEpoch [39/100], Step [170/760], Total Loss: 3.1085\nEpoch [39/100], Step [180/760], Total Loss: 3.2670\nEpoch [39/100], Step [190/760], Total Loss: 3.1270\nEpoch [39/100], Step [200/760], Total Loss: 3.1617\nEpoch [39/100], Step [210/760], Total Loss: 3.2119\nEpoch [39/100], Step [220/760], Total Loss: 3.2407\nEpoch [39/100], Step [230/760], Total Loss: 3.1145\nEpoch [39/100], Step [240/760], Total Loss: 3.2070\nEpoch [39/100], Step [250/760], Total Loss: 3.1876\nEpoch [39/100], Step [260/760], Total Loss: 3.1873\nEpoch [39/100], Step [270/760], Total Loss: 3.1979\nEpoch [39/100], Step [280/760], Total Loss: 3.1336\nEpoch [39/100], Step [290/760], Total Loss: 3.2016\nEpoch [39/100], Step [300/760], Total Loss: 3.2126\nEpoch [39/100], Step [310/760], Total Loss: 3.1856\nEpoch [39/100], Step [320/760], Total Loss: 3.1729\nEpoch [39/100], Step [330/760], Total Loss: 3.1933\nEpoch [39/100], Step [340/760], Total Loss: 3.1734\nEpoch [39/100], Step [350/760], Total Loss: 3.2115\nEpoch [39/100], Step [360/760], Total Loss: 3.1253\nEpoch [39/100], Step [370/760], Total Loss: 3.1697\nEpoch [39/100], Step [380/760], Total Loss: 3.1538\nEpoch [39/100], Step [390/760], Total Loss: 3.2078\nEpoch [39/100], Step [400/760], Total Loss: 3.1000\nEpoch [39/100], Step [410/760], Total Loss: 3.1826\nEpoch [39/100], Step [420/760], Total Loss: 3.1517\nEpoch [39/100], Step [430/760], Total Loss: 3.1673\nEpoch [39/100], Step [440/760], Total Loss: 3.2001\nEpoch [39/100], Step [450/760], Total Loss: 3.1705\nEpoch [39/100], Step [460/760], Total Loss: 3.1146\nEpoch [39/100], Step [470/760], Total Loss: 3.0749\nEpoch [39/100], Step [480/760], Total Loss: 3.1458\nEpoch [39/100], Step [490/760], Total Loss: 3.1844\nEpoch [39/100], Step [500/760], Total Loss: 3.1453\nEpoch [39/100], Step [510/760], Total Loss: 3.1308\nEpoch [39/100], Step [520/760], Total Loss: 3.1656\nEpoch [39/100], Step [530/760], Total Loss: 3.1504\nEpoch [39/100], Step [540/760], Total Loss: 3.1009\nEpoch [39/100], Step [550/760], Total Loss: 3.1999\nEpoch [39/100], Step [560/760], Total Loss: 3.1434\nEpoch [39/100], Step [570/760], Total Loss: 3.2403\nEpoch [39/100], Step [580/760], Total Loss: 3.1811\nEpoch [39/100], Step [590/760], Total Loss: 3.0982\nEpoch [39/100], Step [600/760], Total Loss: 3.1922\nEpoch [39/100], Step [610/760], Total Loss: 3.1581\nEpoch [39/100], Step [620/760], Total Loss: 3.1854\nEpoch [39/100], Step [630/760], Total Loss: 3.1839\nEpoch [39/100], Step [640/760], Total Loss: 3.1566\nEpoch [39/100], Step [650/760], Total Loss: 3.1265\nEpoch [39/100], Step [660/760], Total Loss: 3.1174\nEpoch [39/100], Step [670/760], Total Loss: 3.1503\nEpoch [39/100], Step [680/760], Total Loss: 3.1288\nEpoch [39/100], Step [690/760], Total Loss: 3.1646\nEpoch [39/100], Step [700/760], Total Loss: 3.1741\nEpoch [39/100], Step [710/760], Total Loss: 3.1391\nEpoch [39/100], Step [720/760], Total Loss: 3.2480\nEpoch [39/100], Step [730/760], Total Loss: 3.1843\nEpoch [39/100], Step [740/760], Total Loss: 3.1582\nEpoch [39/100], Step [750/760], Total Loss: 3.1948\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 39/100 [1:31:03<2:22:19, 139.99s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [39/100], Step [760/760], Total Loss: 3.1654\nEpoch [40/100], Step [10/760], Total Loss: 3.2384\nEpoch [40/100], Step [20/760], Total Loss: 3.1670\nEpoch [40/100], Step [30/760], Total Loss: 3.1784\nEpoch [40/100], Step [40/760], Total Loss: 3.1722\nEpoch [40/100], Step [50/760], Total Loss: 3.2415\nEpoch [40/100], Step [60/760], Total Loss: 3.1293\nEpoch [40/100], Step [70/760], Total Loss: 3.1811\nEpoch [40/100], Step [80/760], Total Loss: 3.1145\nEpoch [40/100], Step [90/760], Total Loss: 3.2063\nEpoch [40/100], Step [100/760], Total Loss: 3.0685\nEpoch [40/100], Step [110/760], Total Loss: 3.1082\nEpoch [40/100], Step [120/760], Total Loss: 3.2132\nEpoch [40/100], Step [130/760], Total Loss: 3.1250\nEpoch [40/100], Step [140/760], Total Loss: 3.1807\nEpoch [40/100], Step [150/760], Total Loss: 3.0673\nEpoch [40/100], Step [160/760], Total Loss: 3.1358\nEpoch [40/100], Step [170/760], Total Loss: 3.1698\nEpoch [40/100], Step [180/760], Total Loss: 3.2010\nEpoch [40/100], Step [190/760], Total Loss: 3.1181\nEpoch [40/100], Step [200/760], Total Loss: 3.1773\nEpoch [40/100], Step [210/760], Total Loss: 3.1018\nEpoch [40/100], Step [220/760], Total Loss: 3.1726\nEpoch [40/100], Step [230/760], Total Loss: 3.0990\nEpoch [40/100], Step [240/760], Total Loss: 3.1595\nEpoch [40/100], Step [250/760], Total Loss: 3.1503\nEpoch [40/100], Step [260/760], Total Loss: 3.1452\nEpoch [40/100], Step [270/760], Total Loss: 3.1348\nEpoch [40/100], Step [280/760], Total Loss: 3.1163\nEpoch [40/100], Step [290/760], Total Loss: 3.1312\nEpoch [40/100], Step [300/760], Total Loss: 3.0923\nEpoch [40/100], Step [310/760], Total Loss: 3.1469\nEpoch [40/100], Step [320/760], Total Loss: 3.1466\nEpoch [40/100], Step [330/760], Total Loss: 3.1920\nEpoch [40/100], Step [340/760], Total Loss: 3.1855\nEpoch [40/100], Step [350/760], Total Loss: 3.1930\nEpoch [40/100], Step [360/760], Total Loss: 3.0985\nEpoch [40/100], Step [370/760], Total Loss: 3.1444\nEpoch [40/100], Step [380/760], Total Loss: 3.0889\nEpoch [40/100], Step [390/760], Total Loss: 3.1521\nEpoch [40/100], Step [400/760], Total Loss: 3.1424\nEpoch [40/100], Step [410/760], Total Loss: 3.2078\nEpoch [40/100], Step [420/760], Total Loss: 3.1308\nEpoch [40/100], Step [430/760], Total Loss: 3.1425\nEpoch [40/100], Step [440/760], Total Loss: 3.1631\nEpoch [40/100], Step [450/760], Total Loss: 3.0855\nEpoch [40/100], Step [460/760], Total Loss: 3.1265\nEpoch [40/100], Step [470/760], Total Loss: 3.1589\nEpoch [40/100], Step [480/760], Total Loss: 3.1732\nEpoch [40/100], Step [490/760], Total Loss: 3.1360\nEpoch [40/100], Step [500/760], Total Loss: 3.1416\nEpoch [40/100], Step [510/760], Total Loss: 3.1219\nEpoch [40/100], Step [520/760], Total Loss: 3.1611\nEpoch [40/100], Step [530/760], Total Loss: 3.1151\nEpoch [40/100], Step [540/760], Total Loss: 3.1317\nEpoch [40/100], Step [550/760], Total Loss: 3.1516\nEpoch [40/100], Step [560/760], Total Loss: 3.1777\nEpoch [40/100], Step [570/760], Total Loss: 3.1517\nEpoch [40/100], Step [580/760], Total Loss: 3.1915\nEpoch [40/100], Step [590/760], Total Loss: 3.1954\nEpoch [40/100], Step [600/760], Total Loss: 3.2397\nEpoch [40/100], Step [610/760], Total Loss: 3.1995\nEpoch [40/100], Step [620/760], Total Loss: 3.2149\nEpoch [40/100], Step [630/760], Total Loss: 3.1554\nEpoch [40/100], Step [640/760], Total Loss: 3.1541\nEpoch [40/100], Step [650/760], Total Loss: 3.1185\nEpoch [40/100], Step [660/760], Total Loss: 3.1169\nEpoch [40/100], Step [670/760], Total Loss: 3.1619\nEpoch [40/100], Step [680/760], Total Loss: 3.2307\nEpoch [40/100], Step [690/760], Total Loss: 3.1617\nEpoch [40/100], Step [700/760], Total Loss: 3.1470\nEpoch [40/100], Step [710/760], Total Loss: 3.1570\nEpoch [40/100], Step [720/760], Total Loss: 3.1954\nEpoch [40/100], Step [730/760], Total Loss: 3.1349\nEpoch [40/100], Step [740/760], Total Loss: 3.1903\nEpoch [40/100], Step [750/760], Total Loss: 3.1065\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 40/100 [1:33:23<2:19:58, 139.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [40/100], Step [760/760], Total Loss: 3.1634\nEpoch [41/100], Step [10/760], Total Loss: 3.1330\nEpoch [41/100], Step [20/760], Total Loss: 3.0628\nEpoch [41/100], Step [30/760], Total Loss: 3.2793\nEpoch [41/100], Step [40/760], Total Loss: 3.1140\nEpoch [41/100], Step [50/760], Total Loss: 3.1505\nEpoch [41/100], Step [60/760], Total Loss: 3.1607\nEpoch [41/100], Step [70/760], Total Loss: 3.1541\nEpoch [41/100], Step [80/760], Total Loss: 3.1402\nEpoch [41/100], Step [90/760], Total Loss: 3.1849\nEpoch [41/100], Step [100/760], Total Loss: 3.1356\nEpoch [41/100], Step [110/760], Total Loss: 3.1286\nEpoch [41/100], Step [120/760], Total Loss: 3.1512\nEpoch [41/100], Step [130/760], Total Loss: 3.1293\nEpoch [41/100], Step [140/760], Total Loss: 3.1634\nEpoch [41/100], Step [150/760], Total Loss: 3.0975\nEpoch [41/100], Step [160/760], Total Loss: 3.1612\nEpoch [41/100], Step [170/760], Total Loss: 3.0912\nEpoch [41/100], Step [180/760], Total Loss: 3.1814\nEpoch [41/100], Step [190/760], Total Loss: 3.1504\nEpoch [41/100], Step [200/760], Total Loss: 3.1674\nEpoch [41/100], Step [210/760], Total Loss: 3.1734\nEpoch [41/100], Step [220/760], Total Loss: 3.1968\nEpoch [41/100], Step [230/760], Total Loss: 3.1610\nEpoch [41/100], Step [240/760], Total Loss: 3.1822\nEpoch [41/100], Step [250/760], Total Loss: 3.1438\nEpoch [41/100], Step [260/760], Total Loss: 3.1506\nEpoch [41/100], Step [270/760], Total Loss: 3.1104\nEpoch [41/100], Step [280/760], Total Loss: 3.1235\nEpoch [41/100], Step [290/760], Total Loss: 3.0985\nEpoch [41/100], Step [300/760], Total Loss: 3.0869\nEpoch [41/100], Step [310/760], Total Loss: 3.1670\nEpoch [41/100], Step [320/760], Total Loss: 3.1439\nEpoch [41/100], Step [330/760], Total Loss: 3.1544\nEpoch [41/100], Step [340/760], Total Loss: 3.1537\nEpoch [41/100], Step [350/760], Total Loss: 3.1291\nEpoch [41/100], Step [360/760], Total Loss: 3.1506\nEpoch [41/100], Step [370/760], Total Loss: 3.1360\nEpoch [41/100], Step [380/760], Total Loss: 3.1745\nEpoch [41/100], Step [390/760], Total Loss: 3.2621\nEpoch [41/100], Step [400/760], Total Loss: 3.1591\nEpoch [41/100], Step [410/760], Total Loss: 3.1780\nEpoch [41/100], Step [420/760], Total Loss: 3.1039\nEpoch [41/100], Step [430/760], Total Loss: 3.0553\nEpoch [41/100], Step [440/760], Total Loss: 3.2012\nEpoch [41/100], Step [450/760], Total Loss: 3.1556\nEpoch [41/100], Step [460/760], Total Loss: 3.1649\nEpoch [41/100], Step [470/760], Total Loss: 3.1244\nEpoch [41/100], Step [480/760], Total Loss: 3.1159\nEpoch [41/100], Step [490/760], Total Loss: 3.2604\nEpoch [41/100], Step [500/760], Total Loss: 3.1449\nEpoch [41/100], Step [510/760], Total Loss: 3.1873\nEpoch [41/100], Step [520/760], Total Loss: 3.1250\nEpoch [41/100], Step [530/760], Total Loss: 3.1095\nEpoch [41/100], Step [540/760], Total Loss: 3.1580\nEpoch [41/100], Step [550/760], Total Loss: 3.1475\nEpoch [41/100], Step [560/760], Total Loss: 3.0902\nEpoch [41/100], Step [570/760], Total Loss: 3.1370\nEpoch [41/100], Step [580/760], Total Loss: 3.1327\nEpoch [41/100], Step [590/760], Total Loss: 3.1086\nEpoch [41/100], Step [600/760], Total Loss: 3.1043\nEpoch [41/100], Step [610/760], Total Loss: 3.1692\nEpoch [41/100], Step [620/760], Total Loss: 3.1025\nEpoch [41/100], Step [630/760], Total Loss: 3.1898\nEpoch [41/100], Step [640/760], Total Loss: 3.1106\nEpoch [41/100], Step [650/760], Total Loss: 3.1021\nEpoch [41/100], Step [660/760], Total Loss: 3.1806\nEpoch [41/100], Step [670/760], Total Loss: 3.1832\nEpoch [41/100], Step [680/760], Total Loss: 3.1172\nEpoch [41/100], Step [690/760], Total Loss: 3.1132\nEpoch [41/100], Step [700/760], Total Loss: 3.1382\nEpoch [41/100], Step [710/760], Total Loss: 3.1898\nEpoch [41/100], Step [720/760], Total Loss: 3.1882\nEpoch [41/100], Step [730/760], Total Loss: 3.0769\nEpoch [41/100], Step [740/760], Total Loss: 3.1565\nEpoch [41/100], Step [750/760], Total Loss: 3.2263\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 41/100 [1:35:42<2:17:37, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [41/100], Step [760/760], Total Loss: 3.1873\nEpoch [42/100], Step [10/760], Total Loss: 3.1066\nEpoch [42/100], Step [20/760], Total Loss: 3.2493\nEpoch [42/100], Step [30/760], Total Loss: 3.1286\nEpoch [42/100], Step [40/760], Total Loss: 3.1313\nEpoch [42/100], Step [50/760], Total Loss: 3.1896\nEpoch [42/100], Step [60/760], Total Loss: 3.1730\nEpoch [42/100], Step [70/760], Total Loss: 3.1296\nEpoch [42/100], Step [80/760], Total Loss: 3.1133\nEpoch [42/100], Step [90/760], Total Loss: 3.1665\nEpoch [42/100], Step [100/760], Total Loss: 3.1869\nEpoch [42/100], Step [110/760], Total Loss: 3.1664\nEpoch [42/100], Step [120/760], Total Loss: 3.1276\nEpoch [42/100], Step [130/760], Total Loss: 3.1813\nEpoch [42/100], Step [140/760], Total Loss: 3.1956\nEpoch [42/100], Step [150/760], Total Loss: 3.2051\nEpoch [42/100], Step [160/760], Total Loss: 3.1418\nEpoch [42/100], Step [170/760], Total Loss: 3.1693\nEpoch [42/100], Step [180/760], Total Loss: 3.1418\nEpoch [42/100], Step [190/760], Total Loss: 3.1317\nEpoch [42/100], Step [200/760], Total Loss: 3.1572\nEpoch [42/100], Step [210/760], Total Loss: 3.1059\nEpoch [42/100], Step [220/760], Total Loss: 3.1430\nEpoch [42/100], Step [230/760], Total Loss: 3.1999\nEpoch [42/100], Step [240/760], Total Loss: 3.1483\nEpoch [42/100], Step [250/760], Total Loss: 3.1342\nEpoch [42/100], Step [260/760], Total Loss: 3.1594\nEpoch [42/100], Step [270/760], Total Loss: 3.1385\nEpoch [42/100], Step [280/760], Total Loss: 3.1396\nEpoch [42/100], Step [290/760], Total Loss: 3.0730\nEpoch [42/100], Step [300/760], Total Loss: 3.1457\nEpoch [42/100], Step [310/760], Total Loss: 3.1532\nEpoch [42/100], Step [320/760], Total Loss: 3.1335\nEpoch [42/100], Step [330/760], Total Loss: 3.1382\nEpoch [42/100], Step [340/760], Total Loss: 3.1220\nEpoch [42/100], Step [350/760], Total Loss: 3.1060\nEpoch [42/100], Step [360/760], Total Loss: 3.2149\nEpoch [42/100], Step [370/760], Total Loss: 3.1242\nEpoch [42/100], Step [380/760], Total Loss: 3.1502\nEpoch [42/100], Step [390/760], Total Loss: 3.1252\nEpoch [42/100], Step [400/760], Total Loss: 3.1306\nEpoch [42/100], Step [410/760], Total Loss: 3.1788\nEpoch [42/100], Step [420/760], Total Loss: 3.0741\nEpoch [42/100], Step [430/760], Total Loss: 3.2402\nEpoch [42/100], Step [440/760], Total Loss: 3.1304\nEpoch [42/100], Step [450/760], Total Loss: 3.1433\nEpoch [42/100], Step [460/760], Total Loss: 3.1244\nEpoch [42/100], Step [470/760], Total Loss: 3.1857\nEpoch [42/100], Step [480/760], Total Loss: 3.2081\nEpoch [42/100], Step [490/760], Total Loss: 3.1259\nEpoch [42/100], Step [500/760], Total Loss: 3.2345\nEpoch [42/100], Step [510/760], Total Loss: 3.1149\nEpoch [42/100], Step [520/760], Total Loss: 3.1529\nEpoch [42/100], Step [530/760], Total Loss: 3.0930\nEpoch [42/100], Step [540/760], Total Loss: 3.2525\nEpoch [42/100], Step [550/760], Total Loss: 3.0989\nEpoch [42/100], Step [560/760], Total Loss: 3.1211\nEpoch [42/100], Step [570/760], Total Loss: 3.1318\nEpoch [42/100], Step [580/760], Total Loss: 3.1867\nEpoch [42/100], Step [590/760], Total Loss: 3.1254\nEpoch [42/100], Step [600/760], Total Loss: 3.1696\nEpoch [42/100], Step [610/760], Total Loss: 3.1533\nEpoch [42/100], Step [620/760], Total Loss: 3.1299\nEpoch [42/100], Step [660/760], Total Loss: 3.0709\nEpoch [42/100], Step [670/760], Total Loss: 3.1161\nEpoch [42/100], Step [680/760], Total Loss: 3.2590\nEpoch [42/100], Step [690/760], Total Loss: 3.1184\nEpoch [42/100], Step [700/760], Total Loss: 3.1390\nEpoch [42/100], Step [710/760], Total Loss: 3.1991\nEpoch [42/100], Step [720/760], Total Loss: 3.1584\nEpoch [42/100], Step [730/760], Total Loss: 3.1813\nEpoch [42/100], Step [740/760], Total Loss: 3.2113\nEpoch [42/100], Step [750/760], Total Loss: 3.1116\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 42/100 [1:38:02<2:15:17, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [42/100], Step [760/760], Total Loss: 3.1826\nEpoch [43/100], Step [10/760], Total Loss: 3.1309\nEpoch [43/100], Step [20/760], Total Loss: 3.1188\nEpoch [43/100], Step [30/760], Total Loss: 3.1467\nEpoch [43/100], Step [40/760], Total Loss: 3.1294\nEpoch [43/100], Step [50/760], Total Loss: 3.1573\nEpoch [43/100], Step [60/760], Total Loss: 3.1927\nEpoch [43/100], Step [70/760], Total Loss: 3.1434\nEpoch [43/100], Step [80/760], Total Loss: 3.1715\nEpoch [43/100], Step [90/760], Total Loss: 3.1175\nEpoch [43/100], Step [100/760], Total Loss: 3.1244\nEpoch [43/100], Step [110/760], Total Loss: 3.0967\nEpoch [43/100], Step [120/760], Total Loss: 3.1656\nEpoch [43/100], Step [130/760], Total Loss: 3.2183\nEpoch [43/100], Step [140/760], Total Loss: 3.1609\nEpoch [43/100], Step [150/760], Total Loss: 3.1229\nEpoch [43/100], Step [160/760], Total Loss: 3.1840\nEpoch [43/100], Step [170/760], Total Loss: 3.0898\nEpoch [43/100], Step [180/760], Total Loss: 3.1849\nEpoch [43/100], Step [190/760], Total Loss: 3.1425\nEpoch [43/100], Step [200/760], Total Loss: 3.1413\nEpoch [43/100], Step [210/760], Total Loss: 3.1249\nEpoch [43/100], Step [220/760], Total Loss: 3.1005\nEpoch [43/100], Step [230/760], Total Loss: 3.1748\nEpoch [43/100], Step [240/760], Total Loss: 3.1111\nEpoch [43/100], Step [250/760], Total Loss: 3.1329\nEpoch [43/100], Step [260/760], Total Loss: 3.1346\nEpoch [43/100], Step [270/760], Total Loss: 3.0838\nEpoch [43/100], Step [280/760], Total Loss: 3.1464\nEpoch [43/100], Step [290/760], Total Loss: 3.1200\nEpoch [43/100], Step [300/760], Total Loss: 3.1327\nEpoch [43/100], Step [310/760], Total Loss: 3.1720\nEpoch [43/100], Step [320/760], Total Loss: 3.1631\nEpoch [43/100], Step [330/760], Total Loss: 3.2299\nEpoch [43/100], Step [340/760], Total Loss: 3.1003\nEpoch [43/100], Step [350/760], Total Loss: 3.0593\nEpoch [43/100], Step [360/760], Total Loss: 3.1322\nEpoch [43/100], Step [370/760], Total Loss: 3.1675\nEpoch [43/100], Step [380/760], Total Loss: 3.1273\nEpoch [43/100], Step [390/760], Total Loss: 3.1821\nEpoch [43/100], Step [400/760], Total Loss: 3.2040\nEpoch [43/100], Step [410/760], Total Loss: 3.1235\nEpoch [43/100], Step [420/760], Total Loss: 3.1385\nEpoch [43/100], Step [430/760], Total Loss: 3.1968\nEpoch [43/100], Step [440/760], Total Loss: 3.1450\nEpoch [43/100], Step [450/760], Total Loss: 3.1268\nEpoch [43/100], Step [460/760], Total Loss: 3.1359\nEpoch [43/100], Step [470/760], Total Loss: 3.1182\nEpoch [43/100], Step [480/760], Total Loss: 3.1397\nEpoch [43/100], Step [490/760], Total Loss: 3.1772\nEpoch [43/100], Step [500/760], Total Loss: 3.1067\nEpoch [43/100], Step [510/760], Total Loss: 3.1299\nEpoch [43/100], Step [520/760], Total Loss: 3.0933\nEpoch [43/100], Step [530/760], Total Loss: 3.1786\nEpoch [43/100], Step [540/760], Total Loss: 3.1546\nEpoch [43/100], Step [550/760], Total Loss: 3.1783\nEpoch [43/100], Step [560/760], Total Loss: 3.1170\nEpoch [43/100], Step [570/760], Total Loss: 3.0955\nEpoch [43/100], Step [580/760], Total Loss: 3.1020\nEpoch [43/100], Step [590/760], Total Loss: 3.1587\nEpoch [43/100], Step [600/760], Total Loss: 3.1388\nEpoch [43/100], Step [610/760], Total Loss: 3.1365\nEpoch [43/100], Step [620/760], Total Loss: 3.1176\nEpoch [43/100], Step [630/760], Total Loss: 3.1583\nEpoch [43/100], Step [640/760], Total Loss: 3.1129\nEpoch [43/100], Step [650/760], Total Loss: 3.1514\nEpoch [43/100], Step [660/760], Total Loss: 3.1507\nEpoch [43/100], Step [670/760], Total Loss: 3.1374\nEpoch [43/100], Step [680/760], Total Loss: 3.1882\nEpoch [43/100], Step [690/760], Total Loss: 3.1598\nEpoch [43/100], Step [700/760], Total Loss: 3.1249\nEpoch [43/100], Step [710/760], Total Loss: 3.1135\nEpoch [43/100], Step [720/760], Total Loss: 3.1940\nEpoch [43/100], Step [730/760], Total Loss: 3.1235\nEpoch [43/100], Step [740/760], Total Loss: 3.1102\nEpoch [43/100], Step [750/760], Total Loss: 3.1683\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 43/100 [1:40:22<2:12:57, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [43/100], Step [760/760], Total Loss: 3.2602\nEpoch [44/100], Step [10/760], Total Loss: 3.0796\nEpoch [44/100], Step [20/760], Total Loss: 3.0967\nEpoch [44/100], Step [30/760], Total Loss: 3.1455\nEpoch [44/100], Step [40/760], Total Loss: 3.2037\nEpoch [44/100], Step [50/760], Total Loss: 3.0713\nEpoch [44/100], Step [60/760], Total Loss: 3.1451\nEpoch [44/100], Step [70/760], Total Loss: 3.1507\nEpoch [44/100], Step [80/760], Total Loss: 3.1922\nEpoch [44/100], Step [90/760], Total Loss: 3.1398\nEpoch [44/100], Step [100/760], Total Loss: 3.1081\nEpoch [44/100], Step [110/760], Total Loss: 3.0802\nEpoch [44/100], Step [120/760], Total Loss: 3.0992\nEpoch [44/100], Step [130/760], Total Loss: 3.1479\nEpoch [44/100], Step [140/760], Total Loss: 3.1510\nEpoch [44/100], Step [150/760], Total Loss: 3.1244\nEpoch [44/100], Step [160/760], Total Loss: 3.0576\nEpoch [44/100], Step [170/760], Total Loss: 3.1673\nEpoch [44/100], Step [180/760], Total Loss: 3.1118\nEpoch [44/100], Step [190/760], Total Loss: 3.1207\nEpoch [44/100], Step [200/760], Total Loss: 3.1107\nEpoch [44/100], Step [210/760], Total Loss: 3.1590\nEpoch [44/100], Step [220/760], Total Loss: 3.1433\nEpoch [44/100], Step [230/760], Total Loss: 3.1168\nEpoch [44/100], Step [240/760], Total Loss: 3.1909\nEpoch [44/100], Step [250/760], Total Loss: 3.1729\nEpoch [44/100], Step [260/760], Total Loss: 3.1259\nEpoch [44/100], Step [270/760], Total Loss: 3.0949\nEpoch [44/100], Step [280/760], Total Loss: 3.1272\nEpoch [44/100], Step [290/760], Total Loss: 3.1122\nEpoch [44/100], Step [300/760], Total Loss: 3.0874\nEpoch [44/100], Step [310/760], Total Loss: 3.1952\nEpoch [44/100], Step [320/760], Total Loss: 3.1582\nEpoch [44/100], Step [330/760], Total Loss: 3.0978\nEpoch [44/100], Step [340/760], Total Loss: 3.1514\nEpoch [44/100], Step [350/760], Total Loss: 3.1132\nEpoch [44/100], Step [360/760], Total Loss: 3.1024\nEpoch [44/100], Step [370/760], Total Loss: 3.1056\nEpoch [44/100], Step [380/760], Total Loss: 3.0990\nEpoch [44/100], Step [390/760], Total Loss: 3.1808\nEpoch [44/100], Step [400/760], Total Loss: 3.0838\nEpoch [44/100], Step [410/760], Total Loss: 3.1590\nEpoch [44/100], Step [420/760], Total Loss: 3.1036\nEpoch [44/100], Step [430/760], Total Loss: 3.1916\nEpoch [44/100], Step [440/760], Total Loss: 3.1298\nEpoch [44/100], Step [450/760], Total Loss: 3.1946\nEpoch [44/100], Step [460/760], Total Loss: 3.1707\nEpoch [44/100], Step [470/760], Total Loss: 3.1532\nEpoch [44/100], Step [480/760], Total Loss: 3.1100\nEpoch [44/100], Step [490/760], Total Loss: 3.1216\nEpoch [44/100], Step [500/760], Total Loss: 3.1115\nEpoch [44/100], Step [510/760], Total Loss: 3.0857\nEpoch [44/100], Step [520/760], Total Loss: 3.0844\nEpoch [44/100], Step [530/760], Total Loss: 3.1411\nEpoch [44/100], Step [540/760], Total Loss: 3.1397\nEpoch [44/100], Step [550/760], Total Loss: 3.1286\nEpoch [44/100], Step [560/760], Total Loss: 3.0945\nEpoch [44/100], Step [570/760], Total Loss: 3.0881\nEpoch [44/100], Step [580/760], Total Loss: 3.1291\nEpoch [44/100], Step [590/760], Total Loss: 3.1816\nEpoch [44/100], Step [600/760], Total Loss: 3.0998\nEpoch [44/100], Step [610/760], Total Loss: 3.1403\nEpoch [44/100], Step [620/760], Total Loss: 3.0938\nEpoch [44/100], Step [630/760], Total Loss: 3.0701\nEpoch [44/100], Step [640/760], Total Loss: 3.1353\nEpoch [44/100], Step [650/760], Total Loss: 3.1732\nEpoch [44/100], Step [660/760], Total Loss: 3.1394\nEpoch [44/100], Step [670/760], Total Loss: 3.1259\nEpoch [44/100], Step [680/760], Total Loss: 3.0895\nEpoch [44/100], Step [690/760], Total Loss: 3.1619\nEpoch [44/100], Step [700/760], Total Loss: 3.1494\nEpoch [44/100], Step [710/760], Total Loss: 3.1104\nEpoch [44/100], Step [720/760], Total Loss: 3.1192\nEpoch [44/100], Step [730/760], Total Loss: 3.1537\nEpoch [44/100], Step [740/760], Total Loss: 3.1444\nEpoch [44/100], Step [750/760], Total Loss: 3.1254\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 44/100 [1:42:42<2:10:36, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [44/100], Step [760/760], Total Loss: 3.1968\nEpoch [45/100], Step [10/760], Total Loss: 3.1550\nEpoch [45/100], Step [20/760], Total Loss: 3.1677\nEpoch [45/100], Step [30/760], Total Loss: 3.1506\nEpoch [45/100], Step [40/760], Total Loss: 3.1023\nEpoch [45/100], Step [50/760], Total Loss: 3.1746\nEpoch [45/100], Step [60/760], Total Loss: 3.1256\nEpoch [45/100], Step [70/760], Total Loss: 3.0932\nEpoch [45/100], Step [80/760], Total Loss: 3.2191\nEpoch [45/100], Step [90/760], Total Loss: 3.1871\nEpoch [45/100], Step [100/760], Total Loss: 3.0967\nEpoch [45/100], Step [110/760], Total Loss: 3.1490\nEpoch [45/100], Step [120/760], Total Loss: 3.1396\nEpoch [45/100], Step [130/760], Total Loss: 3.1110\nEpoch [45/100], Step [140/760], Total Loss: 3.0862\nEpoch [45/100], Step [150/760], Total Loss: 3.1736\nEpoch [45/100], Step [160/760], Total Loss: 3.1724\nEpoch [45/100], Step [170/760], Total Loss: 3.1080\nEpoch [45/100], Step [180/760], Total Loss: 3.1729\nEpoch [45/100], Step [190/760], Total Loss: 3.1038\nEpoch [45/100], Step [200/760], Total Loss: 3.1930\nEpoch [45/100], Step [210/760], Total Loss: 3.0977\nEpoch [45/100], Step [220/760], Total Loss: 3.0867\nEpoch [45/100], Step [230/760], Total Loss: 3.1546\nEpoch [45/100], Step [240/760], Total Loss: 3.1479\nEpoch [45/100], Step [250/760], Total Loss: 3.1242\nEpoch [45/100], Step [260/760], Total Loss: 3.1147\nEpoch [45/100], Step [270/760], Total Loss: 3.0858\nEpoch [45/100], Step [280/760], Total Loss: 3.0773\nEpoch [45/100], Step [290/760], Total Loss: 3.1186\nEpoch [45/100], Step [300/760], Total Loss: 3.0925\nEpoch [45/100], Step [310/760], Total Loss: 3.0669\nEpoch [45/100], Step [320/760], Total Loss: 3.1331\nEpoch [45/100], Step [330/760], Total Loss: 3.0588\nEpoch [45/100], Step [340/760], Total Loss: 3.1153\nEpoch [45/100], Step [350/760], Total Loss: 3.1550\nEpoch [45/100], Step [360/760], Total Loss: 3.0963\nEpoch [45/100], Step [370/760], Total Loss: 3.0384\nEpoch [45/100], Step [380/760], Total Loss: 3.1995\nEpoch [45/100], Step [390/760], Total Loss: 3.2068\nEpoch [45/100], Step [400/760], Total Loss: 3.1291\nEpoch [45/100], Step [410/760], Total Loss: 3.1248\nEpoch [45/100], Step [420/760], Total Loss: 3.1650\nEpoch [45/100], Step [430/760], Total Loss: 3.1639\nEpoch [45/100], Step [440/760], Total Loss: 3.1276\nEpoch [45/100], Step [450/760], Total Loss: 3.1101\nEpoch [45/100], Step [460/760], Total Loss: 3.1795\nEpoch [45/100], Step [470/760], Total Loss: 3.1081\nEpoch [45/100], Step [480/760], Total Loss: 3.2057\nEpoch [45/100], Step [490/760], Total Loss: 3.1833\nEpoch [45/100], Step [500/760], Total Loss: 3.1146\nEpoch [45/100], Step [510/760], Total Loss: 3.1433\nEpoch [45/100], Step [520/760], Total Loss: 3.0835\nEpoch [45/100], Step [530/760], Total Loss: 3.1419\nEpoch [45/100], Step [540/760], Total Loss: 3.0962\nEpoch [45/100], Step [550/760], Total Loss: 3.1383\nEpoch [45/100], Step [560/760], Total Loss: 3.1300\nEpoch [45/100], Step [570/760], Total Loss: 3.0914\nEpoch [45/100], Step [580/760], Total Loss: 3.0887\nEpoch [45/100], Step [590/760], Total Loss: 3.2052\nEpoch [45/100], Step [600/760], Total Loss: 3.0875\nEpoch [45/100], Step [610/760], Total Loss: 3.1391\nEpoch [45/100], Step [620/760], Total Loss: 3.1011\nEpoch [45/100], Step [630/760], Total Loss: 3.1807\nEpoch [45/100], Step [640/760], Total Loss: 3.1442\nEpoch [45/100], Step [650/760], Total Loss: 3.1160\nEpoch [45/100], Step [660/760], Total Loss: 3.1347\nEpoch [45/100], Step [670/760], Total Loss: 3.1684\nEpoch [45/100], Step [680/760], Total Loss: 3.1351\nEpoch [45/100], Step [690/760], Total Loss: 3.1741\nEpoch [45/100], Step [700/760], Total Loss: 3.1517\nEpoch [45/100], Step [710/760], Total Loss: 3.1194\nEpoch [45/100], Step [720/760], Total Loss: 3.1244\nEpoch [45/100], Step [730/760], Total Loss: 3.1503\nEpoch [45/100], Step [740/760], Total Loss: 3.1137\nEpoch [45/100], Step [750/760], Total Loss: 3.1228\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 45/100 [1:45:02<2:08:16, 139.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [45/100], Step [760/760], Total Loss: 3.1088\nEpoch [46/100], Step [10/760], Total Loss: 3.0964\nEpoch [46/100], Step [20/760], Total Loss: 3.1553\nEpoch [46/100], Step [30/760], Total Loss: 3.0466\nEpoch [46/100], Step [40/760], Total Loss: 3.1352\nEpoch [46/100], Step [50/760], Total Loss: 3.1500\nEpoch [46/100], Step [60/760], Total Loss: 3.1438\nEpoch [46/100], Step [70/760], Total Loss: 3.0610\nEpoch [46/100], Step [80/760], Total Loss: 3.1878\nEpoch [46/100], Step [90/760], Total Loss: 3.1007\nEpoch [46/100], Step [100/760], Total Loss: 3.1165\nEpoch [46/100], Step [110/760], Total Loss: 3.1281\nEpoch [46/100], Step [120/760], Total Loss: 3.1434\nEpoch [46/100], Step [130/760], Total Loss: 3.2295\nEpoch [46/100], Step [140/760], Total Loss: 3.1096\nEpoch [46/100], Step [150/760], Total Loss: 3.1604\nEpoch [46/100], Step [160/760], Total Loss: 3.0812\nEpoch [46/100], Step [170/760], Total Loss: 3.1195\nEpoch [46/100], Step [180/760], Total Loss: 3.1580\nEpoch [46/100], Step [190/760], Total Loss: 3.1720\nEpoch [46/100], Step [200/760], Total Loss: 3.1778\nEpoch [46/100], Step [210/760], Total Loss: 3.1219\nEpoch [46/100], Step [220/760], Total Loss: 3.1345\nEpoch [46/100], Step [230/760], Total Loss: 3.1195\nEpoch [46/100], Step [240/760], Total Loss: 3.1616\nEpoch [46/100], Step [250/760], Total Loss: 3.1383\nEpoch [46/100], Step [260/760], Total Loss: 3.0658\nEpoch [46/100], Step [270/760], Total Loss: 3.1476\nEpoch [46/100], Step [280/760], Total Loss: 3.1092\nEpoch [46/100], Step [290/760], Total Loss: 3.1738\nEpoch [46/100], Step [300/760], Total Loss: 3.1237\nEpoch [46/100], Step [310/760], Total Loss: 3.1789\nEpoch [46/100], Step [320/760], Total Loss: 3.1344\nEpoch [46/100], Step [330/760], Total Loss: 3.1004\nEpoch [46/100], Step [340/760], Total Loss: 3.1511\nEpoch [46/100], Step [350/760], Total Loss: 3.1934\nEpoch [46/100], Step [360/760], Total Loss: 3.0862\nEpoch [46/100], Step [370/760], Total Loss: 3.0811\nEpoch [46/100], Step [380/760], Total Loss: 3.1020\nEpoch [46/100], Step [390/760], Total Loss: 3.1258\nEpoch [46/100], Step [400/760], Total Loss: 3.1246\nEpoch [46/100], Step [410/760], Total Loss: 3.1080\nEpoch [46/100], Step [420/760], Total Loss: 3.1694\nEpoch [46/100], Step [430/760], Total Loss: 3.0763\nEpoch [46/100], Step [440/760], Total Loss: 3.1491\nEpoch [46/100], Step [450/760], Total Loss: 3.1513\nEpoch [46/100], Step [460/760], Total Loss: 3.1406\nEpoch [46/100], Step [470/760], Total Loss: 3.1177\nEpoch [46/100], Step [480/760], Total Loss: 3.1460\nEpoch [46/100], Step [490/760], Total Loss: 3.1188\nEpoch [46/100], Step [500/760], Total Loss: 3.1072\nEpoch [46/100], Step [510/760], Total Loss: 3.1393\nEpoch [46/100], Step [520/760], Total Loss: 3.1381\nEpoch [46/100], Step [530/760], Total Loss: 3.1243\nEpoch [46/100], Step [540/760], Total Loss: 3.1279\nEpoch [46/100], Step [550/760], Total Loss: 3.1176\nEpoch [46/100], Step [560/760], Total Loss: 3.0991\nEpoch [46/100], Step [570/760], Total Loss: 3.0860\nEpoch [46/100], Step [580/760], Total Loss: 3.1261\nEpoch [46/100], Step [590/760], Total Loss: 3.1374\nEpoch [46/100], Step [600/760], Total Loss: 3.2126\nEpoch [46/100], Step [610/760], Total Loss: 3.0746\nEpoch [46/100], Step [620/760], Total Loss: 3.1434\nEpoch [46/100], Step [630/760], Total Loss: 3.1469\nEpoch [46/100], Step [640/760], Total Loss: 3.1362\nEpoch [46/100], Step [650/760], Total Loss: 3.1956\nEpoch [46/100], Step [660/760], Total Loss: 3.1291\nEpoch [46/100], Step [670/760], Total Loss: 3.1624\nEpoch [46/100], Step [680/760], Total Loss: 3.2020\nEpoch [46/100], Step [690/760], Total Loss: 3.1521\nEpoch [46/100], Step [700/760], Total Loss: 3.1330\nEpoch [46/100], Step [710/760], Total Loss: 3.1310\nEpoch [46/100], Step [720/760], Total Loss: 3.1291\nEpoch [46/100], Step [730/760], Total Loss: 3.1859\nEpoch [46/100], Step [740/760], Total Loss: 3.1639\nEpoch [46/100], Step [750/760], Total Loss: 3.1250\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 46/100 [1:47:22<2:05:57, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [46/100], Step [760/760], Total Loss: 3.1627\nEpoch [47/100], Step [10/760], Total Loss: 3.1598\nEpoch [47/100], Step [20/760], Total Loss: 3.1423\nEpoch [47/100], Step [30/760], Total Loss: 3.1395\nEpoch [47/100], Step [40/760], Total Loss: 3.2000\nEpoch [47/100], Step [50/760], Total Loss: 3.1065\nEpoch [47/100], Step [60/760], Total Loss: 3.1544\nEpoch [47/100], Step [70/760], Total Loss: 3.2258\nEpoch [47/100], Step [80/760], Total Loss: 3.1365\nEpoch [47/100], Step [90/760], Total Loss: 3.1486\nEpoch [47/100], Step [100/760], Total Loss: 3.1199\nEpoch [47/100], Step [110/760], Total Loss: 3.1138\nEpoch [47/100], Step [120/760], Total Loss: 3.0885\nEpoch [47/100], Step [130/760], Total Loss: 3.1802\nEpoch [47/100], Step [140/760], Total Loss: 3.2240\nEpoch [47/100], Step [150/760], Total Loss: 3.1198\nEpoch [47/100], Step [160/760], Total Loss: 3.1435\nEpoch [47/100], Step [170/760], Total Loss: 3.1039\nEpoch [47/100], Step [180/760], Total Loss: 3.1851\nEpoch [47/100], Step [190/760], Total Loss: 3.1343\nEpoch [47/100], Step [200/760], Total Loss: 3.1341\nEpoch [47/100], Step [210/760], Total Loss: 3.0853\nEpoch [47/100], Step [220/760], Total Loss: 3.1281\nEpoch [47/100], Step [230/760], Total Loss: 3.1369\nEpoch [47/100], Step [240/760], Total Loss: 3.1110\nEpoch [47/100], Step [250/760], Total Loss: 3.1103\nEpoch [47/100], Step [260/760], Total Loss: 3.1202\nEpoch [47/100], Step [270/760], Total Loss: 3.1715\nEpoch [47/100], Step [280/760], Total Loss: 3.1359\nEpoch [47/100], Step [290/760], Total Loss: 3.1915\nEpoch [47/100], Step [300/760], Total Loss: 3.1253\nEpoch [47/100], Step [310/760], Total Loss: 3.1555\nEpoch [47/100], Step [320/760], Total Loss: 3.0930\nEpoch [47/100], Step [330/760], Total Loss: 3.1430\nEpoch [47/100], Step [340/760], Total Loss: 3.0721\nEpoch [47/100], Step [350/760], Total Loss: 3.0601\nEpoch [47/100], Step [360/760], Total Loss: 3.1509\nEpoch [47/100], Step [370/760], Total Loss: 3.1314\nEpoch [47/100], Step [380/760], Total Loss: 3.1252\nEpoch [47/100], Step [390/760], Total Loss: 3.1034\nEpoch [47/100], Step [400/760], Total Loss: 3.1313\nEpoch [47/100], Step [410/760], Total Loss: 3.1045\nEpoch [47/100], Step [420/760], Total Loss: 3.1655\nEpoch [47/100], Step [430/760], Total Loss: 3.1418\nEpoch [47/100], Step [440/760], Total Loss: 3.2236\nEpoch [47/100], Step [450/760], Total Loss: 3.1799\nEpoch [47/100], Step [460/760], Total Loss: 3.1624\nEpoch [47/100], Step [470/760], Total Loss: 3.1084\nEpoch [47/100], Step [480/760], Total Loss: 3.0941\nEpoch [47/100], Step [490/760], Total Loss: 3.1639\nEpoch [47/100], Step [500/760], Total Loss: 3.1696\nEpoch [47/100], Step [510/760], Total Loss: 3.1545\nEpoch [47/100], Step [520/760], Total Loss: 3.1235\nEpoch [47/100], Step [530/760], Total Loss: 3.1647\nEpoch [47/100], Step [540/760], Total Loss: 3.1388\nEpoch [47/100], Step [550/760], Total Loss: 3.1828\nEpoch [47/100], Step [560/760], Total Loss: 3.1177\nEpoch [47/100], Step [570/760], Total Loss: 3.1024\nEpoch [47/100], Step [580/760], Total Loss: 3.1237\nEpoch [47/100], Step [590/760], Total Loss: 3.1015\nEpoch [47/100], Step [600/760], Total Loss: 3.0925\nEpoch [47/100], Step [610/760], Total Loss: 3.1020\nEpoch [47/100], Step [620/760], Total Loss: 3.0690\nEpoch [47/100], Step [630/760], Total Loss: 3.1135\nEpoch [47/100], Step [640/760], Total Loss: 3.1267\nEpoch [47/100], Step [650/760], Total Loss: 3.1473\nEpoch [47/100], Step [660/760], Total Loss: 3.1535\nEpoch [47/100], Step [670/760], Total Loss: 3.1982\nEpoch [47/100], Step [680/760], Total Loss: 3.1313\nEpoch [47/100], Step [690/760], Total Loss: 3.1248\nEpoch [47/100], Step [700/760], Total Loss: 3.1409\nEpoch [47/100], Step [710/760], Total Loss: 3.2462\nEpoch [47/100], Step [720/760], Total Loss: 3.0738\nEpoch [47/100], Step [730/760], Total Loss: 3.1164\nEpoch [47/100], Step [740/760], Total Loss: 3.1908\nEpoch [47/100], Step [750/760], Total Loss: 3.1869\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 47/100 [1:49:42<2:03:37, 139.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [47/100], Step [760/760], Total Loss: 3.0816\nEpoch [48/100], Step [10/760], Total Loss: 3.1567\nEpoch [48/100], Step [20/760], Total Loss: 3.1085\nEpoch [48/100], Step [30/760], Total Loss: 3.0935\nEpoch [48/100], Step [40/760], Total Loss: 3.1221\nEpoch [48/100], Step [50/760], Total Loss: 3.1506\nEpoch [48/100], Step [60/760], Total Loss: 3.0907\nEpoch [48/100], Step [70/760], Total Loss: 3.2248\nEpoch [48/100], Step [80/760], Total Loss: 3.0571\nEpoch [48/100], Step [90/760], Total Loss: 3.1190\nEpoch [48/100], Step [100/760], Total Loss: 3.1102\nEpoch [48/100], Step [110/760], Total Loss: 3.1388\nEpoch [48/100], Step [120/760], Total Loss: 3.1329\nEpoch [48/100], Step [130/760], Total Loss: 3.0823\nEpoch [48/100], Step [140/760], Total Loss: 3.1898\nEpoch [48/100], Step [150/760], Total Loss: 3.1307\nEpoch [48/100], Step [160/760], Total Loss: 3.1019\nEpoch [48/100], Step [170/760], Total Loss: 3.1410\nEpoch [48/100], Step [180/760], Total Loss: 3.1995\nEpoch [48/100], Step [190/760], Total Loss: 3.1551\nEpoch [48/100], Step [200/760], Total Loss: 3.1437\nEpoch [48/100], Step [210/760], Total Loss: 3.0951\nEpoch [48/100], Step [220/760], Total Loss: 3.1424\nEpoch [48/100], Step [230/760], Total Loss: 3.1211\nEpoch [48/100], Step [240/760], Total Loss: 3.1180\nEpoch [48/100], Step [250/760], Total Loss: 3.1689\nEpoch [48/100], Step [260/760], Total Loss: 3.0310\nEpoch [48/100], Step [270/760], Total Loss: 3.1520\nEpoch [48/100], Step [280/760], Total Loss: 3.0783\nEpoch [48/100], Step [290/760], Total Loss: 3.1805\nEpoch [48/100], Step [300/760], Total Loss: 3.1780\nEpoch [48/100], Step [310/760], Total Loss: 3.2235\nEpoch [48/100], Step [320/760], Total Loss: 3.1389\nEpoch [48/100], Step [330/760], Total Loss: 3.1170\nEpoch [48/100], Step [340/760], Total Loss: 3.1334\nEpoch [48/100], Step [350/760], Total Loss: 3.1687\nEpoch [48/100], Step [360/760], Total Loss: 3.1140\nEpoch [48/100], Step [370/760], Total Loss: 3.1356\nEpoch [48/100], Step [380/760], Total Loss: 3.1511\nEpoch [48/100], Step [390/760], Total Loss: 3.1857\nEpoch [48/100], Step [400/760], Total Loss: 3.1036\nEpoch [48/100], Step [410/760], Total Loss: 3.1091\nEpoch [48/100], Step [420/760], Total Loss: 3.1606\nEpoch [48/100], Step [430/760], Total Loss: 3.1201\nEpoch [48/100], Step [440/760], Total Loss: 3.1403\nEpoch [48/100], Step [450/760], Total Loss: 3.1376\nEpoch [48/100], Step [460/760], Total Loss: 3.1618\nEpoch [48/100], Step [470/760], Total Loss: 3.0722\nEpoch [48/100], Step [480/760], Total Loss: 3.1085\nEpoch [48/100], Step [490/760], Total Loss: 3.1360\nEpoch [48/100], Step [500/760], Total Loss: 3.1493\nEpoch [48/100], Step [510/760], Total Loss: 3.0918\nEpoch [48/100], Step [520/760], Total Loss: 3.1539\nEpoch [48/100], Step [530/760], Total Loss: 3.1479\nEpoch [48/100], Step [540/760], Total Loss: 3.0726\nEpoch [48/100], Step [550/760], Total Loss: 3.0846\nEpoch [48/100], Step [560/760], Total Loss: 3.0819\nEpoch [48/100], Step [570/760], Total Loss: 3.1889\nEpoch [48/100], Step [580/760], Total Loss: 3.1469\nEpoch [48/100], Step [590/760], Total Loss: 3.1208\nEpoch [48/100], Step [600/760], Total Loss: 3.2024\nEpoch [48/100], Step [610/760], Total Loss: 3.1311\nEpoch [48/100], Step [620/760], Total Loss: 3.1719\nEpoch [48/100], Step [630/760], Total Loss: 3.0864\nEpoch [48/100], Step [640/760], Total Loss: 3.1349\nEpoch [48/100], Step [650/760], Total Loss: 3.1667\nEpoch [48/100], Step [660/760], Total Loss: 3.1175\nEpoch [48/100], Step [670/760], Total Loss: 3.1142\nEpoch [48/100], Step [680/760], Total Loss: 3.1226\nEpoch [48/100], Step [690/760], Total Loss: 3.1638\nEpoch [48/100], Step [700/760], Total Loss: 3.1574\nEpoch [48/100], Step [710/760], Total Loss: 3.1255\nEpoch [48/100], Step [720/760], Total Loss: 3.1722\nEpoch [48/100], Step [730/760], Total Loss: 3.1095\nEpoch [48/100], Step [740/760], Total Loss: 3.1180\nEpoch [48/100], Step [750/760], Total Loss: 3.0889\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 48/100 [1:52:02<2:01:17, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [48/100], Step [760/760], Total Loss: 3.1690\nEpoch [49/100], Step [10/760], Total Loss: 3.1753\nEpoch [49/100], Step [20/760], Total Loss: 3.1119\nEpoch [49/100], Step [30/760], Total Loss: 3.1252\nEpoch [49/100], Step [40/760], Total Loss: 3.0942\nEpoch [49/100], Step [50/760], Total Loss: 3.1301\nEpoch [49/100], Step [60/760], Total Loss: 3.1287\nEpoch [49/100], Step [70/760], Total Loss: 3.0895\nEpoch [49/100], Step [80/760], Total Loss: 3.1958\nEpoch [49/100], Step [90/760], Total Loss: 3.1341\nEpoch [49/100], Step [100/760], Total Loss: 3.0396\nEpoch [49/100], Step [110/760], Total Loss: 3.1081\nEpoch [49/100], Step [120/760], Total Loss: 3.0817\nEpoch [49/100], Step [130/760], Total Loss: 3.1302\nEpoch [49/100], Step [140/760], Total Loss: 3.0773\nEpoch [49/100], Step [150/760], Total Loss: 3.0494\nEpoch [49/100], Step [160/760], Total Loss: 3.1280\nEpoch [49/100], Step [170/760], Total Loss: 3.1315\nEpoch [49/100], Step [180/760], Total Loss: 3.1157\nEpoch [49/100], Step [190/760], Total Loss: 3.1089\nEpoch [49/100], Step [200/760], Total Loss: 3.0673\nEpoch [49/100], Step [210/760], Total Loss: 3.1654\nEpoch [49/100], Step [220/760], Total Loss: 3.1718\nEpoch [49/100], Step [230/760], Total Loss: 3.1350\nEpoch [49/100], Step [240/760], Total Loss: 3.1096\nEpoch [49/100], Step [250/760], Total Loss: 3.0527\nEpoch [49/100], Step [260/760], Total Loss: 3.1797\nEpoch [49/100], Step [270/760], Total Loss: 3.1313\nEpoch [49/100], Step [280/760], Total Loss: 3.0950\nEpoch [49/100], Step [290/760], Total Loss: 3.1346\nEpoch [49/100], Step [300/760], Total Loss: 3.0746\nEpoch [49/100], Step [310/760], Total Loss: 3.1970\nEpoch [49/100], Step [320/760], Total Loss: 3.1178\nEpoch [49/100], Step [330/760], Total Loss: 3.1781\nEpoch [49/100], Step [340/760], Total Loss: 3.1469\nEpoch [49/100], Step [350/760], Total Loss: 3.1599\nEpoch [49/100], Step [360/760], Total Loss: 3.1114\nEpoch [49/100], Step [370/760], Total Loss: 3.2024\nEpoch [49/100], Step [380/760], Total Loss: 3.0972\nEpoch [49/100], Step [390/760], Total Loss: 3.0727\nEpoch [49/100], Step [400/760], Total Loss: 3.1200\nEpoch [49/100], Step [410/760], Total Loss: 3.1163\nEpoch [49/100], Step [420/760], Total Loss: 3.1339\nEpoch [49/100], Step [430/760], Total Loss: 3.0793\nEpoch [49/100], Step [440/760], Total Loss: 3.1069\nEpoch [49/100], Step [450/760], Total Loss: 3.1429\nEpoch [49/100], Step [460/760], Total Loss: 3.1511\nEpoch [49/100], Step [470/760], Total Loss: 3.1279\nEpoch [49/100], Step [480/760], Total Loss: 3.1801\nEpoch [49/100], Step [490/760], Total Loss: 3.0842\nEpoch [49/100], Step [500/760], Total Loss: 3.1006\nEpoch [49/100], Step [510/760], Total Loss: 3.1697\nEpoch [49/100], Step [520/760], Total Loss: 3.1099\nEpoch [49/100], Step [530/760], Total Loss: 3.1284\nEpoch [49/100], Step [540/760], Total Loss: 3.1052\nEpoch [49/100], Step [550/760], Total Loss: 3.1821\nEpoch [49/100], Step [560/760], Total Loss: 3.0881\nEpoch [49/100], Step [570/760], Total Loss: 3.0936\nEpoch [49/100], Step [580/760], Total Loss: 3.1081\nEpoch [49/100], Step [590/760], Total Loss: 3.0748\nEpoch [49/100], Step [600/760], Total Loss: 3.1093\nEpoch [49/100], Step [610/760], Total Loss: 3.1427\nEpoch [49/100], Step [620/760], Total Loss: 3.1562\nEpoch [49/100], Step [630/760], Total Loss: 3.1211\nEpoch [49/100], Step [640/760], Total Loss: 3.1349\nEpoch [49/100], Step [650/760], Total Loss: 3.0413\nEpoch [49/100], Step [660/760], Total Loss: 3.0836\nEpoch [49/100], Step [670/760], Total Loss: 3.1296\nEpoch [49/100], Step [680/760], Total Loss: 3.1282\nEpoch [49/100], Step [690/760], Total Loss: 3.1377\nEpoch [49/100], Step [700/760], Total Loss: 3.0966\nEpoch [49/100], Step [710/760], Total Loss: 3.1416\nEpoch [49/100], Step [720/760], Total Loss: 3.1417\nEpoch [49/100], Step [730/760], Total Loss: 3.0885\nEpoch [49/100], Step [740/760], Total Loss: 3.0964\nEpoch [49/100], Step [750/760], Total Loss: 3.1420\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 49/100 [1:54:22<1:58:57, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [49/100], Step [760/760], Total Loss: 3.1734\nEpoch [50/100], Step [10/760], Total Loss: 3.1273\nEpoch [50/100], Step [20/760], Total Loss: 3.1039\nEpoch [50/100], Step [30/760], Total Loss: 3.0867\nEpoch [50/100], Step [40/760], Total Loss: 3.0243\nEpoch [50/100], Step [50/760], Total Loss: 3.0570\nEpoch [50/100], Step [60/760], Total Loss: 3.0858\nEpoch [50/100], Step [70/760], Total Loss: 3.1061\nEpoch [50/100], Step [80/760], Total Loss: 3.1036\nEpoch [50/100], Step [90/760], Total Loss: 3.1128\nEpoch [50/100], Step [100/760], Total Loss: 3.1269\nEpoch [50/100], Step [110/760], Total Loss: 3.1246\nEpoch [50/100], Step [120/760], Total Loss: 3.1519\nEpoch [50/100], Step [130/760], Total Loss: 3.1505\nEpoch [50/100], Step [140/760], Total Loss: 3.0684\nEpoch [50/100], Step [150/760], Total Loss: 3.1469\nEpoch [50/100], Step [160/760], Total Loss: 3.1393\nEpoch [50/100], Step [170/760], Total Loss: 3.1666\nEpoch [50/100], Step [180/760], Total Loss: 3.1047\nEpoch [50/100], Step [190/760], Total Loss: 3.1208\nEpoch [50/100], Step [200/760], Total Loss: 3.1583\nEpoch [50/100], Step [210/760], Total Loss: 3.0811\nEpoch [50/100], Step [220/760], Total Loss: 3.1191\nEpoch [50/100], Step [230/760], Total Loss: 3.0793\nEpoch [50/100], Step [240/760], Total Loss: 3.0417\nEpoch [50/100], Step [250/760], Total Loss: 3.0897\nEpoch [50/100], Step [260/760], Total Loss: 3.0990\nEpoch [50/100], Step [270/760], Total Loss: 3.0921\nEpoch [50/100], Step [280/760], Total Loss: 3.1255\nEpoch [50/100], Step [290/760], Total Loss: 3.1985\nEpoch [50/100], Step [300/760], Total Loss: 3.0786\nEpoch [50/100], Step [310/760], Total Loss: 3.1304\nEpoch [50/100], Step [320/760], Total Loss: 3.1368\nEpoch [50/100], Step [330/760], Total Loss: 3.1230\nEpoch [50/100], Step [340/760], Total Loss: 3.0911\nEpoch [50/100], Step [350/760], Total Loss: 3.0823\nEpoch [50/100], Step [360/760], Total Loss: 3.0993\nEpoch [50/100], Step [370/760], Total Loss: 3.1800\nEpoch [50/100], Step [380/760], Total Loss: 3.0928\nEpoch [50/100], Step [390/760], Total Loss: 3.1345\nEpoch [50/100], Step [400/760], Total Loss: 3.1304\nEpoch [50/100], Step [410/760], Total Loss: 3.1726\nEpoch [50/100], Step [420/760], Total Loss: 3.1437\nEpoch [50/100], Step [430/760], Total Loss: 3.1523\nEpoch [50/100], Step [440/760], Total Loss: 3.1326\nEpoch [50/100], Step [450/760], Total Loss: 3.1675\nEpoch [50/100], Step [460/760], Total Loss: 3.1669\nEpoch [50/100], Step [470/760], Total Loss: 3.1136\nEpoch [50/100], Step [480/760], Total Loss: 3.1095\nEpoch [50/100], Step [490/760], Total Loss: 3.1816\nEpoch [50/100], Step [500/760], Total Loss: 3.1593\nEpoch [50/100], Step [510/760], Total Loss: 3.2189\nEpoch [50/100], Step [520/760], Total Loss: 3.0710\nEpoch [50/100], Step [530/760], Total Loss: 3.1434\nEpoch [50/100], Step [540/760], Total Loss: 3.1469\nEpoch [50/100], Step [550/760], Total Loss: 3.1547\nEpoch [50/100], Step [560/760], Total Loss: 3.0838\nEpoch [50/100], Step [570/760], Total Loss: 3.1013\nEpoch [50/100], Step [580/760], Total Loss: 3.1203\nEpoch [50/100], Step [590/760], Total Loss: 3.0698\nEpoch [50/100], Step [600/760], Total Loss: 3.1255\nEpoch [50/100], Step [610/760], Total Loss: 3.0734\nEpoch [50/100], Step [620/760], Total Loss: 3.0778\nEpoch [50/100], Step [630/760], Total Loss: 3.1007\nEpoch [50/100], Step [640/760], Total Loss: 3.0979\nEpoch [50/100], Step [650/760], Total Loss: 3.0872\nEpoch [50/100], Step [660/760], Total Loss: 3.1229\nEpoch [50/100], Step [670/760], Total Loss: 3.1306\nEpoch [50/100], Step [680/760], Total Loss: 3.0460\nEpoch [50/100], Step [690/760], Total Loss: 3.1674\nEpoch [50/100], Step [700/760], Total Loss: 3.1544\nEpoch [50/100], Step [710/760], Total Loss: 3.1210\nEpoch [50/100], Step [720/760], Total Loss: 3.2029\nEpoch [50/100], Step [730/760], Total Loss: 3.1214\nEpoch [50/100], Step [740/760], Total Loss: 3.0872\nEpoch [50/100], Step [750/760], Total Loss: 3.1429\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 50/100 [1:56:42<1:56:37, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [50/100], Step [760/760], Total Loss: 3.4190\nEpoch [51/100], Step [10/760], Total Loss: 3.1328\nEpoch [51/100], Step [20/760], Total Loss: 3.1243\nEpoch [51/100], Step [30/760], Total Loss: 3.1018\nEpoch [51/100], Step [40/760], Total Loss: 3.1360\nEpoch [51/100], Step [50/760], Total Loss: 3.0781\nEpoch [51/100], Step [60/760], Total Loss: 3.1479\nEpoch [51/100], Step [70/760], Total Loss: 3.1272\nEpoch [51/100], Step [80/760], Total Loss: 3.0682\nEpoch [51/100], Step [90/760], Total Loss: 3.1948\nEpoch [51/100], Step [100/760], Total Loss: 3.1078\nEpoch [51/100], Step [110/760], Total Loss: 3.1257\nEpoch [51/100], Step [120/760], Total Loss: 3.0981\nEpoch [51/100], Step [130/760], Total Loss: 3.0954\nEpoch [51/100], Step [140/760], Total Loss: 3.1112\nEpoch [51/100], Step [150/760], Total Loss: 3.0546\nEpoch [51/100], Step [160/760], Total Loss: 3.0998\nEpoch [51/100], Step [170/760], Total Loss: 3.1996\nEpoch [51/100], Step [180/760], Total Loss: 3.1648\nEpoch [51/100], Step [190/760], Total Loss: 3.0964\nEpoch [51/100], Step [200/760], Total Loss: 3.0934\nEpoch [51/100], Step [210/760], Total Loss: 3.1277\nEpoch [51/100], Step [220/760], Total Loss: 3.1757\nEpoch [51/100], Step [230/760], Total Loss: 3.1346\nEpoch [51/100], Step [240/760], Total Loss: 3.1007\nEpoch [51/100], Step [250/760], Total Loss: 3.1096\nEpoch [51/100], Step [260/760], Total Loss: 3.1365\nEpoch [51/100], Step [270/760], Total Loss: 3.1389\nEpoch [51/100], Step [280/760], Total Loss: 3.1342\nEpoch [51/100], Step [290/760], Total Loss: 3.1580\nEpoch [51/100], Step [300/760], Total Loss: 3.0816\nEpoch [51/100], Step [310/760], Total Loss: 3.1191\nEpoch [51/100], Step [320/760], Total Loss: 3.1314\nEpoch [51/100], Step [330/760], Total Loss: 3.1352\nEpoch [51/100], Step [340/760], Total Loss: 3.1710\nEpoch [51/100], Step [350/760], Total Loss: 3.2269\nEpoch [51/100], Step [360/760], Total Loss: 3.0902\nEpoch [51/100], Step [370/760], Total Loss: 3.1346\nEpoch [51/100], Step [380/760], Total Loss: 3.0762\nEpoch [51/100], Step [390/760], Total Loss: 3.1050\nEpoch [51/100], Step [400/760], Total Loss: 3.1385\nEpoch [51/100], Step [410/760], Total Loss: 3.1141\nEpoch [51/100], Step [420/760], Total Loss: 3.1277\nEpoch [51/100], Step [430/760], Total Loss: 3.1461\nEpoch [51/100], Step [440/760], Total Loss: 3.1093\nEpoch [51/100], Step [450/760], Total Loss: 3.1265\nEpoch [51/100], Step [460/760], Total Loss: 3.1112\nEpoch [51/100], Step [470/760], Total Loss: 3.1084\nEpoch [51/100], Step [480/760], Total Loss: 3.1025\nEpoch [51/100], Step [490/760], Total Loss: 3.1097\nEpoch [51/100], Step [500/760], Total Loss: 3.1268\nEpoch [51/100], Step [510/760], Total Loss: 3.0985\nEpoch [51/100], Step [520/760], Total Loss: 3.1803\nEpoch [51/100], Step [530/760], Total Loss: 3.2207\nEpoch [51/100], Step [540/760], Total Loss: 3.1267\nEpoch [51/100], Step [550/760], Total Loss: 3.1322\nEpoch [51/100], Step [560/760], Total Loss: 3.1082\nEpoch [51/100], Step [570/760], Total Loss: 3.0693\nEpoch [51/100], Step [580/760], Total Loss: 3.2521\nEpoch [51/100], Step [590/760], Total Loss: 3.1023\nEpoch [51/100], Step [600/760], Total Loss: 3.0839\nEpoch [51/100], Step [610/760], Total Loss: 3.1385\nEpoch [51/100], Step [620/760], Total Loss: 3.1590\nEpoch [51/100], Step [630/760], Total Loss: 3.0944\nEpoch [51/100], Step [640/760], Total Loss: 3.1016\nEpoch [51/100], Step [650/760], Total Loss: 3.1579\nEpoch [51/100], Step [660/760], Total Loss: 3.1491\nEpoch [51/100], Step [670/760], Total Loss: 3.0994\nEpoch [51/100], Step [680/760], Total Loss: 3.0668\nEpoch [51/100], Step [690/760], Total Loss: 3.1186\nEpoch [51/100], Step [700/760], Total Loss: 3.1578\nEpoch [51/100], Step [710/760], Total Loss: 3.1171\nEpoch [51/100], Step [720/760], Total Loss: 3.1317\nEpoch [51/100], Step [730/760], Total Loss: 3.2323\nEpoch [51/100], Step [740/760], Total Loss: 3.0813\nEpoch [51/100], Step [750/760], Total Loss: 3.1582\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 51/100 [1:59:02<1:54:17, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [51/100], Step [760/760], Total Loss: 3.2300\nEpoch [52/100], Step [10/760], Total Loss: 3.0995\nEpoch [52/100], Step [20/760], Total Loss: 3.0817\nEpoch [52/100], Step [30/760], Total Loss: 3.0981\nEpoch [52/100], Step [40/760], Total Loss: 3.1101\nEpoch [52/100], Step [50/760], Total Loss: 3.1561\nEpoch [52/100], Step [60/760], Total Loss: 3.0862\nEpoch [52/100], Step [70/760], Total Loss: 3.0959\nEpoch [52/100], Step [80/760], Total Loss: 3.1383\nEpoch [52/100], Step [90/760], Total Loss: 3.1168\nEpoch [52/100], Step [100/760], Total Loss: 3.1685\nEpoch [52/100], Step [110/760], Total Loss: 3.0830\nEpoch [52/100], Step [120/760], Total Loss: 3.1236\nEpoch [52/100], Step [130/760], Total Loss: 3.0984\nEpoch [52/100], Step [140/760], Total Loss: 3.1342\nEpoch [52/100], Step [150/760], Total Loss: 3.0706\nEpoch [52/100], Step [160/760], Total Loss: 3.0748\nEpoch [52/100], Step [170/760], Total Loss: 3.0605\nEpoch [52/100], Step [180/760], Total Loss: 3.1106\nEpoch [52/100], Step [190/760], Total Loss: 3.0673\nEpoch [52/100], Step [200/760], Total Loss: 3.1502\nEpoch [52/100], Step [210/760], Total Loss: 3.1370\nEpoch [52/100], Step [220/760], Total Loss: 3.0926\nEpoch [52/100], Step [230/760], Total Loss: 3.0838\nEpoch [52/100], Step [240/760], Total Loss: 3.1092\nEpoch [52/100], Step [250/760], Total Loss: 3.0883\nEpoch [52/100], Step [260/760], Total Loss: 3.2010\nEpoch [52/100], Step [270/760], Total Loss: 3.1239\nEpoch [52/100], Step [280/760], Total Loss: 3.1629\nEpoch [52/100], Step [290/760], Total Loss: 3.0991\nEpoch [52/100], Step [300/760], Total Loss: 3.0603\nEpoch [52/100], Step [310/760], Total Loss: 3.1019\nEpoch [52/100], Step [320/760], Total Loss: 3.1645\nEpoch [52/100], Step [330/760], Total Loss: 3.0989\nEpoch [52/100], Step [340/760], Total Loss: 3.1356\nEpoch [52/100], Step [350/760], Total Loss: 3.1360\nEpoch [52/100], Step [360/760], Total Loss: 3.0800\nEpoch [52/100], Step [370/760], Total Loss: 3.1179\nEpoch [52/100], Step [380/760], Total Loss: 3.1734\nEpoch [52/100], Step [390/760], Total Loss: 3.0993\nEpoch [52/100], Step [400/760], Total Loss: 3.0852\nEpoch [52/100], Step [410/760], Total Loss: 3.0976\nEpoch [52/100], Step [420/760], Total Loss: 3.1103\nEpoch [52/100], Step [430/760], Total Loss: 3.0992\nEpoch [52/100], Step [440/760], Total Loss: 3.1118\nEpoch [52/100], Step [450/760], Total Loss: 3.0645\nEpoch [52/100], Step [460/760], Total Loss: 3.0817\nEpoch [52/100], Step [470/760], Total Loss: 3.0561\nEpoch [52/100], Step [480/760], Total Loss: 3.1221\nEpoch [52/100], Step [490/760], Total Loss: 3.1253\nEpoch [52/100], Step [500/760], Total Loss: 3.1063\nEpoch [52/100], Step [510/760], Total Loss: 3.1415\nEpoch [52/100], Step [520/760], Total Loss: 3.1057\nEpoch [52/100], Step [530/760], Total Loss: 3.0644\nEpoch [52/100], Step [540/760], Total Loss: 3.1099\nEpoch [52/100], Step [550/760], Total Loss: 3.0968\nEpoch [52/100], Step [560/760], Total Loss: 3.1459\nEpoch [52/100], Step [570/760], Total Loss: 3.1168\nEpoch [52/100], Step [580/760], Total Loss: 3.0966\nEpoch [52/100], Step [590/760], Total Loss: 3.0742\nEpoch [52/100], Step [600/760], Total Loss: 3.0529\nEpoch [52/100], Step [610/760], Total Loss: 3.1572\nEpoch [52/100], Step [620/760], Total Loss: 3.1482\nEpoch [52/100], Step [630/760], Total Loss: 3.1473\nEpoch [52/100], Step [640/760], Total Loss: 3.1356\nEpoch [52/100], Step [650/760], Total Loss: 3.0482\nEpoch [52/100], Step [660/760], Total Loss: 3.1347\nEpoch [52/100], Step [670/760], Total Loss: 3.1335\nEpoch [52/100], Step [680/760], Total Loss: 3.1320\nEpoch [52/100], Step [690/760], Total Loss: 3.0864\nEpoch [52/100], Step [700/760], Total Loss: 3.0480\nEpoch [52/100], Step [710/760], Total Loss: 3.1846\nEpoch [52/100], Step [720/760], Total Loss: 3.1529\nEpoch [52/100], Step [730/760], Total Loss: 3.0968\nEpoch [52/100], Step [740/760], Total Loss: 3.1132\nEpoch [52/100], Step [750/760], Total Loss: 3.1414\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 52/100 [2:01:22<1:51:57, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [52/100], Step [760/760], Total Loss: 3.1636\nEpoch [53/100], Step [10/760], Total Loss: 3.1386\nEpoch [53/100], Step [20/760], Total Loss: 3.1429\nEpoch [53/100], Step [30/760], Total Loss: 3.1706\nEpoch [53/100], Step [40/760], Total Loss: 3.0895\nEpoch [53/100], Step [50/760], Total Loss: 3.1388\nEpoch [53/100], Step [60/760], Total Loss: 3.0796\nEpoch [53/100], Step [70/760], Total Loss: 3.0816\nEpoch [53/100], Step [80/760], Total Loss: 3.1455\nEpoch [53/100], Step [90/760], Total Loss: 3.0867\nEpoch [53/100], Step [100/760], Total Loss: 3.0968\nEpoch [53/100], Step [110/760], Total Loss: 3.0824\nEpoch [53/100], Step [120/760], Total Loss: 3.0378\nEpoch [53/100], Step [130/760], Total Loss: 3.1283\nEpoch [53/100], Step [140/760], Total Loss: 3.2000\nEpoch [53/100], Step [150/760], Total Loss: 3.0950\nEpoch [53/100], Step [160/760], Total Loss: 3.1169\nEpoch [53/100], Step [170/760], Total Loss: 3.1114\nEpoch [53/100], Step [180/760], Total Loss: 3.0371\nEpoch [53/100], Step [190/760], Total Loss: 3.0675\nEpoch [53/100], Step [200/760], Total Loss: 3.0978\nEpoch [53/100], Step [210/760], Total Loss: 3.0867\nEpoch [53/100], Step [220/760], Total Loss: 3.1022\nEpoch [53/100], Step [230/760], Total Loss: 3.1121\nEpoch [53/100], Step [240/760], Total Loss: 3.0598\nEpoch [53/100], Step [250/760], Total Loss: 3.1783\nEpoch [53/100], Step [260/760], Total Loss: 3.1257\nEpoch [53/100], Step [270/760], Total Loss: 3.1231\nEpoch [53/100], Step [280/760], Total Loss: 3.0600\nEpoch [53/100], Step [290/760], Total Loss: 3.1491\nEpoch [53/100], Step [300/760], Total Loss: 3.1610\nEpoch [53/100], Step [310/760], Total Loss: 3.0941\nEpoch [53/100], Step [320/760], Total Loss: 3.0993\nEpoch [53/100], Step [330/760], Total Loss: 3.0274\nEpoch [53/100], Step [340/760], Total Loss: 3.1014\nEpoch [53/100], Step [350/760], Total Loss: 3.0966\nEpoch [53/100], Step [360/760], Total Loss: 3.0986\nEpoch [53/100], Step [370/760], Total Loss: 3.1332\nEpoch [53/100], Step [380/760], Total Loss: 3.1040\nEpoch [53/100], Step [390/760], Total Loss: 3.0775\nEpoch [53/100], Step [400/760], Total Loss: 3.0901\nEpoch [53/100], Step [410/760], Total Loss: 3.1353\nEpoch [53/100], Step [420/760], Total Loss: 3.1158\nEpoch [53/100], Step [430/760], Total Loss: 3.1354\nEpoch [53/100], Step [440/760], Total Loss: 3.1705\nEpoch [53/100], Step [450/760], Total Loss: 3.0742\nEpoch [53/100], Step [460/760], Total Loss: 3.0704\nEpoch [53/100], Step [470/760], Total Loss: 3.0959\nEpoch [53/100], Step [480/760], Total Loss: 3.1454\nEpoch [53/100], Step [490/760], Total Loss: 3.1659\nEpoch [53/100], Step [500/760], Total Loss: 3.1425\nEpoch [53/100], Step [510/760], Total Loss: 3.1158\nEpoch [53/100], Step [520/760], Total Loss: 3.1321\nEpoch [53/100], Step [530/760], Total Loss: 3.0581\nEpoch [53/100], Step [540/760], Total Loss: 3.1468\nEpoch [53/100], Step [550/760], Total Loss: 3.1845\nEpoch [53/100], Step [560/760], Total Loss: 3.1433\nEpoch [53/100], Step [570/760], Total Loss: 3.1317\nEpoch [53/100], Step [580/760], Total Loss: 3.1674\nEpoch [53/100], Step [590/760], Total Loss: 3.1248\nEpoch [53/100], Step [600/760], Total Loss: 3.1034\nEpoch [53/100], Step [610/760], Total Loss: 3.0334\nEpoch [53/100], Step [620/760], Total Loss: 3.0917\nEpoch [53/100], Step [630/760], Total Loss: 3.0897\nEpoch [53/100], Step [640/760], Total Loss: 3.1679\nEpoch [53/100], Step [650/760], Total Loss: 3.1777\nEpoch [53/100], Step [660/760], Total Loss: 3.0752\nEpoch [53/100], Step [670/760], Total Loss: 3.1634\nEpoch [53/100], Step [680/760], Total Loss: 3.1197\nEpoch [53/100], Step [690/760], Total Loss: 3.1211\nEpoch [53/100], Step [700/760], Total Loss: 3.0392\nEpoch [53/100], Step [710/760], Total Loss: 3.0898\nEpoch [53/100], Step [720/760], Total Loss: 3.0860\nEpoch [53/100], Step [730/760], Total Loss: 3.0745\nEpoch [53/100], Step [740/760], Total Loss: 3.1445\nEpoch [53/100], Step [750/760], Total Loss: 3.0879\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 53/100 [2:03:42<1:49:37, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [53/100], Step [760/760], Total Loss: 3.0326\nEpoch [54/100], Step [10/760], Total Loss: 3.1495\nEpoch [54/100], Step [20/760], Total Loss: 3.0925\nEpoch [54/100], Step [30/760], Total Loss: 3.0759\nEpoch [54/100], Step [40/760], Total Loss: 3.1550\nEpoch [54/100], Step [50/760], Total Loss: 3.0941\nEpoch [54/100], Step [60/760], Total Loss: 3.0611\nEpoch [54/100], Step [70/760], Total Loss: 3.1014\nEpoch [54/100], Step [80/760], Total Loss: 3.0703\nEpoch [54/100], Step [90/760], Total Loss: 3.0858\nEpoch [54/100], Step [100/760], Total Loss: 3.0960\nEpoch [54/100], Step [110/760], Total Loss: 3.1977\nEpoch [54/100], Step [120/760], Total Loss: 3.0819\nEpoch [54/100], Step [130/760], Total Loss: 3.1101\nEpoch [54/100], Step [140/760], Total Loss: 3.0713\nEpoch [54/100], Step [150/760], Total Loss: 3.0293\nEpoch [54/100], Step [160/760], Total Loss: 3.1027\nEpoch [54/100], Step [170/760], Total Loss: 3.0843\nEpoch [54/100], Step [180/760], Total Loss: 3.1453\nEpoch [54/100], Step [190/760], Total Loss: 3.0992\nEpoch [54/100], Step [200/760], Total Loss: 3.1088\nEpoch [54/100], Step [210/760], Total Loss: 3.0432\nEpoch [54/100], Step [220/760], Total Loss: 3.1903\nEpoch [54/100], Step [230/760], Total Loss: 3.1292\nEpoch [54/100], Step [240/760], Total Loss: 3.1720\nEpoch [54/100], Step [250/760], Total Loss: 3.1279\nEpoch [54/100], Step [260/760], Total Loss: 3.1633\nEpoch [54/100], Step [270/760], Total Loss: 3.1456\nEpoch [54/100], Step [280/760], Total Loss: 3.0584\nEpoch [54/100], Step [290/760], Total Loss: 3.0937\nEpoch [54/100], Step [300/760], Total Loss: 3.2774\nEpoch [54/100], Step [310/760], Total Loss: 3.1803\nEpoch [54/100], Step [320/760], Total Loss: 3.1309\nEpoch [54/100], Step [330/760], Total Loss: 3.1185\nEpoch [54/100], Step [340/760], Total Loss: 3.1150\nEpoch [54/100], Step [350/760], Total Loss: 3.0953\nEpoch [54/100], Step [360/760], Total Loss: 3.1057\nEpoch [54/100], Step [370/760], Total Loss: 3.0607\nEpoch [54/100], Step [380/760], Total Loss: 3.0751\nEpoch [54/100], Step [390/760], Total Loss: 3.1127\nEpoch [54/100], Step [400/760], Total Loss: 3.1518\nEpoch [54/100], Step [410/760], Total Loss: 3.1369\nEpoch [54/100], Step [420/760], Total Loss: 3.0743\nEpoch [54/100], Step [430/760], Total Loss: 3.1062\nEpoch [54/100], Step [440/760], Total Loss: 3.1148\nEpoch [54/100], Step [450/760], Total Loss: 3.1784\nEpoch [54/100], Step [460/760], Total Loss: 3.1226\nEpoch [54/100], Step [470/760], Total Loss: 3.1260\nEpoch [54/100], Step [480/760], Total Loss: 3.1355\nEpoch [54/100], Step [490/760], Total Loss: 3.1394\nEpoch [54/100], Step [500/760], Total Loss: 3.0963\nEpoch [54/100], Step [510/760], Total Loss: 3.1543\nEpoch [54/100], Step [520/760], Total Loss: 3.0671\nEpoch [54/100], Step [530/760], Total Loss: 3.0583\nEpoch [54/100], Step [540/760], Total Loss: 3.0838\nEpoch [54/100], Step [550/760], Total Loss: 3.1343\nEpoch [54/100], Step [560/760], Total Loss: 3.1169\nEpoch [54/100], Step [570/760], Total Loss: 3.1378\nEpoch [54/100], Step [580/760], Total Loss: 3.1048\nEpoch [54/100], Step [590/760], Total Loss: 3.1392\nEpoch [54/100], Step [600/760], Total Loss: 3.1264\nEpoch [54/100], Step [610/760], Total Loss: 3.1346\nEpoch [54/100], Step [620/760], Total Loss: 3.1175\nEpoch [54/100], Step [630/760], Total Loss: 3.0565\nEpoch [54/100], Step [640/760], Total Loss: 3.1528\nEpoch [54/100], Step [650/760], Total Loss: 3.0614\nEpoch [54/100], Step [660/760], Total Loss: 3.1301\nEpoch [54/100], Step [670/760], Total Loss: 3.1123\nEpoch [54/100], Step [680/760], Total Loss: 3.1363\nEpoch [54/100], Step [690/760], Total Loss: 3.1125\nEpoch [54/100], Step [700/760], Total Loss: 3.1211\nEpoch [54/100], Step [710/760], Total Loss: 3.1058\nEpoch [54/100], Step [720/760], Total Loss: 3.0904\nEpoch [54/100], Step [730/760], Total Loss: 3.1114\nEpoch [54/100], Step [740/760], Total Loss: 3.1321\nEpoch [54/100], Step [750/760], Total Loss: 3.1248\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 54/100 [2:06:02<1:47:17, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [54/100], Step [760/760], Total Loss: 3.0699\nEpoch [55/100], Step [10/760], Total Loss: 3.1518\nEpoch [55/100], Step [20/760], Total Loss: 3.0632\nEpoch [55/100], Step [30/760], Total Loss: 3.1176\nEpoch [55/100], Step [40/760], Total Loss: 3.0749\nEpoch [55/100], Step [50/760], Total Loss: 3.1233\nEpoch [55/100], Step [60/760], Total Loss: 3.1453\nEpoch [55/100], Step [70/760], Total Loss: 3.1181\nEpoch [55/100], Step [80/760], Total Loss: 3.1081\nEpoch [55/100], Step [90/760], Total Loss: 3.1972\nEpoch [55/100], Step [100/760], Total Loss: 3.1011\nEpoch [55/100], Step [110/760], Total Loss: 3.1168\nEpoch [55/100], Step [120/760], Total Loss: 3.0808\nEpoch [55/100], Step [130/760], Total Loss: 3.0956\nEpoch [55/100], Step [140/760], Total Loss: 3.1017\nEpoch [55/100], Step [150/760], Total Loss: 3.1293\nEpoch [55/100], Step [160/760], Total Loss: 3.0670\nEpoch [55/100], Step [170/760], Total Loss: 3.0686\nEpoch [55/100], Step [180/760], Total Loss: 3.1472\nEpoch [55/100], Step [190/760], Total Loss: 3.0965\nEpoch [55/100], Step [200/760], Total Loss: 3.1499\nEpoch [55/100], Step [210/760], Total Loss: 3.1527\nEpoch [55/100], Step [220/760], Total Loss: 3.1330\nEpoch [55/100], Step [230/760], Total Loss: 3.0864\nEpoch [55/100], Step [240/760], Total Loss: 3.2085\nEpoch [55/100], Step [250/760], Total Loss: 3.0156\nEpoch [55/100], Step [260/760], Total Loss: 3.1004\nEpoch [55/100], Step [270/760], Total Loss: 3.1379\nEpoch [55/100], Step [280/760], Total Loss: 3.1005\nEpoch [55/100], Step [290/760], Total Loss: 3.0713\nEpoch [55/100], Step [300/760], Total Loss: 3.1101\nEpoch [55/100], Step [310/760], Total Loss: 3.1134\nEpoch [55/100], Step [320/760], Total Loss: 3.0930\nEpoch [55/100], Step [330/760], Total Loss: 3.1515\nEpoch [55/100], Step [340/760], Total Loss: 3.0841\nEpoch [55/100], Step [350/760], Total Loss: 3.1219\nEpoch [55/100], Step [360/760], Total Loss: 3.0837\nEpoch [55/100], Step [370/760], Total Loss: 3.1492\nEpoch [55/100], Step [380/760], Total Loss: 3.0699\nEpoch [55/100], Step [390/760], Total Loss: 3.1262\nEpoch [55/100], Step [400/760], Total Loss: 3.0766\nEpoch [55/100], Step [410/760], Total Loss: 3.0950\nEpoch [55/100], Step [420/760], Total Loss: 3.1223\nEpoch [55/100], Step [430/760], Total Loss: 3.0605\nEpoch [55/100], Step [440/760], Total Loss: 3.1466\nEpoch [55/100], Step [450/760], Total Loss: 3.1201\nEpoch [55/100], Step [460/760], Total Loss: 3.0853\nEpoch [55/100], Step [470/760], Total Loss: 3.1037\nEpoch [55/100], Step [480/760], Total Loss: 3.1636\nEpoch [55/100], Step [490/760], Total Loss: 3.1068\nEpoch [55/100], Step [500/760], Total Loss: 3.1476\nEpoch [55/100], Step [510/760], Total Loss: 3.0908\nEpoch [55/100], Step [520/760], Total Loss: 3.0924\nEpoch [55/100], Step [530/760], Total Loss: 3.0574\nEpoch [55/100], Step [540/760], Total Loss: 3.0681\nEpoch [55/100], Step [550/760], Total Loss: 3.0481\nEpoch [55/100], Step [560/760], Total Loss: 3.0917\nEpoch [55/100], Step [570/760], Total Loss: 3.1209\nEpoch [55/100], Step [580/760], Total Loss: 3.0824\nEpoch [55/100], Step [590/760], Total Loss: 3.0861\nEpoch [55/100], Step [600/760], Total Loss: 3.0855\nEpoch [55/100], Step [610/760], Total Loss: 3.1151\nEpoch [55/100], Step [620/760], Total Loss: 3.0808\nEpoch [55/100], Step [630/760], Total Loss: 3.1231\nEpoch [55/100], Step [640/760], Total Loss: 3.1273\nEpoch [55/100], Step [650/760], Total Loss: 3.1242\nEpoch [55/100], Step [660/760], Total Loss: 3.1807\nEpoch [55/100], Step [670/760], Total Loss: 3.0909\nEpoch [55/100], Step [680/760], Total Loss: 3.1132\nEpoch [55/100], Step [690/760], Total Loss: 3.1205\nEpoch [55/100], Step [700/760], Total Loss: 3.1736\nEpoch [55/100], Step [710/760], Total Loss: 3.0827\nEpoch [55/100], Step [720/760], Total Loss: 3.1235\nEpoch [55/100], Step [730/760], Total Loss: 3.1361\nEpoch [55/100], Step [740/760], Total Loss: 3.1027\nEpoch [55/100], Step [750/760], Total Loss: 3.1355\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 55/100 [2:08:22<1:44:57, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [55/100], Step [760/760], Total Loss: 3.0398\nEpoch [56/100], Step [10/760], Total Loss: 3.0483\nEpoch [56/100], Step [20/760], Total Loss: 3.1324\nEpoch [56/100], Step [30/760], Total Loss: 3.1123\nEpoch [56/100], Step [40/760], Total Loss: 3.1127\nEpoch [56/100], Step [50/760], Total Loss: 3.1429\nEpoch [56/100], Step [60/760], Total Loss: 3.1069\nEpoch [56/100], Step [70/760], Total Loss: 3.0761\nEpoch [56/100], Step [80/760], Total Loss: 3.1112\nEpoch [56/100], Step [90/760], Total Loss: 3.0533\nEpoch [56/100], Step [100/760], Total Loss: 3.1154\nEpoch [56/100], Step [110/760], Total Loss: 3.0733\nEpoch [56/100], Step [120/760], Total Loss: 3.0858\nEpoch [56/100], Step [130/760], Total Loss: 3.1524\nEpoch [56/100], Step [140/760], Total Loss: 3.0827\nEpoch [56/100], Step [150/760], Total Loss: 3.1240\nEpoch [56/100], Step [160/760], Total Loss: 3.0754\nEpoch [56/100], Step [170/760], Total Loss: 3.1726\nEpoch [56/100], Step [180/760], Total Loss: 3.0654\nEpoch [56/100], Step [190/760], Total Loss: 3.0129\nEpoch [56/100], Step [200/760], Total Loss: 3.1509\nEpoch [56/100], Step [210/760], Total Loss: 3.0999\nEpoch [56/100], Step [220/760], Total Loss: 3.0630\nEpoch [56/100], Step [230/760], Total Loss: 3.0784\nEpoch [56/100], Step [240/760], Total Loss: 3.1529\nEpoch [56/100], Step [250/760], Total Loss: 3.1841\nEpoch [56/100], Step [260/760], Total Loss: 3.0961\nEpoch [56/100], Step [270/760], Total Loss: 3.1351\nEpoch [56/100], Step [280/760], Total Loss: 3.1245\nEpoch [56/100], Step [290/760], Total Loss: 3.1625\nEpoch [56/100], Step [300/760], Total Loss: 3.0948\nEpoch [56/100], Step [310/760], Total Loss: 3.1255\nEpoch [56/100], Step [320/760], Total Loss: 3.0906\nEpoch [56/100], Step [330/760], Total Loss: 3.1144\nEpoch [56/100], Step [340/760], Total Loss: 3.1529\nEpoch [56/100], Step [350/760], Total Loss: 3.1238\nEpoch [56/100], Step [360/760], Total Loss: 3.1809\nEpoch [56/100], Step [370/760], Total Loss: 3.0670\nEpoch [56/100], Step [380/760], Total Loss: 3.1798\nEpoch [56/100], Step [390/760], Total Loss: 3.0527\nEpoch [56/100], Step [400/760], Total Loss: 3.0635\nEpoch [56/100], Step [410/760], Total Loss: 3.0647\nEpoch [56/100], Step [420/760], Total Loss: 3.0797\nEpoch [56/100], Step [430/760], Total Loss: 3.0947\nEpoch [56/100], Step [440/760], Total Loss: 3.1194\nEpoch [56/100], Step [450/760], Total Loss: 3.1623\nEpoch [56/100], Step [460/760], Total Loss: 3.0974\nEpoch [56/100], Step [470/760], Total Loss: 3.0898\nEpoch [56/100], Step [480/760], Total Loss: 3.1471\nEpoch [56/100], Step [490/760], Total Loss: 3.0706\nEpoch [56/100], Step [500/760], Total Loss: 3.0986\nEpoch [56/100], Step [510/760], Total Loss: 3.0557\nEpoch [56/100], Step [520/760], Total Loss: 3.1549\nEpoch [56/100], Step [530/760], Total Loss: 3.1061\nEpoch [56/100], Step [540/760], Total Loss: 3.1303\nEpoch [56/100], Step [550/760], Total Loss: 3.0805\nEpoch [56/100], Step [560/760], Total Loss: 3.1179\nEpoch [56/100], Step [570/760], Total Loss: 3.1013\nEpoch [56/100], Step [580/760], Total Loss: 3.1362\nEpoch [56/100], Step [590/760], Total Loss: 3.1170\nEpoch [56/100], Step [600/760], Total Loss: 3.1491\nEpoch [56/100], Step [610/760], Total Loss: 3.1103\nEpoch [56/100], Step [620/760], Total Loss: 3.1106\nEpoch [56/100], Step [630/760], Total Loss: 3.0892\nEpoch [56/100], Step [640/760], Total Loss: 3.1961\nEpoch [56/100], Step [650/760], Total Loss: 3.1249\nEpoch [56/100], Step [660/760], Total Loss: 3.0960\nEpoch [56/100], Step [670/760], Total Loss: 3.1000\nEpoch [56/100], Step [680/760], Total Loss: 3.1087\nEpoch [56/100], Step [690/760], Total Loss: 3.1017\nEpoch [56/100], Step [700/760], Total Loss: 3.0837\nEpoch [56/100], Step [710/760], Total Loss: 3.0937\nEpoch [56/100], Step [720/760], Total Loss: 3.0668\nEpoch [56/100], Step [730/760], Total Loss: 3.1080\nEpoch [56/100], Step [740/760], Total Loss: 3.0870\nEpoch [56/100], Step [750/760], Total Loss: 3.1418\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 56/100 [2:10:42<1:42:38, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [56/100], Step [760/760], Total Loss: 3.1717\nEpoch [57/100], Step [10/760], Total Loss: 3.0890\nEpoch [57/100], Step [20/760], Total Loss: 3.0737\nEpoch [57/100], Step [30/760], Total Loss: 3.1035\nEpoch [57/100], Step [40/760], Total Loss: 3.1308\nEpoch [57/100], Step [50/760], Total Loss: 3.1253\nEpoch [57/100], Step [60/760], Total Loss: 3.0827\nEpoch [57/100], Step [70/760], Total Loss: 3.1144\nEpoch [57/100], Step [80/760], Total Loss: 3.1037\nEpoch [57/100], Step [90/760], Total Loss: 3.1419\nEpoch [57/100], Step [100/760], Total Loss: 3.1253\nEpoch [57/100], Step [110/760], Total Loss: 3.1683\nEpoch [57/100], Step [120/760], Total Loss: 3.1597\nEpoch [57/100], Step [130/760], Total Loss: 3.0603\nEpoch [57/100], Step [140/760], Total Loss: 3.0998\nEpoch [57/100], Step [150/760], Total Loss: 3.1008\nEpoch [57/100], Step [160/760], Total Loss: 3.1315\nEpoch [57/100], Step [170/760], Total Loss: 3.0563\nEpoch [57/100], Step [180/760], Total Loss: 3.1045\nEpoch [57/100], Step [190/760], Total Loss: 3.0862\nEpoch [57/100], Step [200/760], Total Loss: 3.1186\nEpoch [57/100], Step [210/760], Total Loss: 3.1249\nEpoch [57/100], Step [220/760], Total Loss: 3.0998\nEpoch [57/100], Step [230/760], Total Loss: 3.0814\nEpoch [57/100], Step [240/760], Total Loss: 3.0974\nEpoch [57/100], Step [250/760], Total Loss: 3.0456\nEpoch [57/100], Step [260/760], Total Loss: 3.1211\nEpoch [57/100], Step [270/760], Total Loss: 3.0830\nEpoch [57/100], Step [280/760], Total Loss: 3.0862\nEpoch [57/100], Step [290/760], Total Loss: 3.0404\nEpoch [57/100], Step [300/760], Total Loss: 3.1332\nEpoch [57/100], Step [310/760], Total Loss: 3.0895\nEpoch [57/100], Step [320/760], Total Loss: 3.1438\nEpoch [57/100], Step [330/760], Total Loss: 3.0688\nEpoch [57/100], Step [340/760], Total Loss: 3.1329\nEpoch [57/100], Step [350/760], Total Loss: 3.0336\nEpoch [57/100], Step [360/760], Total Loss: 3.0912\nEpoch [57/100], Step [370/760], Total Loss: 3.0691\nEpoch [57/100], Step [380/760], Total Loss: 3.0779\nEpoch [57/100], Step [390/760], Total Loss: 3.0985\nEpoch [57/100], Step [400/760], Total Loss: 3.0829\nEpoch [57/100], Step [410/760], Total Loss: 3.1285\nEpoch [57/100], Step [420/760], Total Loss: 3.1726\nEpoch [57/100], Step [430/760], Total Loss: 3.1412\nEpoch [57/100], Step [440/760], Total Loss: 3.0992\nEpoch [57/100], Step [450/760], Total Loss: 3.1365\nEpoch [57/100], Step [460/760], Total Loss: 3.1748\nEpoch [57/100], Step [470/760], Total Loss: 3.0968\nEpoch [57/100], Step [480/760], Total Loss: 3.0770\nEpoch [57/100], Step [490/760], Total Loss: 3.0843\nEpoch [57/100], Step [500/760], Total Loss: 3.0858\nEpoch [57/100], Step [510/760], Total Loss: 3.0605\nEpoch [57/100], Step [520/760], Total Loss: 3.1030\nEpoch [57/100], Step [530/760], Total Loss: 3.0519\nEpoch [57/100], Step [540/760], Total Loss: 3.0649\nEpoch [57/100], Step [550/760], Total Loss: 3.0390\nEpoch [57/100], Step [560/760], Total Loss: 3.1123\nEpoch [57/100], Step [570/760], Total Loss: 3.0970\nEpoch [57/100], Step [580/760], Total Loss: 3.1142\nEpoch [57/100], Step [590/760], Total Loss: 3.1630\nEpoch [57/100], Step [600/760], Total Loss: 3.1144\nEpoch [57/100], Step [610/760], Total Loss: 3.0874\nEpoch [57/100], Step [620/760], Total Loss: 3.1616\nEpoch [57/100], Step [630/760], Total Loss: 3.0568\nEpoch [57/100], Step [640/760], Total Loss: 3.1117\nEpoch [57/100], Step [650/760], Total Loss: 3.1332\nEpoch [57/100], Step [660/760], Total Loss: 3.0927\nEpoch [57/100], Step [670/760], Total Loss: 3.0541\nEpoch [57/100], Step [680/760], Total Loss: 3.1067\nEpoch [57/100], Step [690/760], Total Loss: 3.1359\nEpoch [57/100], Step [700/760], Total Loss: 3.0960\nEpoch [57/100], Step [710/760], Total Loss: 3.0600\nEpoch [57/100], Step [720/760], Total Loss: 3.1454\nEpoch [57/100], Step [730/760], Total Loss: 3.1068\nEpoch [57/100], Step [740/760], Total Loss: 3.0971\nEpoch [57/100], Step [750/760], Total Loss: 3.1345\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 57/100 [2:13:02<1:40:18, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [57/100], Step [760/760], Total Loss: 3.1254\nEpoch [58/100], Step [10/760], Total Loss: 3.0851\nEpoch [58/100], Step [20/760], Total Loss: 3.1011\nEpoch [58/100], Step [30/760], Total Loss: 3.2094\nEpoch [58/100], Step [40/760], Total Loss: 3.1003\nEpoch [58/100], Step [50/760], Total Loss: 3.0789\nEpoch [58/100], Step [60/760], Total Loss: 3.1434\nEpoch [58/100], Step [70/760], Total Loss: 3.0948\nEpoch [58/100], Step [80/760], Total Loss: 3.1367\nEpoch [58/100], Step [90/760], Total Loss: 3.1195\nEpoch [58/100], Step [100/760], Total Loss: 3.1472\nEpoch [58/100], Step [110/760], Total Loss: 3.0703\nEpoch [58/100], Step [120/760], Total Loss: 3.0729\nEpoch [58/100], Step [130/760], Total Loss: 3.0499\nEpoch [58/100], Step [140/760], Total Loss: 3.1400\nEpoch [58/100], Step [150/760], Total Loss: 3.1545\nEpoch [58/100], Step [160/760], Total Loss: 3.1406\nEpoch [58/100], Step [170/760], Total Loss: 3.0682\nEpoch [58/100], Step [180/760], Total Loss: 3.0985\nEpoch [58/100], Step [190/760], Total Loss: 3.0461\nEpoch [58/100], Step [200/760], Total Loss: 3.0879\nEpoch [58/100], Step [210/760], Total Loss: 3.0922\nEpoch [58/100], Step [220/760], Total Loss: 3.0681\nEpoch [58/100], Step [230/760], Total Loss: 3.0952\nEpoch [58/100], Step [240/760], Total Loss: 3.1168\nEpoch [58/100], Step [250/760], Total Loss: 3.0834\nEpoch [58/100], Step [260/760], Total Loss: 3.0758\nEpoch [58/100], Step [270/760], Total Loss: 3.0791\nEpoch [58/100], Step [280/760], Total Loss: 3.0768\nEpoch [58/100], Step [290/760], Total Loss: 3.0577\nEpoch [58/100], Step [300/760], Total Loss: 3.0845\nEpoch [58/100], Step [310/760], Total Loss: 3.0159\nEpoch [58/100], Step [320/760], Total Loss: 3.0627\nEpoch [58/100], Step [330/760], Total Loss: 3.0546\nEpoch [58/100], Step [340/760], Total Loss: 3.1331\nEpoch [58/100], Step [350/760], Total Loss: 3.0733\nEpoch [58/100], Step [360/760], Total Loss: 3.2108\nEpoch [58/100], Step [370/760], Total Loss: 3.0969\nEpoch [58/100], Step [380/760], Total Loss: 3.0913\nEpoch [58/100], Step [390/760], Total Loss: 3.0979\nEpoch [58/100], Step [400/760], Total Loss: 3.0451\nEpoch [58/100], Step [410/760], Total Loss: 3.1536\nEpoch [58/100], Step [420/760], Total Loss: 3.2037\nEpoch [58/100], Step [430/760], Total Loss: 3.0842\nEpoch [58/100], Step [440/760], Total Loss: 3.1011\nEpoch [58/100], Step [450/760], Total Loss: 3.0907\nEpoch [58/100], Step [460/760], Total Loss: 3.1200\nEpoch [58/100], Step [470/760], Total Loss: 3.1495\nEpoch [58/100], Step [480/760], Total Loss: 3.0888\nEpoch [58/100], Step [490/760], Total Loss: 3.0488\nEpoch [58/100], Step [500/760], Total Loss: 3.0875\nEpoch [58/100], Step [510/760], Total Loss: 3.0613\nEpoch [58/100], Step [520/760], Total Loss: 3.0997\nEpoch [58/100], Step [530/760], Total Loss: 3.0776\nEpoch [58/100], Step [540/760], Total Loss: 3.0662\nEpoch [58/100], Step [550/760], Total Loss: 3.0817\nEpoch [58/100], Step [560/760], Total Loss: 3.1020\nEpoch [58/100], Step [570/760], Total Loss: 3.1057\nEpoch [58/100], Step [580/760], Total Loss: 3.1022\nEpoch [58/100], Step [590/760], Total Loss: 3.0846\nEpoch [58/100], Step [600/760], Total Loss: 3.1153\nEpoch [58/100], Step [610/760], Total Loss: 3.1070\nEpoch [58/100], Step [620/760], Total Loss: 3.1004\nEpoch [58/100], Step [630/760], Total Loss: 3.0836\nEpoch [58/100], Step [640/760], Total Loss: 3.0614\nEpoch [58/100], Step [650/760], Total Loss: 3.1050\nEpoch [58/100], Step [660/760], Total Loss: 3.0509\nEpoch [58/100], Step [670/760], Total Loss: 3.0403\nEpoch [58/100], Step [680/760], Total Loss: 3.1698\nEpoch [58/100], Step [690/760], Total Loss: 3.1160\nEpoch [58/100], Step [700/760], Total Loss: 3.0918\nEpoch [58/100], Step [710/760], Total Loss: 3.0883\nEpoch [58/100], Step [720/760], Total Loss: 3.1075\nEpoch [58/100], Step [730/760], Total Loss: 3.1167\nEpoch [58/100], Step [740/760], Total Loss: 3.1011\nEpoch [58/100], Step [750/760], Total Loss: 3.1091\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 58/100 [2:15:22<1:37:58, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [58/100], Step [760/760], Total Loss: 3.1053\nEpoch [59/100], Step [10/760], Total Loss: 3.0860\nEpoch [59/100], Step [20/760], Total Loss: 3.0973\nEpoch [59/100], Step [30/760], Total Loss: 3.1011\nEpoch [59/100], Step [40/760], Total Loss: 3.1097\nEpoch [59/100], Step [50/760], Total Loss: 3.2284\nEpoch [59/100], Step [60/760], Total Loss: 3.0862\nEpoch [59/100], Step [70/760], Total Loss: 3.0236\nEpoch [59/100], Step [80/760], Total Loss: 3.0522\nEpoch [59/100], Step [90/760], Total Loss: 3.0963\nEpoch [59/100], Step [100/760], Total Loss: 3.0719\nEpoch [59/100], Step [110/760], Total Loss: 3.1254\nEpoch [59/100], Step [120/760], Total Loss: 3.1230\nEpoch [59/100], Step [130/760], Total Loss: 3.0763\nEpoch [59/100], Step [140/760], Total Loss: 3.1014\nEpoch [59/100], Step [150/760], Total Loss: 3.0794\nEpoch [59/100], Step [160/760], Total Loss: 3.0755\nEpoch [59/100], Step [170/760], Total Loss: 3.1630\nEpoch [59/100], Step [180/760], Total Loss: 3.1229\nEpoch [59/100], Step [190/760], Total Loss: 3.0755\nEpoch [59/100], Step [200/760], Total Loss: 3.0867\nEpoch [59/100], Step [210/760], Total Loss: 3.1107\nEpoch [59/100], Step [220/760], Total Loss: 3.1146\nEpoch [59/100], Step [230/760], Total Loss: 3.0445\nEpoch [59/100], Step [240/760], Total Loss: 3.0887\nEpoch [59/100], Step [250/760], Total Loss: 3.0893\nEpoch [59/100], Step [260/760], Total Loss: 3.0890\nEpoch [59/100], Step [270/760], Total Loss: 3.0511\nEpoch [59/100], Step [280/760], Total Loss: 3.1274\nEpoch [59/100], Step [290/760], Total Loss: 3.0839\nEpoch [59/100], Step [300/760], Total Loss: 3.1758\nEpoch [59/100], Step [310/760], Total Loss: 3.0872\nEpoch [59/100], Step [320/760], Total Loss: 3.1202\nEpoch [59/100], Step [330/760], Total Loss: 3.0298\nEpoch [59/100], Step [340/760], Total Loss: 3.0784\nEpoch [59/100], Step [350/760], Total Loss: 3.0676\nEpoch [59/100], Step [360/760], Total Loss: 3.0645\nEpoch [59/100], Step [370/760], Total Loss: 3.1341\nEpoch [59/100], Step [380/760], Total Loss: 3.1299\nEpoch [59/100], Step [390/760], Total Loss: 3.1201\nEpoch [59/100], Step [400/760], Total Loss: 3.1027\nEpoch [59/100], Step [410/760], Total Loss: 3.0937\nEpoch [59/100], Step [420/760], Total Loss: 3.0653\nEpoch [59/100], Step [430/760], Total Loss: 3.1263\nEpoch [59/100], Step [440/760], Total Loss: 3.1432\nEpoch [59/100], Step [450/760], Total Loss: 3.0563\nEpoch [59/100], Step [460/760], Total Loss: 3.0736\nEpoch [59/100], Step [470/760], Total Loss: 3.0452\nEpoch [59/100], Step [480/760], Total Loss: 3.0820\nEpoch [59/100], Step [490/760], Total Loss: 3.0529\nEpoch [59/100], Step [500/760], Total Loss: 3.0709\nEpoch [59/100], Step [510/760], Total Loss: 3.0468\nEpoch [59/100], Step [520/760], Total Loss: 3.1482\nEpoch [59/100], Step [530/760], Total Loss: 3.1255\nEpoch [59/100], Step [540/760], Total Loss: 3.1012\nEpoch [59/100], Step [550/760], Total Loss: 3.0698\nEpoch [59/100], Step [560/760], Total Loss: 3.0501\nEpoch [59/100], Step [570/760], Total Loss: 3.0773\nEpoch [59/100], Step [580/760], Total Loss: 3.1328\nEpoch [59/100], Step [590/760], Total Loss: 3.1244\nEpoch [59/100], Step [600/760], Total Loss: 3.0777\nEpoch [59/100], Step [610/760], Total Loss: 3.0657\nEpoch [59/100], Step [620/760], Total Loss: 3.0810\nEpoch [59/100], Step [630/760], Total Loss: 3.0996\nEpoch [59/100], Step [640/760], Total Loss: 3.0613\nEpoch [59/100], Step [650/760], Total Loss: 3.1454\nEpoch [59/100], Step [660/760], Total Loss: 3.1270\nEpoch [59/100], Step [670/760], Total Loss: 3.1618\nEpoch [59/100], Step [680/760], Total Loss: 3.0842\nEpoch [59/100], Step [690/760], Total Loss: 3.1013\nEpoch [59/100], Step [700/760], Total Loss: 3.0947\nEpoch [59/100], Step [710/760], Total Loss: 3.0963\nEpoch [59/100], Step [720/760], Total Loss: 3.0470\nEpoch [59/100], Step [730/760], Total Loss: 3.0308\nEpoch [59/100], Step [740/760], Total Loss: 3.0853\nEpoch [59/100], Step [750/760], Total Loss: 3.0094\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 59/100 [2:17:42<1:35:38, 139.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [59/100], Step [760/760], Total Loss: 3.1450\nEpoch [60/100], Step [10/760], Total Loss: 3.1153\nEpoch [60/100], Step [20/760], Total Loss: 3.0875\nEpoch [60/100], Step [30/760], Total Loss: 3.0709\nEpoch [60/100], Step [40/760], Total Loss: 3.0671\nEpoch [60/100], Step [50/760], Total Loss: 3.0581\nEpoch [60/100], Step [60/760], Total Loss: 3.1254\nEpoch [60/100], Step [70/760], Total Loss: 3.1241\nEpoch [60/100], Step [80/760], Total Loss: 3.0881\nEpoch [60/100], Step [90/760], Total Loss: 3.0690\nEpoch [60/100], Step [100/760], Total Loss: 3.0709\nEpoch [60/100], Step [110/760], Total Loss: 3.1059\nEpoch [60/100], Step [120/760], Total Loss: 3.0727\nEpoch [60/100], Step [130/760], Total Loss: 3.0857\nEpoch [60/100], Step [140/760], Total Loss: 3.1003\nEpoch [60/100], Step [150/760], Total Loss: 3.0655\nEpoch [60/100], Step [160/760], Total Loss: 3.2277\nEpoch [60/100], Step [170/760], Total Loss: 3.0638\nEpoch [60/100], Step [180/760], Total Loss: 3.1141\nEpoch [60/100], Step [190/760], Total Loss: 3.0795\nEpoch [60/100], Step [200/760], Total Loss: 3.0850\nEpoch [60/100], Step [210/760], Total Loss: 3.1175\nEpoch [60/100], Step [220/760], Total Loss: 3.1615\nEpoch [60/100], Step [230/760], Total Loss: 3.1106\nEpoch [60/100], Step [240/760], Total Loss: 3.0739\nEpoch [60/100], Step [250/760], Total Loss: 3.1038\nEpoch [60/100], Step [260/760], Total Loss: 3.0701\nEpoch [60/100], Step [270/760], Total Loss: 3.1409\nEpoch [60/100], Step [280/760], Total Loss: 3.0587\nEpoch [60/100], Step [290/760], Total Loss: 3.0995\nEpoch [60/100], Step [300/760], Total Loss: 3.0911\nEpoch [60/100], Step [310/760], Total Loss: 3.1620\nEpoch [60/100], Step [320/760], Total Loss: 3.1936\nEpoch [60/100], Step [330/760], Total Loss: 3.0639\nEpoch [60/100], Step [340/760], Total Loss: 3.1273\nEpoch [60/100], Step [350/760], Total Loss: 3.1213\nEpoch [60/100], Step [360/760], Total Loss: 3.0790\nEpoch [60/100], Step [370/760], Total Loss: 3.0636\nEpoch [60/100], Step [380/760], Total Loss: 3.0600\nEpoch [60/100], Step [390/760], Total Loss: 3.0856\nEpoch [60/100], Step [400/760], Total Loss: 3.1064\nEpoch [60/100], Step [410/760], Total Loss: 3.1079\nEpoch [60/100], Step [420/760], Total Loss: 3.1329\nEpoch [60/100], Step [430/760], Total Loss: 3.1444\nEpoch [60/100], Step [440/760], Total Loss: 3.0400\nEpoch [60/100], Step [450/760], Total Loss: 3.0988\nEpoch [60/100], Step [460/760], Total Loss: 3.0966\nEpoch [60/100], Step [470/760], Total Loss: 3.0585\nEpoch [60/100], Step [480/760], Total Loss: 3.1470\nEpoch [60/100], Step [490/760], Total Loss: 3.1187\nEpoch [60/100], Step [500/760], Total Loss: 3.1158\nEpoch [60/100], Step [510/760], Total Loss: 3.0809\nEpoch [60/100], Step [520/760], Total Loss: 3.0679\nEpoch [60/100], Step [530/760], Total Loss: 3.0781\nEpoch [60/100], Step [540/760], Total Loss: 3.0902\nEpoch [60/100], Step [550/760], Total Loss: 3.1313\nEpoch [60/100], Step [560/760], Total Loss: 3.0820\nEpoch [60/100], Step [570/760], Total Loss: 3.1300\nEpoch [60/100], Step [580/760], Total Loss: 3.0941\nEpoch [60/100], Step [590/760], Total Loss: 3.0436\nEpoch [60/100], Step [600/760], Total Loss: 3.0493\nEpoch [60/100], Step [610/760], Total Loss: 3.1142\nEpoch [60/100], Step [620/760], Total Loss: 3.0587\nEpoch [60/100], Step [630/760], Total Loss: 3.0981\nEpoch [60/100], Step [640/760], Total Loss: 3.1040\nEpoch [60/100], Step [650/760], Total Loss: 3.1486\nEpoch [60/100], Step [660/760], Total Loss: 3.0800\nEpoch [60/100], Step [670/760], Total Loss: 3.1282\nEpoch [60/100], Step [680/760], Total Loss: 3.0651\nEpoch [60/100], Step [690/760], Total Loss: 3.0704\nEpoch [60/100], Step [700/760], Total Loss: 3.0450\nEpoch [60/100], Step [710/760], Total Loss: 3.1213\nEpoch [60/100], Step [720/760], Total Loss: 3.1254\nEpoch [60/100], Step [730/760], Total Loss: 3.0689\nEpoch [60/100], Step [740/760], Total Loss: 3.0881\nEpoch [60/100], Step [750/760], Total Loss: 3.1038\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 60/100 [2:20:02<1:33:18, 139.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [60/100], Step [760/760], Total Loss: 3.1201\nEpoch [61/100], Step [10/760], Total Loss: 3.0595\nEpoch [61/100], Step [20/760], Total Loss: 3.0895\nEpoch [61/100], Step [30/760], Total Loss: 3.0819\nEpoch [61/100], Step [40/760], Total Loss: 3.0728\nEpoch [61/100], Step [50/760], Total Loss: 3.1039\nEpoch [61/100], Step [60/760], Total Loss: 3.1085\nEpoch [61/100], Step [70/760], Total Loss: 3.0406\nEpoch [61/100], Step [80/760], Total Loss: 3.0876\nEpoch [61/100], Step [90/760], Total Loss: 3.0995\nEpoch [61/100], Step [100/760], Total Loss: 3.0680\nEpoch [61/100], Step [110/760], Total Loss: 3.1188\nEpoch [61/100], Step [120/760], Total Loss: 3.0827\nEpoch [61/100], Step [130/760], Total Loss: 3.0748\nEpoch [61/100], Step [140/760], Total Loss: 3.0945\nEpoch [61/100], Step [150/760], Total Loss: 3.1650\nEpoch [61/100], Step [160/760], Total Loss: 3.0923\nEpoch [61/100], Step [170/760], Total Loss: 3.0625\nEpoch [61/100], Step [180/760], Total Loss: 3.1028\nEpoch [61/100], Step [190/760], Total Loss: 3.0533\nEpoch [61/100], Step [200/760], Total Loss: 3.0742\nEpoch [61/100], Step [210/760], Total Loss: 3.0835\nEpoch [61/100], Step [220/760], Total Loss: 3.0567\nEpoch [61/100], Step [230/760], Total Loss: 3.0663\nEpoch [61/100], Step [240/760], Total Loss: 3.1004\nEpoch [61/100], Step [250/760], Total Loss: 3.1369\nEpoch [61/100], Step [260/760], Total Loss: 3.0909\nEpoch [61/100], Step [270/760], Total Loss: 3.0413\nEpoch [61/100], Step [280/760], Total Loss: 3.0512\nEpoch [61/100], Step [290/760], Total Loss: 3.0645\nEpoch [61/100], Step [300/760], Total Loss: 3.0977\nEpoch [61/100], Step [310/760], Total Loss: 3.0915\nEpoch [61/100], Step [320/760], Total Loss: 3.0814\nEpoch [61/100], Step [330/760], Total Loss: 3.0728\nEpoch [61/100], Step [340/760], Total Loss: 3.0562\nEpoch [61/100], Step [350/760], Total Loss: 3.0735\nEpoch [61/100], Step [360/760], Total Loss: 3.0459\nEpoch [61/100], Step [370/760], Total Loss: 3.1032\nEpoch [61/100], Step [380/760], Total Loss: 3.0412\nEpoch [61/100], Step [390/760], Total Loss: 3.0325\nEpoch [61/100], Step [400/760], Total Loss: 3.0486\nEpoch [61/100], Step [410/760], Total Loss: 3.0231\nEpoch [61/100], Step [420/760], Total Loss: 3.0690\nEpoch [61/100], Step [430/760], Total Loss: 3.1277\nEpoch [61/100], Step [440/760], Total Loss: 3.1064\nEpoch [61/100], Step [450/760], Total Loss: 3.0729\nEpoch [61/100], Step [460/760], Total Loss: 3.1214\nEpoch [61/100], Step [470/760], Total Loss: 3.0651\nEpoch [61/100], Step [480/760], Total Loss: 3.1141\nEpoch [61/100], Step [490/760], Total Loss: 3.0888\nEpoch [61/100], Step [500/760], Total Loss: 3.1146\nEpoch [61/100], Step [510/760], Total Loss: 3.0769\nEpoch [61/100], Step [520/760], Total Loss: 3.0810\nEpoch [61/100], Step [530/760], Total Loss: 3.0582\nEpoch [61/100], Step [540/760], Total Loss: 3.0444\nEpoch [61/100], Step [550/760], Total Loss: 3.1434\nEpoch [61/100], Step [560/760], Total Loss: 3.0894\nEpoch [61/100], Step [570/760], Total Loss: 3.0718\nEpoch [61/100], Step [580/760], Total Loss: 3.0511\nEpoch [61/100], Step [590/760], Total Loss: 3.1134\nEpoch [61/100], Step [600/760], Total Loss: 3.1299\nEpoch [61/100], Step [610/760], Total Loss: 3.0613\nEpoch [61/100], Step [620/760], Total Loss: 3.1260\nEpoch [61/100], Step [630/760], Total Loss: 3.1242\nEpoch [61/100], Step [640/760], Total Loss: 3.0650\nEpoch [61/100], Step [650/760], Total Loss: 3.0540\nEpoch [61/100], Step [660/760], Total Loss: 3.0710\nEpoch [61/100], Step [670/760], Total Loss: 3.1936\nEpoch [61/100], Step [680/760], Total Loss: 3.0700\nEpoch [61/100], Step [690/760], Total Loss: 3.0653\nEpoch [61/100], Step [700/760], Total Loss: 3.1210\nEpoch [61/100], Step [710/760], Total Loss: 3.1458\nEpoch [61/100], Step [720/760], Total Loss: 3.0567\nEpoch [61/100], Step [730/760], Total Loss: 3.0212\nEpoch [61/100], Step [740/760], Total Loss: 3.0332\nEpoch [61/100], Step [750/760], Total Loss: 3.0495\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 61/100 [2:22:22<1:30:58, 139.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [61/100], Step [760/760], Total Loss: 3.0724\nEpoch [62/100], Step [10/760], Total Loss: 3.0437\nEpoch [62/100], Step [20/760], Total Loss: 3.0599\nEpoch [62/100], Step [30/760], Total Loss: 3.0759\nEpoch [62/100], Step [40/760], Total Loss: 3.1158\nEpoch [62/100], Step [50/760], Total Loss: 3.0886\nEpoch [62/100], Step [60/760], Total Loss: 3.0540\nEpoch [62/100], Step [70/760], Total Loss: 3.1014\nEpoch [62/100], Step [80/760], Total Loss: 3.0470\nEpoch [62/100], Step [90/760], Total Loss: 3.1052\nEpoch [62/100], Step [100/760], Total Loss: 3.1248\nEpoch [62/100], Step [110/760], Total Loss: 3.0875\nEpoch [62/100], Step [120/760], Total Loss: 3.1010\nEpoch [62/100], Step [130/760], Total Loss: 3.0621\nEpoch [62/100], Step [140/760], Total Loss: 3.0756\nEpoch [62/100], Step [150/760], Total Loss: 3.1110\nEpoch [62/100], Step [160/760], Total Loss: 3.0052\nEpoch [62/100], Step [170/760], Total Loss: 3.1524\nEpoch [62/100], Step [180/760], Total Loss: 3.0828\nEpoch [62/100], Step [190/760], Total Loss: 3.0338\nEpoch [62/100], Step [200/760], Total Loss: 3.0862\nEpoch [62/100], Step [210/760], Total Loss: 3.0319\nEpoch [62/100], Step [220/760], Total Loss: 3.0364\nEpoch [62/100], Step [230/760], Total Loss: 3.1282\nEpoch [62/100], Step [240/760], Total Loss: 3.0742\nEpoch [62/100], Step [250/760], Total Loss: 3.1078\nEpoch [62/100], Step [260/760], Total Loss: 3.0936\nEpoch [62/100], Step [270/760], Total Loss: 3.1264\nEpoch [62/100], Step [280/760], Total Loss: 3.1113\nEpoch [62/100], Step [290/760], Total Loss: 3.0351\nEpoch [62/100], Step [300/760], Total Loss: 3.0976\nEpoch [62/100], Step [310/760], Total Loss: 3.1315\nEpoch [62/100], Step [320/760], Total Loss: 3.0850\nEpoch [62/100], Step [330/760], Total Loss: 3.0647\nEpoch [62/100], Step [340/760], Total Loss: 3.0730\nEpoch [62/100], Step [350/760], Total Loss: 3.0520\nEpoch [62/100], Step [360/760], Total Loss: 3.1016\nEpoch [62/100], Step [370/760], Total Loss: 3.0613\nEpoch [62/100], Step [380/760], Total Loss: 3.1175\nEpoch [62/100], Step [390/760], Total Loss: 3.1223\nEpoch [62/100], Step [400/760], Total Loss: 3.1131\nEpoch [62/100], Step [410/760], Total Loss: 3.0843\nEpoch [62/100], Step [420/760], Total Loss: 3.0652\nEpoch [62/100], Step [430/760], Total Loss: 3.0982\nEpoch [62/100], Step [440/760], Total Loss: 3.0675\nEpoch [62/100], Step [450/760], Total Loss: 3.1159\nEpoch [62/100], Step [460/760], Total Loss: 3.0936\nEpoch [62/100], Step [470/760], Total Loss: 3.1366\nEpoch [62/100], Step [480/760], Total Loss: 3.0679\nEpoch [62/100], Step [490/760], Total Loss: 3.0759\nEpoch [62/100], Step [500/760], Total Loss: 3.0774\nEpoch [62/100], Step [510/760], Total Loss: 3.0509\nEpoch [62/100], Step [520/760], Total Loss: 3.0955\nEpoch [62/100], Step [530/760], Total Loss: 3.1040\nEpoch [62/100], Step [540/760], Total Loss: 3.0605\nEpoch [62/100], Step [550/760], Total Loss: 3.1025\nEpoch [62/100], Step [560/760], Total Loss: 3.1103\nEpoch [62/100], Step [570/760], Total Loss: 3.1113\nEpoch [62/100], Step [580/760], Total Loss: 3.0727\nEpoch [62/100], Step [590/760], Total Loss: 3.0715\nEpoch [62/100], Step [600/760], Total Loss: 3.0702\nEpoch [62/100], Step [610/760], Total Loss: 3.0580\nEpoch [62/100], Step [620/760], Total Loss: 3.1598\nEpoch [62/100], Step [630/760], Total Loss: 3.1291\nEpoch [62/100], Step [640/760], Total Loss: 3.1052\nEpoch [62/100], Step [650/760], Total Loss: 3.0733\nEpoch [62/100], Step [660/760], Total Loss: 3.0596\nEpoch [62/100], Step [670/760], Total Loss: 3.1344\nEpoch [62/100], Step [680/760], Total Loss: 3.1474\nEpoch [62/100], Step [690/760], Total Loss: 3.0808\nEpoch [62/100], Step [700/760], Total Loss: 3.1060\nEpoch [62/100], Step [710/760], Total Loss: 3.0798\nEpoch [62/100], Step [720/760], Total Loss: 3.0563\nEpoch [62/100], Step [730/760], Total Loss: 3.1675\nEpoch [62/100], Step [740/760], Total Loss: 3.1011\nEpoch [62/100], Step [750/760], Total Loss: 3.0776\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 62/100 [2:24:42<1:28:38, 139.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [62/100], Step [760/760], Total Loss: 3.1453\nEpoch [63/100], Step [10/760], Total Loss: 3.0759\nEpoch [63/100], Step [20/760], Total Loss: 3.1587\nEpoch [63/100], Step [30/760], Total Loss: 3.0646\nEpoch [63/100], Step [40/760], Total Loss: 3.0757\nEpoch [63/100], Step [50/760], Total Loss: 3.1115\nEpoch [63/100], Step [60/760], Total Loss: 3.0227\nEpoch [63/100], Step [70/760], Total Loss: 3.0925\nEpoch [63/100], Step [80/760], Total Loss: 3.1211\nEpoch [63/100], Step [90/760], Total Loss: 3.0469\nEpoch [63/100], Step [100/760], Total Loss: 3.0880\nEpoch [63/100], Step [110/760], Total Loss: 3.0976\nEpoch [63/100], Step [120/760], Total Loss: 3.0960\nEpoch [63/100], Step [130/760], Total Loss: 3.0807\nEpoch [63/100], Step [140/760], Total Loss: 3.0585\nEpoch [63/100], Step [150/760], Total Loss: 3.1060\nEpoch [63/100], Step [160/760], Total Loss: 3.1009\nEpoch [63/100], Step [170/760], Total Loss: 3.0555\nEpoch [63/100], Step [180/760], Total Loss: 3.0438\nEpoch [63/100], Step [190/760], Total Loss: 3.0822\nEpoch [63/100], Step [200/760], Total Loss: 3.1246\nEpoch [63/100], Step [210/760], Total Loss: 3.0804\nEpoch [63/100], Step [220/760], Total Loss: 3.0471\nEpoch [63/100], Step [230/760], Total Loss: 3.0729\nEpoch [63/100], Step [240/760], Total Loss: 3.0676\nEpoch [63/100], Step [250/760], Total Loss: 3.0438\nEpoch [63/100], Step [260/760], Total Loss: 3.1069\nEpoch [63/100], Step [270/760], Total Loss: 3.1003\nEpoch [63/100], Step [280/760], Total Loss: 3.1384\nEpoch [63/100], Step [290/760], Total Loss: 3.0741\nEpoch [63/100], Step [300/760], Total Loss: 3.1290\nEpoch [63/100], Step [310/760], Total Loss: 3.0455\nEpoch [63/100], Step [320/760], Total Loss: 3.0761\nEpoch [63/100], Step [330/760], Total Loss: 3.0916\nEpoch [63/100], Step [340/760], Total Loss: 3.1367\nEpoch [63/100], Step [350/760], Total Loss: 3.0877\nEpoch [63/100], Step [360/760], Total Loss: 3.0956\nEpoch [63/100], Step [370/760], Total Loss: 3.1372\nEpoch [63/100], Step [380/760], Total Loss: 3.0927\nEpoch [63/100], Step [390/760], Total Loss: 3.1165\nEpoch [63/100], Step [400/760], Total Loss: 3.1137\nEpoch [63/100], Step [410/760], Total Loss: 3.1249\nEpoch [63/100], Step [420/760], Total Loss: 3.0641\nEpoch [63/100], Step [430/760], Total Loss: 3.0801\nEpoch [63/100], Step [440/760], Total Loss: 3.1012\nEpoch [63/100], Step [450/760], Total Loss: 3.0656\nEpoch [63/100], Step [460/760], Total Loss: 3.1259\nEpoch [63/100], Step [470/760], Total Loss: 3.1487\nEpoch [63/100], Step [480/760], Total Loss: 3.1348\nEpoch [63/100], Step [490/760], Total Loss: 3.1477\nEpoch [63/100], Step [500/760], Total Loss: 3.1241\nEpoch [63/100], Step [510/760], Total Loss: 3.0894\nEpoch [63/100], Step [520/760], Total Loss: 3.0783\nEpoch [63/100], Step [530/760], Total Loss: 3.0934\nEpoch [63/100], Step [540/760], Total Loss: 3.1606\nEpoch [63/100], Step [550/760], Total Loss: 3.0758\nEpoch [63/100], Step [560/760], Total Loss: 3.0610\nEpoch [63/100], Step [570/760], Total Loss: 3.1069\nEpoch [63/100], Step [580/760], Total Loss: 3.0626\nEpoch [63/100], Step [590/760], Total Loss: 3.0980\nEpoch [63/100], Step [600/760], Total Loss: 3.1247\nEpoch [63/100], Step [610/760], Total Loss: 3.0987\nEpoch [63/100], Step [620/760], Total Loss: 3.0951\nEpoch [63/100], Step [630/760], Total Loss: 3.1044\nEpoch [63/100], Step [640/760], Total Loss: 3.0617\nEpoch [63/100], Step [650/760], Total Loss: 3.0687\nEpoch [63/100], Step [660/760], Total Loss: 3.0847\nEpoch [63/100], Step [670/760], Total Loss: 3.0758\nEpoch [63/100], Step [680/760], Total Loss: 3.1137\nEpoch [63/100], Step [690/760], Total Loss: 3.1443\nEpoch [63/100], Step [700/760], Total Loss: 3.1297\nEpoch [63/100], Step [710/760], Total Loss: 3.0902\nEpoch [63/100], Step [720/760], Total Loss: 3.0758\nEpoch [63/100], Step [730/760], Total Loss: 3.0809\nEpoch [63/100], Step [740/760], Total Loss: 3.0653\nEpoch [63/100], Step [750/760], Total Loss: 3.0883\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 63/100 [2:27:01<1:26:18, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [63/100], Step [760/760], Total Loss: 3.1699\nEpoch [64/100], Step [10/760], Total Loss: 3.1689\nEpoch [64/100], Step [20/760], Total Loss: 3.1040\nEpoch [64/100], Step [30/760], Total Loss: 3.0917\nEpoch [64/100], Step [40/760], Total Loss: 3.0655\nEpoch [64/100], Step [50/760], Total Loss: 3.0825\nEpoch [64/100], Step [60/760], Total Loss: 2.9988\nEpoch [64/100], Step [70/760], Total Loss: 3.0943\nEpoch [64/100], Step [80/760], Total Loss: 3.1176\nEpoch [64/100], Step [90/760], Total Loss: 3.1076\nEpoch [64/100], Step [100/760], Total Loss: 3.1247\nEpoch [64/100], Step [110/760], Total Loss: 3.1203\nEpoch [64/100], Step [120/760], Total Loss: 3.0211\nEpoch [64/100], Step [130/760], Total Loss: 3.0427\nEpoch [64/100], Step [140/760], Total Loss: 3.0940\nEpoch [64/100], Step [150/760], Total Loss: 3.1155\nEpoch [64/100], Step [160/760], Total Loss: 3.1183\nEpoch [64/100], Step [170/760], Total Loss: 3.0874\nEpoch [64/100], Step [180/760], Total Loss: 3.1837\nEpoch [64/100], Step [190/760], Total Loss: 3.0508\nEpoch [64/100], Step [200/760], Total Loss: 3.1139\nEpoch [64/100], Step [210/760], Total Loss: 3.0783\nEpoch [64/100], Step [220/760], Total Loss: 3.0935\nEpoch [64/100], Step [230/760], Total Loss: 3.0511\nEpoch [64/100], Step [240/760], Total Loss: 3.0620\nEpoch [64/100], Step [250/760], Total Loss: 3.0651\nEpoch [64/100], Step [260/760], Total Loss: 3.1057\nEpoch [64/100], Step [270/760], Total Loss: 3.0972\nEpoch [64/100], Step [280/760], Total Loss: 3.0809\nEpoch [64/100], Step [290/760], Total Loss: 3.1258\nEpoch [64/100], Step [300/760], Total Loss: 3.0438\nEpoch [64/100], Step [310/760], Total Loss: 3.0923\nEpoch [64/100], Step [320/760], Total Loss: 3.0917\nEpoch [64/100], Step [330/760], Total Loss: 3.1108\nEpoch [64/100], Step [340/760], Total Loss: 3.0650\nEpoch [64/100], Step [350/760], Total Loss: 3.1057\nEpoch [64/100], Step [360/760], Total Loss: 3.1070\nEpoch [64/100], Step [370/760], Total Loss: 3.1209\nEpoch [64/100], Step [380/760], Total Loss: 3.0855\nEpoch [64/100], Step [390/760], Total Loss: 3.0574\nEpoch [64/100], Step [400/760], Total Loss: 3.1092\nEpoch [64/100], Step [410/760], Total Loss: 3.0973\nEpoch [64/100], Step [420/760], Total Loss: 3.0717\nEpoch [64/100], Step [430/760], Total Loss: 3.0728\nEpoch [64/100], Step [440/760], Total Loss: 3.0775\nEpoch [64/100], Step [450/760], Total Loss: 3.0354\nEpoch [64/100], Step [460/760], Total Loss: 3.0329\nEpoch [64/100], Step [470/760], Total Loss: 3.0728\nEpoch [64/100], Step [480/760], Total Loss: 3.0971\nEpoch [64/100], Step [490/760], Total Loss: 3.0921\nEpoch [64/100], Step [500/760], Total Loss: 3.1340\nEpoch [64/100], Step [510/760], Total Loss: 3.1128\nEpoch [64/100], Step [520/760], Total Loss: 3.0882\nEpoch [64/100], Step [530/760], Total Loss: 3.1127\nEpoch [64/100], Step [540/760], Total Loss: 3.1148\nEpoch [64/100], Step [550/760], Total Loss: 3.0492\nEpoch [64/100], Step [560/760], Total Loss: 3.1226\nEpoch [64/100], Step [570/760], Total Loss: 3.0627\nEpoch [64/100], Step [580/760], Total Loss: 3.1209\nEpoch [64/100], Step [590/760], Total Loss: 3.1471\nEpoch [64/100], Step [600/760], Total Loss: 3.0986\nEpoch [64/100], Step [610/760], Total Loss: 3.0637\nEpoch [64/100], Step [620/760], Total Loss: 3.0610\nEpoch [64/100], Step [630/760], Total Loss: 3.0763\nEpoch [64/100], Step [640/760], Total Loss: 3.0855\nEpoch [64/100], Step [650/760], Total Loss: 3.1409\nEpoch [64/100], Step [660/760], Total Loss: 3.0495\nEpoch [64/100], Step [670/760], Total Loss: 3.0999\nEpoch [64/100], Step [680/760], Total Loss: 3.1100\nEpoch [64/100], Step [690/760], Total Loss: 3.0449\nEpoch [64/100], Step [700/760], Total Loss: 3.0662\nEpoch [64/100], Step [710/760], Total Loss: 3.0482\nEpoch [64/100], Step [720/760], Total Loss: 3.0932\nEpoch [64/100], Step [730/760], Total Loss: 3.0549\nEpoch [64/100], Step [740/760], Total Loss: 3.0381\nEpoch [64/100], Step [750/760], Total Loss: 3.0969\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 64/100 [2:29:21<1:23:58, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [64/100], Step [760/760], Total Loss: 3.0592\nEpoch [65/100], Step [10/760], Total Loss: 3.1831\nEpoch [65/100], Step [20/760], Total Loss: 3.1148\nEpoch [65/100], Step [30/760], Total Loss: 3.1394\nEpoch [65/100], Step [40/760], Total Loss: 3.0398\nEpoch [65/100], Step [50/760], Total Loss: 3.0832\nEpoch [65/100], Step [60/760], Total Loss: 3.0928\nEpoch [65/100], Step [70/760], Total Loss: 3.1589\nEpoch [65/100], Step [80/760], Total Loss: 3.1405\nEpoch [65/100], Step [90/760], Total Loss: 3.0916\nEpoch [65/100], Step [100/760], Total Loss: 3.0544\nEpoch [65/100], Step [110/760], Total Loss: 3.0610\nEpoch [65/100], Step [120/760], Total Loss: 3.1087\nEpoch [65/100], Step [130/760], Total Loss: 3.0508\nEpoch [65/100], Step [140/760], Total Loss: 3.0553\nEpoch [65/100], Step [150/760], Total Loss: 3.0579\nEpoch [65/100], Step [160/760], Total Loss: 3.0861\nEpoch [65/100], Step [170/760], Total Loss: 3.0964\nEpoch [65/100], Step [180/760], Total Loss: 3.0772\nEpoch [65/100], Step [190/760], Total Loss: 3.0604\nEpoch [65/100], Step [200/760], Total Loss: 3.0683\nEpoch [65/100], Step [210/760], Total Loss: 3.0701\nEpoch [65/100], Step [220/760], Total Loss: 3.1133\nEpoch [65/100], Step [230/760], Total Loss: 3.0624\nEpoch [65/100], Step [240/760], Total Loss: 3.1262\nEpoch [65/100], Step [250/760], Total Loss: 3.1093\nEpoch [65/100], Step [260/760], Total Loss: 3.1777\nEpoch [65/100], Step [270/760], Total Loss: 3.0884\nEpoch [65/100], Step [280/760], Total Loss: 3.0829\nEpoch [65/100], Step [290/760], Total Loss: 3.0717\nEpoch [65/100], Step [300/760], Total Loss: 3.1170\nEpoch [65/100], Step [310/760], Total Loss: 3.0601\nEpoch [65/100], Step [320/760], Total Loss: 3.0663\nEpoch [65/100], Step [330/760], Total Loss: 3.0965\nEpoch [65/100], Step [340/760], Total Loss: 3.0411\nEpoch [65/100], Step [350/760], Total Loss: 3.0629\nEpoch [65/100], Step [360/760], Total Loss: 3.1136\nEpoch [65/100], Step [370/760], Total Loss: 3.0837\nEpoch [65/100], Step [380/760], Total Loss: 3.0752\nEpoch [65/100], Step [390/760], Total Loss: 3.1003\nEpoch [65/100], Step [400/760], Total Loss: 3.1314\nEpoch [65/100], Step [410/760], Total Loss: 3.0528\nEpoch [65/100], Step [420/760], Total Loss: 3.1022\nEpoch [65/100], Step [430/760], Total Loss: 3.1019\nEpoch [65/100], Step [440/760], Total Loss: 3.1147\nEpoch [65/100], Step [450/760], Total Loss: 3.1034\nEpoch [65/100], Step [460/760], Total Loss: 3.0459\nEpoch [65/100], Step [470/760], Total Loss: 3.0597\nEpoch [65/100], Step [480/760], Total Loss: 3.0987\nEpoch [65/100], Step [490/760], Total Loss: 3.1145\nEpoch [65/100], Step [500/760], Total Loss: 3.0387\nEpoch [65/100], Step [510/760], Total Loss: 3.1071\nEpoch [65/100], Step [520/760], Total Loss: 3.1049\nEpoch [65/100], Step [530/760], Total Loss: 3.0290\nEpoch [65/100], Step [540/760], Total Loss: 3.0731\nEpoch [65/100], Step [550/760], Total Loss: 3.0980\nEpoch [65/100], Step [560/760], Total Loss: 3.0541\nEpoch [65/100], Step [570/760], Total Loss: 3.1149\nEpoch [65/100], Step [580/760], Total Loss: 3.0871\nEpoch [65/100], Step [590/760], Total Loss: 3.0678\nEpoch [65/100], Step [600/760], Total Loss: 3.1182\nEpoch [65/100], Step [610/760], Total Loss: 3.0634\nEpoch [65/100], Step [620/760], Total Loss: 3.0696\nEpoch [65/100], Step [630/760], Total Loss: 3.1414\nEpoch [65/100], Step [640/760], Total Loss: 3.1400\nEpoch [65/100], Step [650/760], Total Loss: 3.1106\nEpoch [65/100], Step [660/760], Total Loss: 3.0333\nEpoch [65/100], Step [670/760], Total Loss: 3.1154\nEpoch [65/100], Step [680/760], Total Loss: 3.0581\nEpoch [65/100], Step [690/760], Total Loss: 3.0377\nEpoch [65/100], Step [700/760], Total Loss: 3.0600\nEpoch [65/100], Step [710/760], Total Loss: 3.0723\nEpoch [65/100], Step [720/760], Total Loss: 3.1238\nEpoch [65/100], Step [730/760], Total Loss: 3.1193\nEpoch [65/100], Step [740/760], Total Loss: 3.0454\nEpoch [65/100], Step [750/760], Total Loss: 3.0648\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 65/100 [2:31:41<1:21:38, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [65/100], Step [760/760], Total Loss: 3.1073\nEpoch [66/100], Step [10/760], Total Loss: 3.0875\nEpoch [66/100], Step [20/760], Total Loss: 3.0505\nEpoch [66/100], Step [30/760], Total Loss: 3.0204\nEpoch [66/100], Step [40/760], Total Loss: 3.0832\nEpoch [66/100], Step [50/760], Total Loss: 3.0391\nEpoch [66/100], Step [60/760], Total Loss: 3.0300\nEpoch [66/100], Step [70/760], Total Loss: 3.0416\nEpoch [66/100], Step [80/760], Total Loss: 3.0542\nEpoch [66/100], Step [90/760], Total Loss: 3.0499\nEpoch [66/100], Step [100/760], Total Loss: 3.0406\nEpoch [66/100], Step [110/760], Total Loss: 3.0402\nEpoch [66/100], Step [120/760], Total Loss: 3.0890\nEpoch [66/100], Step [130/760], Total Loss: 3.0531\nEpoch [66/100], Step [140/760], Total Loss: 3.0783\nEpoch [66/100], Step [150/760], Total Loss: 3.0585\nEpoch [66/100], Step [160/760], Total Loss: 3.0827\nEpoch [66/100], Step [170/760], Total Loss: 3.0811\nEpoch [66/100], Step [180/760], Total Loss: 3.0632\nEpoch [66/100], Step [190/760], Total Loss: 3.1325\nEpoch [66/100], Step [200/760], Total Loss: 3.0472\nEpoch [66/100], Step [210/760], Total Loss: 3.0567\nEpoch [66/100], Step [220/760], Total Loss: 3.0631\nEpoch [66/100], Step [230/760], Total Loss: 3.1084\nEpoch [66/100], Step [240/760], Total Loss: 3.1287\nEpoch [66/100], Step [250/760], Total Loss: 3.0608\nEpoch [66/100], Step [260/760], Total Loss: 3.1387\nEpoch [66/100], Step [270/760], Total Loss: 3.0653\nEpoch [66/100], Step [280/760], Total Loss: 3.1970\nEpoch [66/100], Step [290/760], Total Loss: 3.1383\nEpoch [66/100], Step [300/760], Total Loss: 3.1374\nEpoch [66/100], Step [310/760], Total Loss: 3.0923\nEpoch [66/100], Step [320/760], Total Loss: 3.0906\nEpoch [66/100], Step [330/760], Total Loss: 3.0806\nEpoch [66/100], Step [340/760], Total Loss: 3.1023\nEpoch [66/100], Step [350/760], Total Loss: 3.0855\nEpoch [66/100], Step [360/760], Total Loss: 3.0867\nEpoch [66/100], Step [370/760], Total Loss: 3.0750\nEpoch [66/100], Step [380/760], Total Loss: 3.1273\nEpoch [66/100], Step [390/760], Total Loss: 3.0680\nEpoch [66/100], Step [400/760], Total Loss: 3.1044\nEpoch [66/100], Step [410/760], Total Loss: 3.0961\nEpoch [66/100], Step [420/760], Total Loss: 3.1252\nEpoch [66/100], Step [430/760], Total Loss: 3.0724\nEpoch [66/100], Step [440/760], Total Loss: 3.0570\nEpoch [66/100], Step [450/760], Total Loss: 3.1453\nEpoch [66/100], Step [460/760], Total Loss: 3.0958\nEpoch [66/100], Step [470/760], Total Loss: 3.1124\nEpoch [66/100], Step [480/760], Total Loss: 3.0996\nEpoch [66/100], Step [490/760], Total Loss: 2.9978\nEpoch [66/100], Step [500/760], Total Loss: 3.0828\nEpoch [66/100], Step [510/760], Total Loss: 3.0826\nEpoch [66/100], Step [520/760], Total Loss: 3.0892\nEpoch [66/100], Step [530/760], Total Loss: 3.0736\nEpoch [66/100], Step [540/760], Total Loss: 3.0222\nEpoch [66/100], Step [550/760], Total Loss: 3.0815\nEpoch [66/100], Step [560/760], Total Loss: 3.0871\nEpoch [66/100], Step [570/760], Total Loss: 3.0242\nEpoch [66/100], Step [580/760], Total Loss: 3.0850\nEpoch [66/100], Step [590/760], Total Loss: 3.0458\nEpoch [66/100], Step [600/760], Total Loss: 3.0612\nEpoch [66/100], Step [610/760], Total Loss: 3.0687\nEpoch [66/100], Step [620/760], Total Loss: 3.0866\nEpoch [66/100], Step [630/760], Total Loss: 3.0659\nEpoch [66/100], Step [640/760], Total Loss: 3.0676\nEpoch [66/100], Step [650/760], Total Loss: 3.1061\nEpoch [66/100], Step [660/760], Total Loss: 3.0439\nEpoch [66/100], Step [670/760], Total Loss: 3.0615\nEpoch [66/100], Step [680/760], Total Loss: 3.0799\nEpoch [66/100], Step [690/760], Total Loss: 3.0971\nEpoch [66/100], Step [700/760], Total Loss: 3.0722\nEpoch [66/100], Step [710/760], Total Loss: 3.0583\nEpoch [66/100], Step [720/760], Total Loss: 3.0728\nEpoch [66/100], Step [730/760], Total Loss: 3.0672\nEpoch [66/100], Step [740/760], Total Loss: 3.0770\nEpoch [66/100], Step [750/760], Total Loss: 3.0985\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 66/100 [2:34:01<1:19:18, 139.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [66/100], Step [760/760], Total Loss: 3.1662\nEpoch [67/100], Step [10/760], Total Loss: 3.0788\nEpoch [67/100], Step [20/760], Total Loss: 3.1376\nEpoch [67/100], Step [30/760], Total Loss: 3.0906\nEpoch [67/100], Step [40/760], Total Loss: 3.0759\nEpoch [67/100], Step [50/760], Total Loss: 3.0299\nEpoch [67/100], Step [60/760], Total Loss: 3.0796\nEpoch [67/100], Step [70/760], Total Loss: 3.0966\nEpoch [67/100], Step [80/760], Total Loss: 3.0869\nEpoch [67/100], Step [90/760], Total Loss: 3.1422\nEpoch [67/100], Step [100/760], Total Loss: 3.0462\nEpoch [67/100], Step [110/760], Total Loss: 3.0492\nEpoch [67/100], Step [120/760], Total Loss: 3.1154\nEpoch [67/100], Step [130/760], Total Loss: 3.1316\nEpoch [67/100], Step [140/760], Total Loss: 3.0823\nEpoch [67/100], Step [150/760], Total Loss: 3.0126\nEpoch [67/100], Step [160/760], Total Loss: 3.1050\nEpoch [67/100], Step [170/760], Total Loss: 3.0847\nEpoch [67/100], Step [180/760], Total Loss: 3.0837\nEpoch [67/100], Step [190/760], Total Loss: 3.0056\nEpoch [67/100], Step [200/760], Total Loss: 3.0725\nEpoch [67/100], Step [210/760], Total Loss: 3.0768\nEpoch [67/100], Step [220/760], Total Loss: 3.1185\nEpoch [67/100], Step [230/760], Total Loss: 3.1926\nEpoch [67/100], Step [240/760], Total Loss: 3.0528\nEpoch [67/100], Step [250/760], Total Loss: 3.0408\nEpoch [67/100], Step [260/760], Total Loss: 3.0971\nEpoch [67/100], Step [270/760], Total Loss: 3.0382\nEpoch [67/100], Step [280/760], Total Loss: 3.0628\nEpoch [67/100], Step [290/760], Total Loss: 3.0582\nEpoch [67/100], Step [300/760], Total Loss: 3.1397\nEpoch [67/100], Step [310/760], Total Loss: 3.1041\nEpoch [67/100], Step [320/760], Total Loss: 3.0785\nEpoch [67/100], Step [330/760], Total Loss: 3.0860\nEpoch [67/100], Step [340/760], Total Loss: 3.0863\nEpoch [67/100], Step [350/760], Total Loss: 3.1330\nEpoch [67/100], Step [360/760], Total Loss: 3.0825\nEpoch [67/100], Step [370/760], Total Loss: 3.0606\nEpoch [67/100], Step [380/760], Total Loss: 3.0244\nEpoch [67/100], Step [390/760], Total Loss: 3.0446\nEpoch [67/100], Step [400/760], Total Loss: 3.0205\nEpoch [67/100], Step [410/760], Total Loss: 3.0621\nEpoch [67/100], Step [420/760], Total Loss: 3.1378\nEpoch [67/100], Step [430/760], Total Loss: 3.1121\nEpoch [67/100], Step [440/760], Total Loss: 3.0455\nEpoch [67/100], Step [450/760], Total Loss: 3.0707\nEpoch [67/100], Step [460/760], Total Loss: 3.0830\nEpoch [67/100], Step [470/760], Total Loss: 3.0892\nEpoch [67/100], Step [480/760], Total Loss: 3.0453\nEpoch [67/100], Step [490/760], Total Loss: 3.0455\nEpoch [67/100], Step [500/760], Total Loss: 3.1337\nEpoch [67/100], Step [510/760], Total Loss: 3.0412\nEpoch [67/100], Step [520/760], Total Loss: 3.0920\nEpoch [67/100], Step [530/760], Total Loss: 3.1025\nEpoch [67/100], Step [540/760], Total Loss: 3.0886\nEpoch [67/100], Step [550/760], Total Loss: 3.0650\nEpoch [67/100], Step [560/760], Total Loss: 3.0717\nEpoch [67/100], Step [570/760], Total Loss: 3.0787\nEpoch [67/100], Step [580/760], Total Loss: 3.0569\nEpoch [67/100], Step [590/760], Total Loss: 3.0998\nEpoch [67/100], Step [600/760], Total Loss: 3.0144\nEpoch [67/100], Step [610/760], Total Loss: 3.0688\nEpoch [67/100], Step [620/760], Total Loss: 3.1225\nEpoch [67/100], Step [630/760], Total Loss: 3.0567\nEpoch [67/100], Step [640/760], Total Loss: 3.1372\nEpoch [67/100], Step [650/760], Total Loss: 3.0333\nEpoch [67/100], Step [660/760], Total Loss: 3.0623\nEpoch [67/100], Step [670/760], Total Loss: 3.1330\nEpoch [67/100], Step [680/760], Total Loss: 3.0920\nEpoch [67/100], Step [690/760], Total Loss: 3.0750\nEpoch [67/100], Step [700/760], Total Loss: 3.0822\nEpoch [67/100], Step [710/760], Total Loss: 3.1043\nEpoch [67/100], Step [720/760], Total Loss: 3.1343\nEpoch [67/100], Step [730/760], Total Loss: 3.0855\nEpoch [67/100], Step [740/760], Total Loss: 3.0945\nEpoch [67/100], Step [750/760], Total Loss: 3.0749\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 67/100 [2:36:21<1:16:58, 139.95s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [67/100], Step [760/760], Total Loss: 3.1071\nEpoch [68/100], Step [10/760], Total Loss: 3.0496\nEpoch [68/100], Step [20/760], Total Loss: 3.0242\nEpoch [68/100], Step [30/760], Total Loss: 3.0558\nEpoch [68/100], Step [40/760], Total Loss: 3.0760\nEpoch [68/100], Step [50/760], Total Loss: 3.0762\nEpoch [68/100], Step [60/760], Total Loss: 3.1048\nEpoch [68/100], Step [70/760], Total Loss: 3.0321\nEpoch [68/100], Step [80/760], Total Loss: 3.0559\nEpoch [68/100], Step [90/760], Total Loss: 3.0893\nEpoch [68/100], Step [100/760], Total Loss: 3.1257\nEpoch [68/100], Step [110/760], Total Loss: 3.0538\nEpoch [68/100], Step [120/760], Total Loss: 3.0936\nEpoch [68/100], Step [130/760], Total Loss: 3.0933\nEpoch [68/100], Step [140/760], Total Loss: 3.0207\nEpoch [68/100], Step [150/760], Total Loss: 3.0884\nEpoch [68/100], Step [160/760], Total Loss: 3.0782\nEpoch [68/100], Step [170/760], Total Loss: 3.0832\nEpoch [68/100], Step [180/760], Total Loss: 3.0968\nEpoch [68/100], Step [190/760], Total Loss: 3.0771\n","output_type":"stream"}]},{"cell_type":"code","source":"model(Xtr[:100])","metadata":{"execution":{"iopub.status.busy":"2024-04-03T08:53:38.061347Z","iopub.execute_input":"2024-04-03T08:53:38.062156Z","iopub.status.idle":"2024-04-03T08:53:38.168719Z","shell.execute_reply.started":"2024-04-03T08:53:38.062116Z","shell.execute_reply":"2024-04-03T08:53:38.167809Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(tensor([[8.3641e-04, 1.3017e-09, 9.9916e-01],\n         [7.9041e-08, 5.2794e-04, 9.9947e-01],\n         [1.0000e+00, 1.1581e-09, 1.7903e-11],\n         [4.9460e-10, 9.5416e-25, 1.0000e+00],\n         [2.8009e-15, 0.0000e+00, 1.0000e+00],\n         [9.8073e-01, 0.0000e+00, 1.9271e-02],\n         [4.2647e-22, 0.0000e+00, 1.0000e+00],\n         [1.7237e-05, 9.9989e-01, 8.8235e-05],\n         [2.1224e-08, 1.0000e+00, 1.7411e-19],\n         [1.0000e+00, 0.0000e+00, 1.0993e-08],\n         [9.9997e-01, 0.0000e+00, 3.0800e-05],\n         [4.1415e-01, 5.8585e-01, 1.4535e-17],\n         [1.4560e-13, 9.9967e-01, 3.2696e-04],\n         [9.9990e-01, 1.0382e-04, 8.5768e-12],\n         [2.6331e-07, 1.0000e+00, 1.6438e-17],\n         [9.9954e-01, 2.0068e-06, 4.6026e-04],\n         [1.0000e+00, 5.2905e-19, 8.8479e-17],\n         [1.0686e-05, 1.4292e-02, 9.8570e-01],\n         [1.0000e+00, 4.3145e-12, 1.7805e-17],\n         [1.0000e+00, 4.2292e-06, 3.8462e-18],\n         [2.8464e-02, 9.7154e-01, 2.6349e-21],\n         [1.6922e-02, 4.0031e-11, 9.8308e-01],\n         [8.5348e-01, 1.4652e-01, 6.7923e-06],\n         [1.0000e+00, 1.4709e-12, 4.8304e-21],\n         [1.0000e+00, 5.0951e-09, 2.1311e-12],\n         [6.9414e-03, 9.9306e-01, 6.3153e-11],\n         [9.9960e-01, 4.1414e-17, 4.0176e-04],\n         [4.3832e-12, 1.0000e+00, 1.8859e-31],\n         [1.0000e+00, 7.7291e-07, 2.6037e-20],\n         [9.9727e-01, 2.7255e-03, 7.5187e-09],\n         [1.0000e+00, 4.6585e-11, 1.0468e-18],\n         [1.6663e-08, 1.0000e+00, 1.1634e-09],\n         [7.1036e-13, 2.0363e-16, 1.0000e+00],\n         [9.9966e-01, 1.0679e-06, 3.3814e-04],\n         [9.8898e-01, 2.1775e-04, 1.0797e-02],\n         [3.6139e-07, 3.8717e-09, 1.0000e+00],\n         [9.9835e-01, 1.6447e-03, 2.0322e-06],\n         [2.6964e-01, 2.2615e-05, 7.3034e-01],\n         [1.5483e-07, 9.9999e-01, 4.9280e-06],\n         [1.2173e-05, 9.9717e-01, 2.8204e-03],\n         [7.5003e-11, 1.0000e+00, 3.0276e-25],\n         [1.7752e-02, 9.8225e-01, 1.4712e-22],\n         [1.3543e-07, 1.0000e+00, 4.6368e-18],\n         [9.8701e-01, 2.4343e-03, 1.0559e-02],\n         [1.9538e-01, 3.6785e-03, 8.0094e-01],\n         [7.8435e-01, 2.1565e-01, 4.4207e-12],\n         [2.3765e-07, 1.0000e+00, 4.9228e-15],\n         [7.5104e-07, 9.9972e-01, 2.8029e-04],\n         [4.8017e-05, 9.9995e-01, 1.6248e-08],\n         [9.9999e-01, 3.6017e-06, 7.8641e-06],\n         [8.6030e-01, 3.7569e-04, 1.3932e-01],\n         [6.6629e-10, 4.2772e-04, 9.9957e-01],\n         [3.5812e-04, 9.9961e-01, 3.3566e-05],\n         [6.0892e-04, 9.3492e-01, 6.4473e-02],\n         [1.5246e-04, 3.3504e-05, 9.9981e-01],\n         [1.0506e-06, 1.8086e-12, 1.0000e+00],\n         [7.0618e-01, 2.8874e-01, 5.0786e-03],\n         [3.0135e-01, 1.5635e-07, 6.9865e-01],\n         [9.9760e-01, 2.1340e-03, 2.6448e-04],\n         [1.4189e-01, 8.5811e-01, 2.6727e-10],\n         [9.9651e-01, 2.6692e-03, 8.2348e-04],\n         [1.3482e-01, 7.9229e-04, 8.6439e-01],\n         [9.9886e-01, 8.9444e-04, 2.4701e-04],\n         [7.2047e-08, 1.1656e-04, 9.9988e-01],\n         [9.9538e-01, 1.9073e-08, 4.6175e-03],\n         [1.0000e+00, 5.4594e-23, 9.0187e-07],\n         [9.9934e-01, 6.6067e-04, 1.1337e-11],\n         [5.2850e-08, 5.0847e-07, 1.0000e+00],\n         [1.0000e+00, 4.8835e-09, 1.9443e-13],\n         [1.0000e+00, 4.3090e-40, 1.5981e-22],\n         [1.0000e+00, 1.1570e-18, 4.3854e-09],\n         [9.1668e-01, 7.5306e-02, 8.0102e-03],\n         [1.6528e-01, 8.3472e-01, 2.5984e-08],\n         [9.9939e-01, 6.0954e-04, 6.3271e-13],\n         [9.5924e-01, 3.8051e-15, 4.0761e-02],\n         [9.9371e-01, 6.2409e-03, 4.9628e-05],\n         [9.6389e-01, 9.0696e-08, 3.6106e-02],\n         [1.0000e+00, 4.5008e-09, 1.7423e-09],\n         [9.9999e-01, 1.4182e-05, 1.2510e-09],\n         [2.3734e-05, 1.6428e-05, 9.9996e-01],\n         [1.0000e+00, 9.0798e-18, 9.5485e-20],\n         [3.2564e-02, 9.6744e-01, 6.7223e-09],\n         [1.7462e-01, 8.2399e-01, 1.3878e-03],\n         [7.6271e-06, 7.9290e-14, 9.9999e-01],\n         [1.0000e+00, 7.8740e-28, 1.6327e-16],\n         [2.7026e-07, 1.1038e-10, 1.0000e+00],\n         [4.1450e-02, 2.9108e-01, 6.6747e-01],\n         [1.0000e+00, 4.7732e-15, 3.4930e-10],\n         [2.7520e-01, 2.3613e-03, 7.2244e-01],\n         [4.0901e-04, 3.8549e-16, 9.9959e-01],\n         [1.9894e-14, 6.5823e-20, 1.0000e+00],\n         [4.4178e-04, 9.9956e-01, 2.6554e-16],\n         [2.8517e-05, 9.9997e-01, 4.6427e-08],\n         [9.9978e-01, 5.6171e-06, 2.1790e-04],\n         [2.9108e-10, 1.0000e+00, 3.1139e-13],\n         [4.2485e-10, 1.4469e-08, 1.0000e+00],\n         [1.0000e+00, 3.0402e-15, 9.7939e-23],\n         [1.0000e+00, 7.6593e-13, 2.4100e-11],\n         [5.1278e-01, 3.1440e-33, 4.8722e-01],\n         [9.9999e-01, 1.9157e-12, 1.1118e-05]], device='cuda:0',\n        grad_fn=<SoftmaxBackward0>),\n tensor([[7.0605e-07, 1.0000e+00, 1.8118e-20, 1.4976e-10, 5.8735e-15, 1.7798e-23],\n         [3.8399e-02, 1.7399e-16, 9.6160e-01, 1.9081e-19, 4.5334e-12, 1.1637e-29],\n         [9.0260e-02, 4.6798e-20, 5.3518e-08, 6.9484e-11, 9.0974e-01, 7.2516e-28],\n         [6.9653e-26, 0.0000e+00, 1.0000e+00, 4.1290e-06, 4.6243e-43, 4.4423e-39],\n         [1.9621e-28, 4.1946e-29, 3.2934e-03, 1.0757e-02, 9.8595e-01, 2.8610e-24],\n         [1.0000e+00, 0.0000e+00, 3.2277e-06, 7.6892e-34, 8.3054e-17, 1.7236e-43],\n         [1.0000e+00, 6.8718e-41, 1.0904e-17, 6.2908e-41, 6.0620e-16, 1.2258e-24],\n         [8.4316e-42, 1.0000e+00, 0.0000e+00, 1.2612e-44, 1.0530e-18, 9.7918e-18],\n         [8.7318e-15, 6.7262e-42, 6.8290e-37, 1.0513e-01, 8.9487e-01, 7.4455e-29],\n         [1.0419e-15, 4.0744e-33, 2.5428e-07, 3.3573e-16, 1.8836e-03, 9.9812e-01],\n         [0.0000e+00, 0.0000e+00, 1.0701e-22, 7.0571e-20, 1.0000e+00, 0.0000e+00],\n         [5.7952e-12, 4.2486e-29, 4.3389e-32, 9.9986e-01, 1.4147e-04, 4.6126e-11],\n         [8.8116e-18, 9.7914e-18, 1.1628e-14, 9.9999e-01, 1.5222e-18, 6.5494e-06],\n         [2.5945e-02, 4.1676e-17, 9.5642e-01, 2.0116e-08, 1.7631e-02, 7.6139e-08],\n         [1.0000e+00, 2.8030e-23, 2.4325e-20, 5.3707e-10, 3.1259e-15, 4.6552e-23],\n         [1.0858e-05, 8.6604e-30, 7.2938e-37, 1.3036e-40, 9.9999e-01, 5.3947e-31],\n         [6.1872e-11, 7.5250e-43, 1.0073e-11, 1.7421e-17, 1.0000e+00, 1.0026e-32],\n         [3.5527e-11, 3.4198e-13, 5.6762e-07, 9.9979e-01, 2.0271e-04, 6.2486e-06],\n         [2.0014e-02, 3.6477e-17, 1.6174e-26, 3.2570e-16, 5.5432e-18, 9.7999e-01],\n         [6.2570e-10, 4.6341e-11, 3.8539e-31, 2.2945e-32, 1.0000e+00, 2.9125e-08],\n         [9.1852e-34, 2.2693e-22, 2.4409e-41, 1.1966e-30, 1.1126e-02, 9.8887e-01],\n         [2.6918e-13, 9.4859e-23, 3.6990e-23, 1.0000e+00, 7.3230e-09, 2.9463e-11],\n         [1.0000e+00, 1.1022e-39, 5.2261e-19, 6.1942e-16, 1.6604e-19, 3.0098e-16],\n         [4.8528e-28, 4.1013e-25, 2.3083e-03, 9.9769e-01, 8.3641e-11, 1.5265e-32],\n         [1.2196e-16, 9.2740e-37, 1.0000e+00, 2.5021e-13, 8.6255e-23, 8.6690e-29],\n         [4.4582e-11, 7.1456e-14, 9.9985e-01, 1.4720e-04, 1.4321e-11, 1.6443e-15],\n         [1.6633e-04, 0.0000e+00, 4.2413e-33, 0.0000e+00, 9.9983e-01, 0.0000e+00],\n         [1.3603e-09, 1.6533e-36, 1.0000e+00, 4.2993e-26, 2.7755e-30, 2.1608e-08],\n         [1.0000e+00, 5.7289e-22, 2.8740e-09, 1.0867e-09, 1.5828e-16, 6.7825e-15],\n         [2.2859e-10, 3.4005e-31, 2.7387e-13, 1.5265e-12, 1.0000e+00, 1.4382e-26],\n         [8.3632e-22, 9.7687e-36, 9.3612e-24, 2.4691e-16, 1.0000e+00, 6.5087e-34],\n         [5.5066e-08, 7.5737e-04, 4.3498e-03, 9.9489e-01, 4.0125e-12, 3.8846e-07],\n         [8.0596e-19, 1.0000e+00, 1.3949e-13, 2.4001e-13, 1.5039e-09, 3.9912e-11],\n         [9.9649e-08, 9.7818e-01, 1.7578e-10, 1.6669e-09, 2.1647e-02, 1.7334e-04],\n         [8.1207e-11, 3.3726e-08, 2.2401e-18, 6.2070e-14, 1.0000e+00, 1.6069e-16],\n         [2.5792e-14, 4.5120e-14, 1.7628e-18, 1.0000e+00, 3.4232e-16, 2.5860e-21],\n         [9.7537e-09, 9.9962e-01, 2.0242e-12, 4.4251e-11, 3.7769e-04, 3.2407e-06],\n         [2.7547e-02, 7.7198e-11, 9.5097e-21, 5.1037e-23, 2.0317e-11, 9.7245e-01],\n         [1.1571e-08, 1.0000e+00, 4.7722e-07, 3.9952e-11, 2.1887e-08, 1.3564e-10],\n         [4.2133e-01, 3.8031e-01, 5.8094e-07, 1.5586e-15, 4.7917e-11, 1.9837e-01],\n         [9.9958e-01, 4.1984e-04, 9.4587e-12, 8.4200e-10, 6.7063e-20, 8.9876e-14],\n         [4.5656e-34, 1.0000e+00, 8.6759e-41, 2.1967e-26, 7.1806e-34, 1.5299e-29],\n         [2.2396e-28, 1.0000e+00, 4.9892e-17, 8.7443e-11, 4.2610e-23, 4.0465e-17],\n         [1.0855e-14, 1.0000e+00, 3.8057e-22, 9.2653e-11, 1.5823e-14, 1.9597e-12],\n         [4.5492e-02, 8.8446e-09, 4.1980e-10, 9.4516e-04, 1.1413e-09, 9.5356e-01],\n         [5.0528e-17, 3.2215e-08, 3.5439e-21, 1.0000e+00, 3.6914e-23, 1.0454e-13],\n         [3.9580e-19, 1.2658e-17, 4.2223e-23, 1.0000e+00, 2.6998e-17, 3.5703e-13],\n         [9.5394e-01, 5.1000e-03, 1.2738e-04, 5.2053e-04, 4.3411e-07, 4.0311e-02],\n         [4.2916e-12, 7.1694e-14, 6.0507e-09, 1.0000e+00, 6.1061e-13, 1.7032e-12],\n         [2.8697e-09, 1.0044e-03, 4.1945e-06, 9.9899e-01, 2.4491e-08, 1.9783e-07],\n         [1.8501e-17, 8.9168e-07, 2.8165e-17, 1.0000e+00, 2.1741e-08, 1.3391e-08],\n         [1.9799e-05, 9.9998e-01, 1.3976e-08, 3.8653e-13, 1.8214e-17, 2.7587e-08],\n         [1.0262e-08, 6.9497e-11, 2.2987e-23, 1.0000e+00, 2.0493e-16, 4.9436e-12],\n         [1.5687e-07, 9.9992e-01, 7.0049e-11, 7.6832e-05, 1.9478e-13, 1.9163e-16],\n         [5.1272e-16, 2.1643e-09, 8.2385e-13, 1.0000e+00, 6.2754e-10, 2.8281e-11],\n         [4.5732e-10, 1.0000e+00, 2.5472e-06, 2.4362e-11, 1.6091e-14, 5.4597e-17],\n         [5.2726e-10, 9.0609e-07, 1.1076e-08, 4.0185e-04, 1.3040e-08, 9.9960e-01],\n         [2.1076e-07, 1.6129e-09, 5.9826e-07, 9.9999e-01, 3.6190e-11, 1.2255e-05],\n         [1.7273e-12, 8.4620e-08, 3.4580e-07, 3.0593e-01, 1.5532e-03, 6.9251e-01],\n         [4.9234e-16, 1.0877e-07, 1.3721e-01, 5.3214e-06, 8.0896e-12, 8.6278e-01],\n         [1.0000e+00, 1.2727e-10, 1.1103e-17, 2.2339e-21, 9.9271e-17, 4.8241e-08],\n         [1.0000e+00, 7.8646e-08, 1.4476e-14, 6.2681e-11, 5.3614e-16, 2.7095e-11],\n         [7.5940e-06, 1.7122e-16, 2.9515e-11, 3.2805e-05, 9.9996e-01, 2.9558e-10],\n         [9.9433e-18, 4.0494e-02, 4.1557e-30, 9.5950e-01, 1.1265e-06, 3.0759e-15],\n         [9.4385e-01, 5.0884e-02, 3.7033e-03, 2.2813e-14, 6.2580e-04, 9.3570e-04],\n         [3.3779e-25, 2.7369e-14, 5.3281e-10, 1.2250e-21, 1.0000e+00, 7.8364e-19],\n         [5.6864e-13, 8.1969e-13, 6.7546e-10, 6.1643e-12, 4.7733e-13, 1.0000e+00],\n         [1.8181e-18, 4.1090e-23, 5.9388e-23, 9.9483e-01, 5.1656e-03, 1.0701e-14],\n         [1.0000e+00, 7.7084e-20, 5.2669e-10, 2.5384e-27, 3.0215e-18, 4.0576e-14],\n         [1.0000e+00, 1.9741e-15, 4.5208e-13, 1.2515e-25, 5.6848e-22, 2.7633e-32],\n         [3.5294e-03, 9.9646e-01, 1.2347e-05, 7.3685e-21, 5.6674e-10, 1.3551e-12],\n         [7.2727e-05, 1.8179e-02, 1.2519e-10, 4.0509e-11, 1.1662e-13, 9.8175e-01],\n         [1.2846e-10, 9.9987e-01, 3.5029e-11, 3.9002e-06, 2.1978e-13, 1.2225e-04],\n         [2.2886e-40, 1.0000e+00, 9.4894e-40, 2.1019e-43, 2.6111e-24, 2.3494e-23],\n         [1.8954e-11, 1.0000e+00, 1.1343e-18, 2.3807e-06, 1.1240e-06, 2.2043e-12],\n         [1.3450e-08, 4.2213e-02, 1.8491e-09, 9.5779e-01, 1.2238e-15, 1.1769e-07],\n         [3.0907e-11, 3.0558e-18, 9.3511e-13, 1.0000e+00, 1.8905e-11, 4.8356e-14],\n         [5.4443e-17, 1.0000e+00, 1.4285e-32, 4.1568e-19, 3.1321e-40, 9.4853e-27],\n         [3.5453e-43, 1.0000e+00, 0.0000e+00, 1.6518e-40, 0.0000e+00, 0.0000e+00],\n         [1.2170e-11, 6.4540e-03, 9.7360e-01, 5.1754e-03, 5.8295e-13, 1.4766e-02],\n         [0.0000e+00, 1.0000e+00, 1.2822e-42, 1.5706e-37, 2.9475e-40, 2.6106e-26],\n         [1.5595e-35, 1.0000e+00, 2.2377e-24, 2.2859e-14, 1.8194e-11, 2.9884e-18],\n         [5.6884e-17, 3.1291e-04, 1.3202e-25, 5.8738e-01, 3.6626e-09, 4.1231e-01],\n         [9.9984e-01, 1.6543e-06, 1.5671e-04, 1.0978e-06, 6.0338e-14, 3.5451e-10],\n         [9.9824e-01, 3.0298e-25, 4.0785e-09, 4.4657e-28, 1.7556e-03, 1.8139e-15],\n         [9.4216e-01, 5.7456e-02, 2.5839e-19, 6.9879e-19, 1.6596e-14, 3.8820e-04],\n         [8.1922e-09, 1.0000e+00, 5.1605e-26, 7.2819e-15, 6.6479e-13, 4.1757e-15],\n         [3.7506e-23, 3.6716e-20, 1.0000e+00, 2.4454e-11, 1.3696e-10, 5.4831e-39],\n         [6.3109e-05, 9.8992e-01, 3.3103e-11, 3.5814e-03, 5.5089e-08, 6.4364e-03],\n         [1.0000e+00, 9.7802e-16, 2.2810e-19, 8.4363e-25, 7.5054e-22, 3.0753e-21],\n         [7.2344e-19, 1.0000e+00, 5.2776e-27, 1.2931e-19, 3.3500e-15, 6.3119e-12],\n         [1.4996e-21, 3.4606e-07, 4.2528e-23, 1.3025e-31, 1.0138e-26, 1.0000e+00],\n         [1.1513e-18, 7.8487e-09, 2.2447e-13, 3.7278e-03, 3.9551e-12, 9.9627e-01],\n         [7.4614e-31, 2.7133e-03, 9.0789e-25, 2.7429e-06, 1.7338e-04, 9.9711e-01],\n         [6.8478e-14, 1.7458e-02, 1.1392e-16, 9.8254e-01, 8.6899e-08, 1.7329e-11],\n         [8.0221e-07, 4.7913e-07, 8.8277e-19, 1.0000e+00, 1.7220e-12, 1.2407e-11],\n         [1.0996e-28, 3.6624e-14, 3.4274e-17, 1.0000e+00, 1.1223e-14, 3.1456e-13],\n         [7.5804e-05, 3.9876e-23, 2.9788e-17, 4.8772e-09, 1.9138e-12, 9.9992e-01],\n         [1.0000e+00, 2.3523e-28, 1.0702e-38, 2.2070e-34, 1.4730e-17, 0.0000e+00],\n         [1.0000e+00, 4.5232e-22, 2.6162e-33, 4.1943e-28, 2.6996e-35, 5.2393e-29]],\n        device='cuda:0', grad_fn=<SoftmaxBackward0>),\n tensor([[5.3286e-06, 6.2504e-19, 9.7740e-07, 9.9999e-01, 1.2351e-09, 3.6457e-24,\n          3.6170e-34, 8.4173e-24, 1.0742e-36],\n         [9.9944e-01, 2.0537e-41, 2.0600e-25, 2.1407e-15, 2.4007e-17, 6.4320e-25,\n          8.5835e-30, 5.6474e-04, 1.6506e-16],\n         [1.0000e+00, 1.8291e-22, 2.2307e-32, 3.6480e-28, 4.5866e-12, 9.9043e-34,\n          0.0000e+00, 2.9541e-33, 6.9490e-33],\n         [2.0172e-24, 5.8595e-26, 2.1706e-02, 4.7879e-01, 3.0435e-04, 6.9243e-02,\n          2.9636e-38, 3.2650e-42, 4.2996e-01],\n         [8.1826e-12, 1.0000e+00, 0.0000e+00, 6.5596e-17, 1.9986e-10, 1.8619e-18,\n          0.0000e+00, 9.5316e-42, 0.0000e+00],\n         [1.0000e+00, 1.3452e-10, 0.0000e+00, 4.9061e-10, 3.2978e-23, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [2.6391e-07, 5.6052e-45, 2.5179e-12, 9.9684e-01, 1.6503e-23, 3.1578e-03,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [2.7125e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.6765e-43],\n         [3.2121e-14, 1.4047e-15, 9.9244e-01, 2.3687e-12, 1.5358e-30, 7.5572e-03,\n          6.8080e-20, 1.6011e-37, 1.8217e-44],\n         [1.0000e+00, 1.7339e-19, 0.0000e+00, 3.9435e-13, 3.2721e-20, 2.7928e-29,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [1.0000e+00, 3.4800e-11, 3.4874e-18, 1.0157e-24, 4.8749e-14, 6.1244e-12,\n          5.7522e-21, 2.3490e-27, 0.0000e+00],\n         [3.3421e-01, 2.9015e-15, 6.6578e-01, 2.0740e-11, 1.1036e-12, 4.6391e-28,\n          7.4436e-06, 5.5466e-26, 7.5069e-26],\n         [5.1203e-42, 1.2034e-09, 5.6177e-19, 2.7664e-12, 7.4486e-13, 2.0309e-07,\n          2.3967e-15, 3.6928e-20, 1.0000e+00],\n         [1.3009e-15, 1.5078e-32, 3.2839e-12, 3.3474e-06, 8.7126e-27, 7.7573e-41,\n          4.2551e-19, 1.0000e+00, 2.1501e-37],\n         [9.9996e-01, 2.2218e-14, 4.4728e-05, 7.1886e-20, 2.4522e-24, 2.0148e-31,\n          3.8829e-21, 2.0535e-23, 2.0866e-18],\n         [9.9175e-01, 0.0000e+00, 4.3889e-08, 2.6767e-14, 7.2567e-25, 8.2480e-03,\n          8.9386e-20, 3.9462e-23, 4.9998e-16],\n         [2.9739e-03, 9.9702e-01, 1.5024e-06, 1.6026e-19, 1.8684e-28, 2.1865e-16,\n          5.5354e-23, 8.9214e-24, 2.4497e-35],\n         [3.6993e-28, 1.7457e-19, 4.4816e-20, 1.0000e+00, 1.9898e-19, 1.7585e-24,\n          5.5017e-09, 1.1820e-07, 6.3273e-11],\n         [3.5458e-23, 1.4258e-39, 1.8487e-01, 4.9310e-28, 2.1997e-21, 8.1513e-01,\n          4.2446e-24, 7.7761e-32, 5.3370e-28],\n         [1.4748e-05, 0.0000e+00, 9.9999e-01, 7.6011e-18, 1.3373e-39, 1.0387e-07,\n          9.4092e-30, 5.4019e-20, 2.7573e-20],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [7.1411e-09, 4.9057e-03, 1.1388e-11, 3.2083e-11, 3.3484e-12, 9.9509e-01,\n          3.9984e-23, 1.1418e-28, 9.3075e-19],\n         [3.4049e-23, 3.9376e-29, 1.0000e+00, 9.1476e-07, 1.4735e-28, 1.4382e-26,\n          0.0000e+00, 4.1198e-43, 1.1771e-43],\n         [4.3267e-29, 2.1373e-03, 6.7495e-22, 9.9786e-01, 6.0800e-28, 2.1889e-24,\n          6.6267e-33, 5.2323e-13, 0.0000e+00],\n         [1.9795e-10, 1.5748e-11, 3.2999e-02, 9.6690e-01, 2.0747e-14, 5.7636e-18,\n          9.9589e-18, 1.0475e-04, 1.3962e-18],\n         [1.0750e-17, 9.9999e-01, 5.3217e-11, 7.3281e-06, 1.5855e-16, 1.5605e-23,\n          4.0493e-11, 9.0866e-18, 2.1264e-27],\n         [1.2622e-28, 0.0000e+00, 1.6826e-15, 5.7011e-30, 0.0000e+00, 1.0000e+00,\n          6.8975e-23, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 4.5791e-26, 1.0000e+00, 5.0068e-32, 0.0000e+00, 0.0000e+00,\n          2.0696e-39, 2.8442e-41, 0.0000e+00],\n         [9.4468e-17, 9.1553e-09, 1.0000e+00, 5.6208e-10, 2.1574e-19, 3.9704e-23,\n          5.9679e-17, 1.5598e-17, 4.2333e-18],\n         [3.9235e-24, 1.5962e-10, 2.7405e-15, 2.8055e-31, 9.3783e-28, 2.4131e-09,\n          1.0000e+00, 2.6680e-31, 1.5412e-25],\n         [8.1916e-35, 1.0000e+00, 1.4019e-26, 7.7814e-31, 3.2790e-43, 8.4078e-45,\n          7.8473e-44, 4.0162e-37, 5.6052e-45],\n         [1.7112e-18, 1.1930e-20, 5.7236e-04, 1.0877e-03, 5.1179e-10, 3.1943e-09,\n          2.5209e-17, 1.7842e-04, 9.9816e-01],\n         [1.8485e-23, 1.9056e-17, 3.0152e-17, 7.4267e-05, 9.9993e-01, 2.7307e-14,\n          9.6238e-26, 7.1523e-20, 8.4739e-19],\n         [1.2356e-19, 2.9747e-17, 9.9993e-01, 2.9890e-05, 2.9220e-06, 8.9696e-19,\n          5.4028e-08, 3.3193e-05, 5.6710e-08],\n         [6.7419e-22, 1.8186e-19, 1.9426e-14, 1.6525e-13, 1.0000e+00, 2.7590e-21,\n          2.5679e-08, 5.6938e-08, 5.4984e-07],\n         [6.0183e-10, 4.9690e-12, 9.7354e-07, 2.4957e-09, 9.9991e-01, 2.2594e-21,\n          9.3684e-05, 1.4213e-15, 1.4745e-13],\n         [7.7322e-19, 1.0937e-15, 5.7239e-13, 1.5018e-11, 3.6700e-06, 9.4008e-01,\n          2.7044e-10, 3.8181e-14, 5.9915e-02],\n         [2.2092e-07, 8.9803e-09, 3.1756e-07, 5.5605e-10, 1.0000e+00, 4.3398e-08,\n          8.1900e-08, 9.5099e-14, 2.1975e-07],\n         [1.9963e-02, 8.4520e-01, 3.9501e-15, 4.4160e-09, 1.2182e-01, 4.8304e-04,\n          2.6957e-08, 1.2537e-02, 1.9406e-07],\n         [1.7741e-02, 1.7495e-02, 3.3083e-08, 5.4808e-01, 2.8135e-06, 9.3724e-03,\n          2.4667e-04, 4.0516e-01, 1.9073e-03],\n         [3.9940e-20, 6.6370e-27, 1.9425e-08, 3.0429e-09, 9.4513e-07, 1.2677e-14,\n          1.1664e-07, 1.0000e+00, 2.5021e-09],\n         [8.1818e-20, 1.0706e-42, 4.1717e-04, 4.2542e-14, 2.4807e-38, 1.7852e-40,\n          9.9958e-01, 1.1533e-32, 1.1789e-14],\n         [2.5570e-19, 1.1671e-40, 3.2209e-14, 7.4520e-09, 0.0000e+00, 8.6190e-33,\n          3.6190e-01, 1.6010e-08, 6.3810e-01],\n         [2.9099e-13, 5.9236e-14, 7.6192e-15, 2.6080e-18, 1.0598e-20, 5.0311e-32,\n          1.0000e+00, 1.6189e-09, 4.3719e-07],\n         [1.3850e-04, 2.1671e-14, 4.1403e-09, 5.2361e-04, 4.4216e-06, 9.5359e-01,\n          2.2386e-12, 4.5729e-02, 1.1922e-05],\n         [1.3451e-07, 2.9768e-13, 3.2454e-03, 2.2737e-03, 8.8779e-13, 1.8805e-20,\n          7.0926e-01, 2.8522e-01, 1.2267e-06],\n         [1.4961e-19, 8.5790e-14, 8.2887e-05, 9.2540e-01, 3.1226e-07, 5.8797e-02,\n          1.5458e-05, 1.5625e-02, 8.1904e-05],\n         [5.3290e-11, 4.6134e-10, 7.1887e-09, 1.9255e-05, 2.4350e-04, 3.0676e-15,\n          1.1403e-07, 9.9974e-01, 4.6000e-08],\n         [4.1606e-08, 5.2175e-10, 3.7471e-09, 9.9977e-01, 1.7359e-04, 4.3146e-09,\n          2.9634e-10, 5.0358e-05, 1.0252e-05],\n         [2.6847e-01, 2.1878e-08, 6.9852e-01, 2.9224e-03, 1.4599e-05, 3.0076e-02,\n          1.0156e-14, 3.4377e-09, 2.5695e-07],\n         [3.6320e-15, 4.0224e-15, 5.1290e-16, 3.9695e-11, 5.9937e-15, 8.9482e-24,\n          1.0000e+00, 3.7483e-10, 2.1060e-10],\n         [7.4931e-08, 1.0000e+00, 4.1074e-22, 9.9573e-21, 1.6904e-14, 4.1107e-26,\n          2.6089e-24, 4.6511e-10, 4.5043e-20],\n         [1.5093e-18, 8.3653e-10, 1.8589e-09, 9.5713e-01, 3.6940e-05, 3.1861e-02,\n          2.2780e-11, 1.0974e-02, 4.2232e-09],\n         [1.0198e-02, 7.7434e-15, 5.3259e-13, 9.8980e-01, 8.6406e-14, 4.5062e-15,\n          4.1225e-26, 1.6776e-09, 1.5138e-22],\n         [1.8908e-17, 5.2437e-12, 3.4132e-09, 9.6388e-01, 1.0641e-08, 7.1942e-10,\n          2.1268e-08, 3.3454e-02, 2.6681e-03],\n         [5.8396e-01, 1.6258e-04, 1.9715e-19, 6.7882e-05, 5.1436e-08, 3.3768e-13,\n          4.1571e-01, 1.0136e-04, 1.1518e-07],\n         [5.2584e-10, 1.9745e-10, 2.4162e-07, 3.5893e-07, 3.7625e-08, 3.1810e-04,\n          2.2581e-05, 9.9949e-01, 1.6681e-04],\n         [6.9729e-12, 2.0976e-09, 6.9106e-17, 4.8437e-17, 7.8191e-16, 1.3799e-21,\n          1.0000e+00, 4.9538e-16, 5.5053e-21],\n         [2.6925e-02, 9.7307e-01, 2.8026e-10, 3.5736e-09, 1.0364e-10, 1.5704e-26,\n          1.0304e-18, 2.0404e-10, 1.9517e-11],\n         [2.0994e-01, 3.8255e-06, 4.6143e-04, 7.8959e-01, 1.0179e-18, 5.5615e-14,\n          8.9297e-13, 2.0580e-07, 2.4923e-12],\n         [9.9701e-01, 3.4508e-11, 7.8280e-18, 1.4319e-10, 2.2099e-04, 7.0453e-25,\n          1.0158e-11, 2.7686e-03, 5.2451e-23],\n         [1.4926e-07, 1.2782e-01, 1.5617e-10, 7.8144e-11, 4.9921e-01, 4.0702e-15,\n          7.2257e-02, 3.0071e-01, 6.8226e-06],\n         [3.4662e-09, 1.2401e-15, 9.9945e-01, 5.2566e-04, 2.7584e-05, 5.1349e-19,\n          1.4541e-14, 1.5983e-16, 3.1209e-11],\n         [2.0476e-41, 2.2794e-30, 4.0390e-34, 8.6846e-22, 1.4003e-39, 4.1496e-36,\n          1.0000e+00, 2.1178e-23, 4.1922e-21],\n         [1.5672e-08, 7.4357e-03, 3.3447e-15, 4.7921e-11, 9.9256e-01, 3.1902e-32,\n          3.2891e-10, 1.7804e-10, 3.2304e-22],\n         [5.5001e-09, 2.0862e-02, 5.5113e-09, 1.9251e-02, 3.7497e-04, 1.7291e-20,\n          3.6052e-01, 5.9899e-01, 1.9033e-06],\n         [3.9321e-06, 1.8964e-02, 6.7932e-03, 7.4859e-01, 2.2565e-01, 8.5682e-27,\n          2.5441e-13, 4.4846e-09, 7.9918e-11],\n         [5.6362e-16, 1.4479e-06, 2.9574e-03, 9.9704e-01, 5.4282e-07, 8.4454e-10,\n          7.6134e-20, 1.2592e-29, 2.5249e-21],\n         [4.2269e-12, 3.8185e-04, 9.1801e-18, 1.7471e-04, 9.9944e-01, 1.5608e-37,\n          2.1384e-22, 4.4678e-10, 3.5985e-24],\n         [7.1003e-16, 8.2622e-19, 1.3880e-30, 1.4600e-21, 1.0000e+00, 7.2772e-21,\n          6.3616e-10, 8.4587e-25, 1.2720e-22],\n         [5.5097e-04, 7.4353e-17, 4.6587e-10, 6.3132e-01, 1.7280e-03, 3.9047e-09,\n          7.7337e-12, 2.1083e-17, 3.6640e-01],\n         [1.4663e-24, 5.3192e-23, 1.7740e-11, 5.3758e-21, 1.6106e-17, 1.0000e+00,\n          6.5656e-17, 6.2807e-17, 9.8211e-26],\n         [8.4086e-05, 1.3081e-08, 1.8574e-03, 1.3140e-04, 5.8781e-16, 6.6727e-18,\n          8.8697e-06, 9.9792e-01, 3.0549e-06],\n         [1.0036e-20, 3.5404e-37, 9.1462e-34, 1.9954e-08, 0.0000e+00, 0.0000e+00,\n          1.0000e+00, 1.6917e-20, 1.9970e-21],\n         [1.1260e-10, 1.9881e-09, 6.6364e-07, 2.9860e-16, 9.9969e-01, 4.7436e-21,\n          8.3430e-10, 1.5899e-06, 3.1053e-04],\n         [2.6362e-11, 3.4842e-10, 1.8149e-01, 8.1851e-01, 2.7594e-07, 6.2972e-12,\n          1.4957e-08, 3.7696e-14, 4.2868e-06],\n         [6.2305e-18, 1.3662e-12, 1.0000e+00, 9.3485e-12, 3.7564e-06, 9.5655e-24,\n          1.5126e-17, 1.3859e-14, 3.2747e-21],\n         [2.2419e-41, 3.6223e-26, 2.9170e-03, 4.7855e-28, 4.2157e-18, 1.1889e-25,\n          9.9708e-01, 1.3511e-16, 2.7792e-23],\n         [0.0000e+00, 0.0000e+00, 8.1140e-06, 1.0257e-37, 1.4013e-45, 0.0000e+00,\n          9.9999e-01, 0.0000e+00, 7.4523e-35],\n         [1.0268e-02, 5.6080e-06, 2.0897e-04, 9.2964e-01, 1.7656e-10, 5.7722e-02,\n          7.8236e-10, 1.4023e-04, 2.0191e-03],\n         [9.8004e-14, 3.2440e-42, 2.0193e-15, 2.2174e-24, 0.0000e+00, 2.9014e-41,\n          1.0000e+00, 2.4032e-29, 3.6767e-07],\n         [1.0000e+00, 1.7969e-17, 8.6058e-09, 1.7417e-08, 4.9540e-19, 2.6677e-31,\n          1.6084e-17, 7.5409e-18, 4.8420e-20],\n         [5.0244e-02, 3.0348e-03, 2.1771e-06, 1.7948e-05, 6.5346e-13, 6.5936e-24,\n          9.7913e-05, 2.2050e-01, 7.2610e-01],\n         [6.6108e-06, 1.0228e-01, 9.1884e-07, 1.0296e-05, 8.9754e-01, 1.5783e-17,\n          1.2467e-17, 1.6505e-04, 9.9069e-17],\n         [3.3147e-11, 3.2932e-10, 9.0460e-22, 3.6714e-03, 9.9633e-01, 3.0596e-41,\n          3.7024e-11, 2.4566e-14, 2.7776e-36],\n         [3.8987e-25, 9.0588e-21, 1.1913e-32, 9.0110e-21, 1.0000e+00, 4.6243e-44,\n          1.0138e-13, 8.2454e-25, 5.0335e-32],\n         [8.5364e-15, 1.7531e-24, 8.3098e-20, 9.9676e-01, 1.5762e-29, 1.4136e-29,\n          5.6393e-16, 2.4239e-20, 3.2387e-03],\n         [1.2071e-04, 7.8567e-15, 4.6434e-21, 9.9988e-01, 4.5816e-09, 3.0631e-24,\n          3.7975e-28, 3.5437e-23, 4.8778e-35],\n         [3.5676e-06, 6.0326e-05, 3.4642e-17, 9.9993e-01, 2.9386e-11, 5.3498e-26,\n          5.1657e-06, 5.7831e-10, 3.5540e-07],\n         [8.6880e-10, 1.1652e-21, 8.9136e-22, 1.0758e-07, 1.0000e+00, 6.2700e-31,\n          1.4265e-28, 6.4089e-23, 2.5483e-33],\n         [3.3607e-16, 2.4562e-19, 3.6012e-17, 1.0000e+00, 2.5010e-30, 3.7749e-30,\n          5.9492e-13, 8.3947e-35, 1.8664e-20],\n         [2.8288e-11, 1.3526e-14, 9.8162e-01, 9.7864e-07, 1.7243e-10, 1.6117e-19,\n          1.8384e-02, 3.3835e-17, 3.9330e-21],\n         [9.9716e-01, 2.6760e-04, 2.7194e-07, 2.3518e-03, 1.3894e-10, 7.9539e-18,\n          3.9182e-05, 3.2170e-10, 1.8191e-04],\n         [1.9777e-13, 1.2389e-01, 3.9738e-16, 5.0680e-05, 3.2873e-23, 4.9073e-18,\n          1.3871e-02, 1.4650e-04, 8.6205e-01],\n         [1.3468e-16, 8.1377e-23, 7.2538e-11, 8.7253e-04, 1.3050e-24, 1.6166e-21,\n          3.3085e-18, 6.3300e-03, 9.9280e-01],\n         [8.8388e-17, 4.0101e-04, 2.7250e-09, 9.9960e-01, 3.1626e-07, 4.6540e-11,\n          1.4413e-10, 2.2031e-09, 6.7398e-09],\n         [2.1548e-31, 7.2277e-34, 1.1088e-41, 5.0731e-24, 1.4950e-12, 1.0000e+00,\n          1.4013e-45, 9.5013e-39, 3.0927e-25],\n         [1.0273e-15, 1.0000e+00, 1.1500e-09, 1.1144e-15, 5.1789e-13, 9.0548e-27,\n          1.1449e-16, 2.0033e-20, 1.0582e-16],\n         [4.4155e-22, 1.0000e+00, 4.3722e-33, 7.6908e-19, 1.6277e-10, 1.9758e-43,\n          4.1517e-26, 8.6161e-26, 7.3783e-38],\n         [3.5385e-01, 5.0194e-01, 2.2531e-22, 1.5137e-21, 1.4422e-01, 3.9570e-30,\n          7.9107e-13, 3.5888e-10, 7.3996e-24]], device='cuda:0',\n        grad_fn=<SoftmaxBackward0>))"},"metadata":{}}]},{"cell_type":"code","source":"y1[:100]","metadata":{"execution":{"iopub.status.busy":"2024-04-03T06:17:55.760030Z","iopub.execute_input":"2024-04-03T06:17:55.760656Z","iopub.status.idle":"2024-04-03T06:17:55.778612Z","shell.execute_reply.started":"2024-04-03T06:17:55.760623Z","shell.execute_reply":"2024-04-03T06:17:55.777754Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.]], device='cuda:0', dtype=torch.float16)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n\n# Training loop\nnum_epochs = 100\nfor epoch in tqdm(range(num_epochs)):\n    for batch_idx, (data, target1, target2, target3) in enumerate(dataloader):\n        # Move data and targets to CUDA device\n        data, target1, target2, target3 = data.cuda(), target1.cuda(), target2.cuda(), target3.cuda()\n\n        # Forward pass\n        outputs1, outputs2, outputs3 = model(data)\n        \n        # Compute the loss for both tasks\n        loss1 = criterion(outputs1, target1)\n        loss2 = criterion(outputs2, target2)\n        loss3 = criterion(outputs3, target3)\n        total_loss = loss1 + loss2 + loss3\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        \n        # Print progress\n        if (batch_idx+1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(dataloader)}], Total Loss: {total_loss.item():.4f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyConv1dPadSame(nn.Module):\n    \"\"\"\n    extend nn.Conv1d to support SAME padding\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n        super(MyConv1dPadSame, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.groups = groups\n        self.conv = torch.nn.Conv1d(\n            in_channels=self.in_channels, \n            out_channels=self.out_channels, \n            kernel_size=self.kernel_size, \n            stride=self.stride, \n            groups=self.groups)\n\n    def forward(self, x):\n        \n        net = x\n        \n        # compute pad shape\n        in_dim = net.shape[-1]\n        out_dim = (in_dim + self.stride - 1) // self.stride\n        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n        pad_left = p // 2\n        pad_right = p - pad_left\n        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n        \n        net = self.conv(net)\n\n        return net","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyMaxPool1dPadSame(nn.Module):\n    \"\"\"\n    extend nn.MaxPool1d to support SAME padding\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(MyMaxPool1dPadSame, self).__init__()\n        self.kernel_size = kernel_size\n        self.stride = 1\n        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n\n    def forward(self, x):\n        \n        net = x\n        \n        # compute pad shape\n        in_dim = net.shape[-1]\n        out_dim = (in_dim + self.stride - 1) // self.stride\n        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n        pad_left = p // 2\n        pad_right = p - pad_left\n        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n        \n        net = self.max_pool(net)\n        \n        return net","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    \"\"\"\n    ResNet Basic Block\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n        super(BasicBlock, self).__init__()\n        \n        self.in_channels = in_channels\n        self.kernel_size = kernel_size\n        self.out_channels = out_channels\n        self.stride = stride\n        self.groups = groups\n        self.downsample = downsample\n        if self.downsample:\n            self.stride = stride\n        else:\n            self.stride = 1\n        self.is_first_block = is_first_block\n        self.use_bn = use_bn\n        self.use_do = use_do\n\n        # the first conv\n        self.bn1 = nn.BatchNorm1d(in_channels)\n        self.relu1 = nn.ReLU()\n        self.do1 = nn.Dropout(p=0.5)\n        self.conv1 = MyConv1dPadSame(\n            in_channels=in_channels, \n            out_channels=out_channels, \n            kernel_size=kernel_size, \n            stride=self.stride,\n            groups=self.groups)\n\n        # the second conv\n        self.bn2 = nn.BatchNorm1d(out_channels)\n        self.relu2 = nn.ReLU()\n        self.do2 = nn.Dropout(p=0.5)\n        self.conv2 = MyConv1dPadSame(\n            in_channels=out_channels, \n            out_channels=out_channels, \n            kernel_size=kernel_size, \n            stride=1,\n            groups=self.groups)\n                \n        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n\n    def forward(self, x):\n        \n        identity = x\n        \n        # the first conv\n        out = x\n        if not self.is_first_block:\n            if self.use_bn:\n                out = self.bn1(out)\n            out = self.relu1(out)\n            if self.use_do:\n                out = self.do1(out)\n        out = self.conv1(out)\n        \n        # the second conv\n        if self.use_bn:\n            out = self.bn2(out)\n        out = self.relu2(out)\n        if self.use_do:\n            out = self.do2(out)\n        out = self.conv2(out)\n        \n        # if downsample, also downsample identity\n        if self.downsample:\n            identity = self.max_pool(identity)\n            \n        # if expand channel, also pad zeros to identity\n        if self.out_channels != self.in_channels:\n            identity = identity.transpose(-1,-2)\n            ch1 = (self.out_channels-self.in_channels)//2\n            ch2 = self.out_channels-self.in_channels-ch1\n            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n            identity = identity.transpose(-1,-2)\n        \n        # shortcut\n        out += identity\n\n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet1D(nn.Module):\n    \"\"\"\n    \n    Input:\n        X: (n_samples, n_channel, n_length)\n        Y: (n_samples)\n        \n    Output:\n        out: (n_samples)\n        \n    Pararmetes:\n        in_channels: dim of input, the same as n_channel\n        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n        kernel_size: width of kernel\n        stride: stride of kernel moving\n        groups: set largest to 1 as ResNeXt\n        n_block: number of blocks\n        n_classes: number of classes\n        \n    \"\"\"\n\n    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n        super(ResNet1D, self).__init__()\n        \n        self.verbose = verbose\n        self.n_block = n_block\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.groups = groups\n        self.use_bn = use_bn\n        self.use_do = use_do\n\n        self.downsample_gap = downsample_gap # 2 for base model\n        self.increasefilter_gap = increasefilter_gap # 4 for base model\n\n        # first block\n        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n        self.first_block_bn = nn.BatchNorm1d(base_filters)\n        self.first_block_relu = nn.ReLU()\n        out_channels = base_filters\n                \n        # residual blocks\n        self.basicblock_list = nn.ModuleList()\n        for i_block in range(self.n_block):\n            # is_first_block\n            if i_block == 0:\n                is_first_block = True\n            else:\n                is_first_block = False\n            # downsample at every self.downsample_gap blocks\n            if i_block % self.downsample_gap == 1:\n                downsample = True\n            else:\n                downsample = False\n            # in_channels and out_channels\n            if is_first_block:\n                in_channels = base_filters\n                out_channels = in_channels\n            else:\n                # increase filters at every self.increasefilter_gap blocks\n                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n                    out_channels = in_channels * 2\n                else:\n                    out_channels = in_channels\n            \n            tmp_block = BasicBlock(\n                in_channels=in_channels, \n                out_channels=out_channels, \n                kernel_size=self.kernel_size, \n                stride = self.stride, \n                groups = self.groups, \n                downsample=downsample, \n                use_bn = self.use_bn, \n                use_do = self.use_do, \n                is_first_block=is_first_block)\n            self.basicblock_list.append(tmp_block)\n\n        # final prediction\n        self.final_bn = nn.BatchNorm1d(out_channels)\n        self.final_relu = nn.ReLU(inplace=True)\n        # self.do = nn.Dropout(p=0.5)\n        self.dense = nn.Linear(out_channels, n_classes)\n        # self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        \n        out = x\n        \n        # first conv\n        if self.verbose:\n            print('input shape', out.shape)\n        out = self.first_block_conv(out)\n        if self.verbose:\n            print('after first conv', out.shape)\n        if self.use_bn:\n            out = self.first_block_bn(out)\n        out = self.first_block_relu(out)\n        \n        # residual blocks, every block has two conv\n        for i_block in range(self.n_block):\n            net = self.basicblock_list[i_block]\n            if self.verbose:\n                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n            out = net(out)\n            if self.verbose:\n                print(out.shape)\n\n        # final prediction\n        if self.use_bn:\n            out = self.final_bn(out)\n        out = self.final_relu(out)\n        out = out.mean(-1)\n        if self.verbose:\n            print('final pooling', out.shape)\n        # out = self.do(out)\n        out = self.dense(out)\n        if self.verbose:\n            print('dense', out.shape)\n        # out = self.softmax(out)\n        if self.verbose:\n            print('softmax', out.shape)\n        \n        return out    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet = ResNet1D(1, 16, 3, 1, 1, 2, 10, verbose=True)","metadata":{},"execution_count":null,"outputs":[]}]}