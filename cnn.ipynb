{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import winsound\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram_array = np.loadtxt('spectrograms_Atrain.csv', delimiter=',')\n",
    "# spectrogram_array = spectrogram_array.reshape(32400, 256, 74) # reshaping the array to have time frames as 3 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_2d = np.loadtxt('sg_train.csv', delimiter=',')\n",
    "train_array = train_array_2d.reshape(len(train_array_2d), 128, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrograms_tensor_Atrain = torch.tensor(spectrogram_array, dtype=torch.float32)\n",
    "# spectrograms_tensor_Atrain = spectrograms_tensor_Atrain.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrograms_tensor_Atrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tensor = torch.tensor(train_array, dtype=torch.float32)\n",
    "training_tensor = training_tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.read_csv('train.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maneuvering_direction = output_data[[4, 5, 6, 7, 8, 9]].values[1:]\n",
    "maneuvering_direction = maneuvering_direction.astype('int32')\n",
    "fault = output_data[[10, 11, 12, 13, 14, 15, 16, 17,18]].values[1:]\n",
    "fault = fault.astype('int32')\n",
    "model_type = output_data[[1, 2, 3]].values[1:]\n",
    "model_type = model_type.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.tensor(model_type, dtype=torch.float16).cuda()\n",
    "y2 = torch.tensor(maneuvering_direction, dtype=torch.float16).cuda()\n",
    "y3 = torch.tensor(fault, dtype=torch.float16).cuda()\n",
    "Xtr = torch.tensor(training_tensor, dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain = torch.tensor(spectrograms_tensor_Atrain, dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(Xtr, y1, y2, y3)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.softplus1 = nn.Softplus(beta=1, threshold=20)  \n",
    "        self.softplus2 = nn.Softplus(beta=1, threshold=20)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.softplus1(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        shortcut = self.shortcut(x)\n",
    "        out += shortcut\n",
    "        out = self.softplus2(out)  \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.rl = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.rl(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        return out\n",
    "\n",
    "class mtl(nn.Module):\n",
    "    def __init__(self, num_classes1=3, num_classes2=6, num_classes3=9):\n",
    "        super(mtl, self).__init__()\n",
    "        self.resnet18 = ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "        self.fc1 = nn.Linear(512, num_classes1)\n",
    "        self.fc2 = nn.Linear(512, num_classes2)\n",
    "        self.fc3 = nn.Linear(512, num_classes3)\n",
    "        self.sm1 = nn.Softmax(dim=1)#dim=1)\n",
    "        self.sm2 = nn.Softmax(dim=1)#dim=1)\n",
    "        self.sm3 = nn.Softmax(dim=1)#dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.resnet18(x)\n",
    "        out1 = self.sm1(self.fc1(out))#, dim=1)\n",
    "        out2 = self.sm2(self.fc2(out))#, dim=1)\n",
    "        out3 = self.sm3(self.fc3(out))#, dim=1)\n",
    "        return out1, out2, out3\n",
    "\n",
    "model = mtl(num_classes1=3, num_classes2=6, num_classes3=9).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch_idx, (data, target1, target2, target3) in enumerate(dataloader):\n",
    "        data, target1, target2, target3 = data.cuda(), target1.cuda(), target2.cuda(), target3.cuda()\n",
    "        outputs1, outputs2, outputs3 = model(data)\n",
    "\n",
    "        loss1 = criterion(outputs1, target1)\n",
    "        loss2 = criterion(outputs2, target2)\n",
    "        loss3 = criterion(outputs3, target3)\n",
    "        total_loss = loss1 + loss2 + loss3\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        if (batch_idx+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(dataloader)}], Total Loss: {total_loss.item():.4f}')\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(Xtr[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_array_test_2d = np.loadtxt('sg_test.csv', delimiter=',')\n",
    "sg_array_test = sg_array_test_2d.reshape(len(sg_array_test_2d), 128, 22)\n",
    "X_test = torch.tensor(sg_array_test, dtype=torch.float32)\n",
    "X_test = X_test.unsqueeze(1)\n",
    "X_test = X_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader1 = DataLoader(X_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_mapping = {0: 'A', 1: 'B', 2: 'C'}\n",
    "maneuvering_direction_mapping = {0: 'B', 1: 'C', 2: 'CC', 3: 'F', 4: 'L', 5: 'R'}\n",
    "fault_mapping = {0: 'MF1', 1: 'MF2', 2: 'MF3', 3: 'MF4', 4: 'N', 5: 'PC1', 6: 'PC2', 7: 'PC3', 8: 'PC4'}\n",
    "\n",
    "model_type_pred = []\n",
    "maneuvering_direction_pred = []\n",
    "fault_pred = []\n",
    "\n",
    "with torch.no_grad(), tqdm(total=len(dataloader1)) as progress_bar:\n",
    "    for batch_idx, (data) in enumerate(dataloader1):\n",
    "        output1, output2, output3 = model(data)\n",
    "        \n",
    "        m1_indices = output1.argmax(dim=1).cpu().numpy()\n",
    "        m2_indices = output2.argmax(dim=1).cpu().numpy()\n",
    "        m3_indices = output3.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        model_type_pred.extend([model_type_mapping.get(idx) for idx in m1_indices])\n",
    "        maneuvering_direction_pred.extend([maneuvering_direction_mapping.get(idx) for idx in m2_indices])\n",
    "        fault_pred.extend([fault_mapping.get(idx) for idx in m3_indices])\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "\n",
    "model_type_pred = np.array(model_type_pred)\n",
    "maneuvering_direction_pred = np.array(maneuvering_direction_pred)\n",
    "fault_pred = np.array(fault_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([model_type_pred, maneuvering_direction_pred, fault_pred])\n",
    "df = pd.DataFrame(data.T, columns=['model_type', 'maneuvering_direction', 'fault']) \n",
    "df.to_csv('predwithoutid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predwithoutid = pd.read_csv('predwithoutid.csv')\n",
    "predwithoutid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = []\n",
    "# Extract labels from file paths and store them in a list\n",
    "for file in os.listdir('./Dataset-ArIES/drone_A/A/test/mic1'):\n",
    "    ID.append(file +'_mic1')\n",
    "for file in os.listdir('./Dataset-ArIES/drone_B/B/test/mic1'):\n",
    "    ID.append(file + '_mic1')\n",
    "for file in os.listdir('./Dataset-ArIES/drone_C/C/test/mic1'):\n",
    "    ID.append(file + '_mic1')\n",
    "for file in os.listdir('./Dataset-ArIES/drone_A/A/test/mic2'):\n",
    "    ID.append(file + '_mic2')\n",
    "for file in os.listdir('./Dataset-ArIES/drone_B/B/test/mic2'):\n",
    "    ID.append(file + '_mic2')\n",
    "for file in os.listdir('./Dataset-ArIES/drone_C/C/test/mic2'):\n",
    "    ID.append(file + '_mic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predwithoutid.insert(0, 'ID', ID)\n",
    "predwithoutid.to_csv('pred1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
